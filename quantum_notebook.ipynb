{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dreamcoder as dc\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_qubit = 2\n",
    "full_circuit = [n_qubit,\n",
    "           [[\"cnot\", 0, 1],\n",
    "           [\"swap\", 0, 1],\n",
    "           [\"hadamard\", 1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -1, 3], [['cnot', 1, 0]]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(n_qubit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(n_qubit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h (no_op $0)))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (no_op $0)))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -7.783640596221253)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -15.567281192442506)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv (no_op $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(2)),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(3)) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(2)) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -14.155496613885283)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size_to_int $0))) (lambda (mv $0))) (no_op $0))))\")\n",
    "code.evaluate([])(3)\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -52.145060152057745)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "# print_circuit(code.evaluate([])(5))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "# print_circuit(code.evaluate([])(5))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile bottom-up enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9013 --control=9011 --hb=9010 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"0a0f4965-9892-404e-adcd-73854468aa16\" --shell=9012 --transport=\"tcp\" --iopub=9014 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-8431LxyAicQH9lzp.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"python\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-03-25 12:32:35.820498 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  python\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 225517568\n",
      "Currently using this much memory: 225517568\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.966272.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.933642.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.888042.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.754496.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.417176.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.360445.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 1.203866.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [168, 168, 869, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.783641 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 5.189094 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 1\n",
      "Currently using this much memory: 225927168\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225927168\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.28\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-4.17\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "-4.17\t(lambda (cnot (h (h (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.89\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.89\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.83\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.83\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "-2.83\t(lambda (mv_r (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -15.567281\tNew joint = -14.998451\n",
      "\n",
      "1.202724 / 8.778653\tmv\n",
      "0.052910 / 8.778653\tmv_r\n",
      "1.425419 / 8.778653\tminv\n",
      "3.000000 / 8.778653\tno_op\n",
      "1.029770 / 8.778653\th\n",
      "2.067830 / 8.778653\tcnot\n",
      "0.000000 / 8.778653\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 1:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225865728\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=1_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_unordered.pdf\n",
      "Currently using this much memory: 225714176\n",
      "Currently using this much memory: 225714176\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971279.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.943310.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.898743.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.803303.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.686891.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.128656.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.464150.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 226070528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 226070528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.7 seconds\n",
      "Grammar after iteration 2:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225996800\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=2_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_unordered.pdf\n",
      "Currently using this much memory: 225853440\n",
      "Currently using this much memory: 225853440\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.965786.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.932314.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.880273.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775636.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.634202.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.900280.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.251888.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225558528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225558528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 3:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225497088\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=3_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_unordered.pdf\n",
      "Currently using this much memory: 225415168\n",
      "Currently using this much memory: 225415168\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.970709.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.916057.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.866513.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775666.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.648860.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.043345.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.101726.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225435648\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225435648\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 4:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225370112\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=4_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_unordered.pdf\n",
      "Currently using this much memory: 225239040\n",
      "Currently using this much memory: 225239040\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.973917.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.946072.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.905853.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.816774.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.683275.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.117403.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.566357.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225259520\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225259520\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 5:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225193984\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=5_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_unordered.pdf\n",
      "Currently using this much memory: 225054720\n",
      "Currently using this much memory: 225054720\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971404.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.944928.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.907639.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.822110.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.702229.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.167367.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.800816.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225075200\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225075200\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 6:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 224989184\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=6_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_unordered.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 1.06798 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: tensor_contraction at line 44\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    44                                           def tensor_contraction(A, B, indices):\n",
      "    45      8907      18291.0      2.1      1.7      n_qubits = get_qubit_number(A)\n",
      "    46      8907      18792.0      2.1      1.8      idx = [i + n_qubits for i in indices]\n",
      "    47      8907     774326.0     86.9     72.5      out = np.tensordot(A, B, (idx, np.arange(len(indices))))\n",
      "    48      8907     256571.0     28.8     24.0      return np.moveaxis(out, np.arange(-len(indices), 0, 1), idx)\n",
      "\n",
      "Total time: 1.31214 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: full_circuit_to_mat at line 129\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   129                                           def full_circuit_to_mat(full_circuit):\n",
      "   130      6181       3203.0      0.5      0.2      n_qubit, op_list = full_circuit\n",
      "   131                                               \n",
      "   132      6181     138071.0     22.3     10.5      tensor = eye(n_qubit)\n",
      "   133     15088       9797.0      0.6      0.7      for op in op_list:\n",
      "   134                                                   \n",
      "   135      8907    1126483.0    126.5     85.9          tensor = full_op_names[op[0]](tensor, *op[1:])\n",
      "   136                                                   \n",
      "   137      6181      34585.0      5.6      2.6      return tensor_to_mat(tensor)\n",
      "\n",
      "Total time: 2.70419 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: execute_quantum_algorithm at line 425\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   425                                           def execute_quantum_algorithm(p, n_qubits, timeout=None):\n",
      "   426     13278       7764.0      0.6      0.3      try:\n",
      "   427     13278      13906.0      1.0      0.5          circuit =  dc.utilities.runWithTimeout(\n",
      "   428     13278      12040.0      0.9      0.4              lambda: p.evaluate([])(n_qubits),\n",
      "   429     13278    1322929.0     99.6     48.9              timeout=timeout\n",
      "   430                                                   )\n",
      "   431      6124    1335440.0    218.1     49.4          return state_circuit_to_mat(circuit)\n",
      "   432      7154       8300.0      1.2      0.3      except dc.utilities.RunWithTimeout: return None\n",
      "   433      7154       3814.0      0.5      0.1      except: return None\n",
      "\n",
      "Total time: 5.14877 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/tasks.py\n",
      "Function: logLikelihood at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                               def logLikelihood(self, e, timeout=None):\n",
      "    22    203252     132890.0      0.7      2.6          if QuantumTask.last_algorithm is not e:\n",
      "    23     12152      15143.0      1.2      0.3              QuantumTask.last_algorithm = e\n",
      "    24     12152      14729.0      1.2      0.3              QuantumTask.last_algorithm_evaluations = {}\n",
      "    25                                           \n",
      "    26    204620     205369.0      1.0      4.0          for n in range(self.min_size, self.max_size):\n",
      "    27    204378     162548.0      0.8      3.2              if n not in QuantumTask.last_algorithm_evaluations.keys():\n",
      "    28     13278    2797987.0    210.7     54.3                  QuantumTask.last_algorithm_evaluations[n] = execute_quantum_algorithm(e, n, timeout)\n",
      "    29                                           \n",
      "    30    204378     112376.0      0.5      2.2              yh = QuantumTask.last_algorithm_evaluations[n]\n",
      "    31    204378     153265.0      0.7      3.0              yh_true = self.target_algorithm_evaluations[n]\n",
      "    32                                           \n",
      "    33    204378      94276.0      0.5      1.8              if yh is None:\n",
      "    34    119090      65833.0      0.6      1.3                  return dc.utilities.NEGATIVEINFINITY\n",
      "    35                                                       \n",
      "    36     85288    1318634.0     15.5     25.6              if not np.all(np.abs(yh-yh_true)<= 1e-5):\n",
      "    37     83920      75608.0      0.9      1.5                  return dc.utilities.NEGATIVEINFINITY\n",
      "    38                                                           \n",
      "    39       242        112.0      0.5      0.0          return 0.\n",
      "\n",
      "Total time: 36.3868 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\n",
      "Function: multicoreEnumeration at line 10\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    10                                           def multicoreEnumeration(g, tasks, _=None,\n",
      "    11                                                                    enumerationTimeout=None,\n",
      "    12                                                                    solver='ocaml',\n",
      "    13                                                                    CPUs=1,\n",
      "    14                                                                    maximumFrontier=None,\n",
      "    15                                                                    verbose=True,\n",
      "    16                                                                    evaluationTimeout=None,\n",
      "    17                                                                    testing=False):\n",
      "    18                                               '''g: Either a Grammar, or a map from task to grammar.\n",
      "    19                                               Returns (list-of-frontiers, map-from-task-to-search-time)'''\n",
      "    20                                           \n",
      "    21                                               # We don't use actual threads but instead use the multiprocessing\n",
      "    22                                               # library. This is because we need to be able to kill workers.\n",
      "    23                                               #from multiprocess import Process, Queue\n",
      "    24                                           \n",
      "    25         6        499.0     83.2      0.0      from multiprocessing import Queue\n",
      "    26                                           \n",
      "    27                                                # everything that gets sent between processes will be dilled\n",
      "    28         6         84.0     14.0      0.0      import dill\n",
      "    29                                               \n",
      "    30         6         44.0      7.3      0.0      solvers = {\"ocaml\": solveForTask_ocaml,\n",
      "    31         6         33.0      5.5      0.0                 \"bottom\": solveForTask_bottom,   \n",
      "    32         6         43.0      7.2      0.0                 \"pypy\": solveForTask_pypy,   \n",
      "    33         6        312.0     52.0      0.0                 \"python\": solveForTask_python}   \n",
      "    34         6         29.0      4.8      0.0      assert solver in solvers, \"You must specify a valid solver. options are ocaml, pypy, or python.\" \n",
      "    35                                           \n",
      "    36         6         22.0      3.7      0.0      likelihoodModel = None\n",
      "    37         6         27.0      4.5      0.0      if solver == 'pypy' or solver == 'python':\n",
      "    38                                                 # Use an all or nothing likelihood model.\n",
      "    39         6        422.0     70.3      0.0        likelihoodModel = AllOrNothingLikelihoodModel(timeout=evaluationTimeout) \n",
      "    40                                                 \n",
      "    41                                           \n",
      "    42         6        101.0     16.8      0.0      if not isinstance(g, dict):\n",
      "    43         6        578.0     96.3      0.0          g = {t: g for t in tasks}\n",
      "    44                                               \n",
      "    45                                               \n",
      "    46         6         41.0      6.8      0.0      if solver == \"bottom\":\n",
      "    47                                                   for t, _g in g.items():\n",
      "    48                                                       _g.unrolled = PCFG.from_grammar(_g, t.request).number_rules()\n",
      "    49                                                           \n",
      "    50         6         23.0      3.8      0.0      task2grammar = g\n",
      "    51                                           \n",
      "    52         6         42.0      7.0      0.0      solver_str = solver\n",
      "    53         6         29.0      4.8      0.0      solver = solvers[solver]\n",
      "    54                                           \n",
      "    55                                               # If we are not evaluating on held out testing tasks:\n",
      "    56                                               # Bin the tasks by request type and grammar\n",
      "    57                                               # If these are the same then we can enumerate for multiple tasks simultaneously\n",
      "    58                                               # If we are evaluating testing tasks:\n",
      "    59                                               # Make sure that each job corresponds to exactly one task\n",
      "    60         6         23.0      3.8      0.0      jobs = {}\n",
      "    61       120        467.0      3.9      0.0      for i, t in enumerate(tasks):\n",
      "    62       114        408.0      3.6      0.0          if testing:\n",
      "    63                                                       k = (task2grammar[t], t.request, i)\n",
      "    64                                                   else:\n",
      "    65       114        688.0      6.0      0.0              k = (task2grammar[t], t.request)\n",
      "    66       114      10581.0     92.8      0.0          jobs[k] = jobs.get(k, []) + [t]\n",
      "    67                                           \n",
      "    68         6         40.0      6.7      0.0      disableParallelism = len(jobs) == 1\n",
      "    69         6         21.0      3.5      0.0      parallelCallback = launchParallelProcess if not disableParallelism else lambda f, * \\\n",
      "    70                                                   a, **k: f(*a, **k)\n",
      "    71         6         27.0      4.5      0.0      if disableParallelism:\n",
      "    72         6       7150.0   1191.7      0.0          eprint(\"Disabling parallelism on the Python side because we only have one job.\")\n",
      "    73         6       5959.0    993.2      0.0          eprint(\"If you are using ocaml or bottom, there could still be parallelism.\")\n",
      "    74                                           \n",
      "    75                                               # Map from task to the shortest time to find a program solving it\n",
      "    76         6        221.0     36.8      0.0      bestSearchTime = {t: None for t in task2grammar}\n",
      "    77                                           \n",
      "    78         6        479.0     79.8      0.0      lowerBounds = {k: 0. for k in jobs}\n",
      "    79                                           \n",
      "    80         6        527.0     87.8      0.0      frontiers = {t: Frontier([], task=t) for t in task2grammar}\n",
      "    81                                           \n",
      "    82                                               # For each job we keep track of how long we have been working on it\n",
      "    83         6        480.0     80.0      0.0      stopwatches = {t: Stopwatch() for t in jobs}\n",
      "    84                                           \n",
      "    85                                               # Map from task to how many programs we enumerated for that task\n",
      "    86         6        129.0     21.5      0.0      taskToNumberOfPrograms = {t: 0 for t in tasks }\n",
      "    87                                           \n",
      "    88         6         33.0      5.5      0.0      def numberOfHits(f):\n",
      "    89                                                   return sum(e.logLikelihood > -0.01 for e in f)\n",
      "    90                                           \n",
      "    91         6         32.0      5.3      0.0      def budgetIncrement(lb):\n",
      "    92                                                   nonlocal solver_str\n",
      "    93                                                   if solver_str==\"bottom\":\n",
      "    94                                                       return 6\n",
      "    95                                                   else:\n",
      "    96                                                       return 1.5\n",
      "    97                                           \n",
      "    98         6         34.0      5.7      0.0      def maximumFrontiers(j):\n",
      "    99                                                   tasks = jobs[j]\n",
      "   100                                                   return {t: maximumFrontier - numberOfHits(frontiers[t]) for t in tasks}\n",
      "   101                                           \n",
      "   102         6         19.0      3.2      0.0      def allocateCPUs(n, tasks):\n",
      "   103                                                   allocation = {t: 0 for t in tasks}\n",
      "   104                                                   while n > 0:\n",
      "   105                                                       for t in tasks:\n",
      "   106                                                           # During testing we use exactly one CPU per task\n",
      "   107                                                           if testing and allocation[t] > 0:\n",
      "   108                                                               return allocation\n",
      "   109                                                           allocation[t] += 1\n",
      "   110                                                           n -= 1\n",
      "   111                                                           if n == 0:\n",
      "   112                                                               break\n",
      "   113                                                   return allocation\n",
      "   114                                           \n",
      "   115         6         21.0      3.5      0.0      def refreshJobs():\n",
      "   116                                                   for k in list(jobs.keys()):\n",
      "   117                                                       v = [t for t in jobs[k]\n",
      "   118                                                            if numberOfHits(frontiers[t]) < maximumFrontier\n",
      "   119                                                            and stopwatches[k].elapsed <= enumerationTimeout]\n",
      "   120                                                       if v:\n",
      "   121                                                           jobs[k] = v\n",
      "   122                                                       else:\n",
      "   123                                                           del jobs[k]\n",
      "   124                                           \n",
      "   125                                               # Workers put their messages in here\n",
      "   126         6       6756.0   1126.0      0.0      q = Queue()\n",
      "   127                                           \n",
      "   128                                               # How many CPUs are we using?\n",
      "   129         6         29.0      4.8      0.0      activeCPUs = 0\n",
      "   130                                           \n",
      "   131                                               # How many CPUs was each job allocated?\n",
      "   132         6         22.0      3.7      0.0      id2CPUs = {}\n",
      "   133                                               # What job was each ID working on?\n",
      "   134         6         21.0      3.5      0.0      id2job = {}\n",
      "   135         6         22.0      3.7      0.0      nextID = 0\n",
      "   136                                           \n",
      "   137         6         22.0      3.7      0.0      while True:\n",
      "   138        54      35212.0    652.1      0.1          refreshJobs()\n",
      "   139                                                   # Don't launch a job that we are already working on\n",
      "   140                                                   # We run the stopwatch whenever the job is being worked on\n",
      "   141                                                   # freeJobs are things that we are not working on but could be\n",
      "   142        54       3357.0     62.2      0.0          freeJobs = [j for j in jobs if not stopwatches[j].running\n",
      "   143                                                               and stopwatches[j].elapsed < enumerationTimeout - 0.5]\n",
      "   144        54        206.0      3.8      0.0          if freeJobs and activeCPUs < CPUs:\n",
      "   145                                                       # Allocate a CPU to each of the jobs that we have made the least\n",
      "   146                                                       # progress on\n",
      "   147        48       1753.0     36.5      0.0              freeJobs.sort(key=lambda j: lowerBounds[j])\n",
      "   148                                                       # Launch some more jobs until all of the CPUs are being used\n",
      "   149        48        193.0      4.0      0.0              availableCPUs = CPUs - activeCPUs\n",
      "   150        48      24117.0    502.4      0.1              allocation = allocateCPUs(availableCPUs, freeJobs)\n",
      "   151        96        358.0      3.7      0.0              for j in freeJobs:\n",
      "   152        48       1477.0     30.8      0.0                  if allocation[j] == 0:\n",
      "   153                                                               continue\n",
      "   154        48        200.0      4.2      0.0                  g, request = j[:2]\n",
      "   155        48       1541.0     32.1      0.0                  bi = budgetIncrement(lowerBounds[j])\n",
      "   156        48       2248.0     46.8      0.0                  thisTimeout = enumerationTimeout - stopwatches[j].elapsed\n",
      "   157        48        246.0      5.1      0.0                  eprint(\"(frontend) Launching %s (%d tasks) w/ %d CPUs. %f <= MDL < %f. Timeout %f.\" %\n",
      "   158        48      68289.0   1422.7      0.2                         (request, len(jobs[j]), allocation[j], lowerBounds[j], lowerBounds[j] + bi, thisTimeout))\n",
      "   159        48       2655.0     55.3      0.0                  stopwatches[j].start()\n",
      "   160        48        541.0     11.3      0.0                  parallelCallback(wrapInThread(solver),\n",
      "   161        48        183.0      3.8      0.0                                   q=q, g=g, ID=nextID,\n",
      "   162        48       1815.0     37.8      0.0                                   elapsedTime=stopwatches[j].elapsed,\n",
      "   163        48       1581.0     32.9      0.0                                   CPUs=allocation[j],\n",
      "   164        48       1840.0     38.3      0.0                                   tasks=jobs[j],\n",
      "   165        48       1563.0     32.6      0.0                                   lowerBound=lowerBounds[j],\n",
      "   166        48       1618.0     33.7      0.0                                   upperBound=lowerBounds[j] + bi,\n",
      "   167        48        166.0      3.5      0.0                                   budgetIncrement=bi,\n",
      "   168        48        177.0      3.7      0.0                                   timeout=thisTimeout,\n",
      "   169        48        167.0      3.5      0.0                                   evaluationTimeout=evaluationTimeout,\n",
      "   170        48       4845.0    100.9      0.0                                   maximumFrontiers=maximumFrontiers(j),\n",
      "   171        48        176.0      3.7      0.0                                   testing=testing,\n",
      "   172        48   36032441.0 750675.9     99.0                                   likelihoodModel=likelihoodModel)\n",
      "   173        48       2892.0     60.2      0.0                  id2CPUs[nextID] = allocation[j]\n",
      "   174        48        236.0      4.9      0.0                  id2job[nextID] = j\n",
      "   175        48        194.0      4.0      0.0                  nextID += 1\n",
      "   176                                           \n",
      "   177        48       1749.0     36.4      0.0                  activeCPUs += allocation[j]\n",
      "   178        48       2907.0     60.6      0.0                  lowerBounds[j] += bi\n",
      "   179                                           \n",
      "   180                                                   # If nothing is running, and we just tried to launch jobs,\n",
      "   181                                                   # then that means we are finished\n",
      "   182        54        581.0     10.8      0.0          if all(not s.running for s in stopwatches.values()):\n",
      "   183         6         20.0      3.3      0.0              break\n",
      "   184                                           \n",
      "   185                                                   # Wait to get a response\n",
      "   186        48      81904.0   1706.3      0.2          message = Bunch(dill.loads(q.get()))\n",
      "   187                                           \n",
      "   188        48        232.0      4.8      0.0          if message.result == \"failure\":\n",
      "   189                                                       eprint(\"PANIC! Exception in child worker:\", message.exception)\n",
      "   190                                                       eprint(message.stacktrace)\n",
      "   191                                                       assert False\n",
      "   192        48        170.0      3.5      0.0          elif message.result == \"success\":\n",
      "   193                                                       # Mark the CPUs is no longer being used and pause the stopwatch\n",
      "   194        48        197.0      4.1      0.0              activeCPUs -= id2CPUs[message.ID]\n",
      "   195        48       2370.0     49.4      0.0              stopwatches[id2job[message.ID]].stop()\n",
      "   196                                           \n",
      "   197        48       1880.0     39.2      0.0              newFrontiers, searchTimes, pc = message.value\n",
      "   198       930       3672.0      3.9      0.0              for t, f in newFrontiers.items():\n",
      "   199       882       3080.0      3.5      0.0                  oldBest = None if len(\n",
      "   200       882       6247.0      7.1      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   201       882      14902.0     16.9      0.0                  frontiers[t] = frontiers[t].combine(f)\n",
      "   202       882       3350.0      3.8      0.0                  newBest = None if len(\n",
      "   203       882       6328.0      7.2      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   204                                           \n",
      "   205       882       4746.0      5.4      0.0                  taskToNumberOfPrograms[t] += pc\n",
      "   206                                           \n",
      "   207       882       3599.0      4.1      0.0                  dt = searchTimes[t]\n",
      "   208       882       3140.0      3.6      0.0                  if dt is not None:\n",
      "   209        53        238.0      4.5      0.0                      if bestSearchTime[t] is None:\n",
      "   210        18         85.0      4.7      0.0                          bestSearchTime[t] = dt\n",
      "   211                                                               else:\n",
      "   212                                                                   # newBest & oldBest should both be defined\n",
      "   213        35        113.0      3.2      0.0                          assert oldBest is not None\n",
      "   214        35        111.0      3.2      0.0                          assert newBest is not None\n",
      "   215        35        128.0      3.7      0.0                          newScore = newBest.logPrior + newBest.logLikelihood\n",
      "   216        35        117.0      3.3      0.0                          oldScore = oldBest.logPrior + oldBest.logLikelihood\n",
      "   217                                           \n",
      "   218        35        112.0      3.2      0.0                          if newScore > oldScore:\n",
      "   219                                                                       bestSearchTime[t] = dt\n",
      "   220        35        115.0      3.3      0.0                          elif newScore == oldScore:\n",
      "   221        35        227.0      6.5      0.0                              bestSearchTime[t] = min(bestSearchTime[t], dt)\n",
      "   222                                                   else:\n",
      "   223                                                       eprint(\"Unknown message result:\", message.result)\n",
      "   224                                                       assert False\n",
      "   225                                           \n",
      "   226         6         22.0      3.7      0.0      eprint(\"We enumerated this many programs, for each task:\\n\\t\",\n",
      "   227         6      15539.0   2589.8      0.0             list(taskToNumberOfPrograms.values()))\n",
      "   228                                           \n",
      "   229         6        133.0     22.2      0.0      return [frontiers[t] for t in tasks], bestSearchTime"
     ]
    }
   ],
   "source": [
    "%lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -13.595880825949859)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (inc(inc(dec 0))) (lambda (mv $0))) (no_op $0)))\")\n",
    "code.evaluate([])(5)\n",
    "code.infer()\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuationtype = tcircuit\n",
    "#avoid  no _ op "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000\tt0\t$_\n",
      "0.000000\ttcircuit -> tcircuit\tmv\n",
      "0.000000\ttcircuit -> tcircuit\tmv_r\n",
      "0.000000\ttcircuit -> tcircuit\tminv\n",
      "0.000000\ttsize -> tcircuit\tno_op\n",
      "0.000000\ttcircuit -> tcircuit\th\n",
      "0.000000\ttcircuit -> tcircuit\tcnot\n",
      "0.000000\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outputs with and without observational equivalence\n",
    "\n",
    "# primitives = [\n",
    "#     p_move_next,\n",
    "#     p_no_op,\n",
    "#     p_hadamard,\n",
    "# ]\n",
    "\n",
    "\n",
    "# grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "\n",
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (minv (cnot (no_op $0))))\n",
      "(lambda (h (mv (no_op $0))))\n",
      "(lambda (h (mv_r (no_op $0))))\n",
      "(lambda (h (minv (no_op $0))))\n",
      "(lambda (h (h (no_op $0))))\n",
      "(lambda (h (cnot (no_op $0))))\n",
      "(lambda (cnot (mv (no_op $0))))\n",
      "(lambda (cnot (mv_r (no_op $0))))\n",
      "(lambda (cnot (minv (no_op $0))))\n",
      "(lambda (cnot (h (no_op $0))))\n",
      "(lambda (cnot (cnot (no_op $0))))\n",
      "(lambda (rep 0 (lambda $0) (no_op $0)))\n",
      "(lambda (mv (mv (mv (no_op $0)))))\n",
      "(lambda (mv (mv (mv_r (no_op $0)))))\n",
      "(lambda (mv (mv (minv (no_op $0)))))\n",
      "(lambda (mv (mv (h (no_op $0)))))\n",
      "(lambda (mv (mv (cnot (no_op $0)))))\n",
      "(lambda (mv (mv_r (mv (no_op $0)))))\n",
      "(lambda (mv (mv_r (mv_r (no_op $0)))))\n",
      "(lambda (mv (mv_r (minv (no_op $0)))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 3], [['hadamard', 0], ['hadamard', 0]]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(\"(lambda (mv (h (h (no_op $0)))))\").evaluate([])(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (mv (minv (cnot (no_op $0)))))\n",
      "(lambda (mv (h (mv (no_op $0)))))\n",
      "(lambda (mv (h (cnot (no_op $0)))))\n",
      "(lambda (mv (cnot (mv (no_op $0)))))\n",
      "(lambda (mv (cnot (h (no_op $0)))))\n",
      "(lambda (mv_r (h (mv (no_op $0)))))\n",
      "(lambda (mv_r (cnot (mv (no_op $0)))))\n",
      "(lambda (minv (h (mv (no_op $0)))))\n",
      "(lambda (minv (h (cnot (no_op $0)))))\n",
      "(lambda (minv (cnot (mv (no_op $0)))))\n",
      "(lambda (minv (cnot (h (no_op $0)))))\n",
      "(lambda (h (mv (mv (no_op $0)))))\n",
      "(lambda (h (mv (h (no_op $0)))))\n",
      "(lambda (h (mv (cnot (no_op $0)))))\n",
      "(lambda (h (cnot (mv (no_op $0)))))\n",
      "(lambda (h (cnot (h (no_op $0)))))\n",
      "(lambda (cnot (mv (mv (no_op $0)))))\n",
      "(lambda (cnot (mv (minv (no_op $0)))))\n",
      "(lambda (cnot (mv (h (no_op $0)))))\n",
      "(lambda (cnot (mv (cnot (no_op $0)))))\n",
      "(lambda (cnot (h (mv (no_op $0)))))\n",
      "(lambda (cnot (h (cnot (no_op $0)))))\n",
      "(lambda (mv (mv (mv (minv (no_op $0))))))\n",
      "(lambda (mv (mv (mv (h (no_op $0))))))\n",
      "(lambda (mv (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (minv (h (no_op $0))))))\n",
      "(lambda (mv (mv (minv (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (h (mv (no_op $0))))))\n",
      "(lambda (mv (mv (h (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (mv (cnot (h (no_op $0))))))\n",
      "(lambda (mv (minv (h (mv (no_op $0))))))\n",
      "(lambda (mv (minv (h (cnot (no_op $0))))))\n",
      "(lambda (mv (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (minv (cnot (h (no_op $0))))))\n",
      "(lambda (mv (h (mv (mv (no_op $0))))))\n",
      "(lambda (mv (h (mv (h (no_op $0))))))\n",
      "(lambda (mv (h (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (h (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (h (cnot (h (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (h (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (cnot (h (mv (no_op $0))))))\n",
      "(lambda (mv (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (mv_r (minv (h (mv (no_op $0))))))\n",
      "(lambda (mv_r (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (mv (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (h (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (cnot (no_op $0))))))\n",
      "(lambda (mv_r (h (cnot (mv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (h (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (mv_r (cnot (h (mv (no_op $0))))))\n",
      "(lambda (minv (h (mv (mv (no_op $0))))))\n",
      "(lambda (minv (h (mv (h (no_op $0))))))\n",
      "(lambda (minv (h (mv (cnot (no_op $0))))))\n",
      "(lambda (minv (h (cnot (mv (no_op $0))))))\n",
      "(lambda (minv (h (cnot (h (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (h (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (minv (cnot (h (mv (no_op $0))))))\n",
      "(lambda (minv (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (h (mv (mv (mv (no_op $0))))))\n",
      "(lambda (h (mv (mv (h (no_op $0))))))\n",
      "(lambda (h (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (h (mv (h (mv (no_op $0))))))\n",
      "(lambda (h (mv (h (cnot (no_op $0))))))\n",
      "(lambda (h (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (h (mv (cnot (h (no_op $0))))))\n",
      "(lambda (h (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (h (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (h (cnot (mv (h (no_op $0))))))\n",
      "(lambda (h (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (h (cnot (h (mv (no_op $0))))))\n",
      "(lambda (h (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (minv (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (h (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (minv (h (no_op $0))))))\n",
      "(lambda (cnot (mv (minv (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (h (mv (no_op $0))))))\n",
      "(lambda (cnot (mv (h (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (mv (cnot (h (no_op $0))))))\n",
      "(lambda (cnot (mv_r (h (mv (no_op $0))))))\n",
      "(lambda (cnot (mv_r (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (minv (h (mv (no_op $0))))))\n",
      "(lambda (cnot (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (h (mv (mv (no_op $0))))))\n",
      "(lambda (cnot (h (mv (h (no_op $0))))))\n",
      "(lambda (cnot (h (mv (cnot (no_op $0))))))\n",
      "(lambda (cnot (h (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (h (cnot (h (no_op $0))))))\n",
      "(lambda (mv (mv (mv (minv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (minv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv (h (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (h (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (h (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (minv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (minv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv_r (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv_r (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (minv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (minv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv_r (mv_r (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (mv_r (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (mv (minv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (minv (h (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (minv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (minv (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (minv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (cnot (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (minv (h (mv (mv (mv (no_op $0)))))))\n",
      "(lambda (minv (h (mv (mv (h (no_op $0)))))))\n",
      "(lambda (minv (h (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (minv (h (mv (h (mv (no_op $0)))))))\n",
      "(lambda (minv (h (mv (h (cnot (no_op $0)))))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerating arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    # p_0,\n",
    "    p_inc,\n",
    "    p_dec,\n",
    "]\n",
    "\n",
    "grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(dc.type.tint, dc.type.tint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = pcfg.quantized_enumeration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda $0)\n",
      "(lambda (inc $0))\n",
      "(lambda (dec $0))\n",
      "(lambda (inc (inc $0)))\n",
      "(lambda (inc (dec $0)))\n",
      "(lambda (dec (inc $0)))\n",
      "(lambda (dec (dec $0)))\n",
      "(lambda (inc (inc (inc $0))))\n",
      "(lambda (inc (inc (dec $0))))\n",
      "(lambda (inc (dec (inc $0))))\n",
      "(lambda (inc (dec (dec $0))))\n",
      "(lambda (dec (inc (inc $0))))\n",
      "(lambda (dec (inc (dec $0))))\n",
      "(lambda (dec (dec (inc $0))))\n",
      "(lambda (dec (dec (dec $0))))\n",
      "(lambda (inc (inc (inc (inc $0)))))\n",
      "(lambda (inc (inc (inc (dec $0)))))\n",
      "(lambda (inc (inc (dec (inc $0)))))\n",
      "(lambda (inc (inc (dec (dec $0)))))\n",
      "(lambda (inc (dec (inc (inc $0)))))\n",
      "(lambda (inc (dec (inc (dec $0)))))\n",
      "(lambda (inc (dec (dec (inc $0)))))\n",
      "(lambda (inc (dec (dec (dec $0)))))\n",
      "(lambda (dec (inc (inc (inc $0)))))\n",
      "(lambda (dec (inc (inc (dec $0)))))\n",
      "(lambda (dec (inc (dec (inc $0)))))\n",
      "(lambda (dec (inc (dec (dec $0)))))\n",
      "(lambda (dec (dec (inc (inc $0)))))\n",
      "(lambda (dec (dec (inc (dec $0)))))\n",
      "(lambda (dec (dec (dec (inc $0)))))\n",
      "(lambda (dec (dec (dec (dec $0)))))\n",
      "(lambda (inc (inc (inc (inc (inc $0))))))\n",
      "(lambda (inc (inc (inc (inc (dec $0))))))\n",
      "(lambda (inc (inc (inc (dec (inc $0))))))\n",
      "(lambda (inc (inc (inc (dec (dec $0))))))\n",
      "(lambda (inc (inc (dec (inc (inc $0))))))\n",
      "(lambda (inc (inc (dec (inc (dec $0))))))\n",
      "(lambda (inc (inc (dec (dec (inc $0))))))\n",
      "(lambda (inc (inc (dec (dec (dec $0))))))\n",
      "(lambda (inc (dec (inc (inc (inc $0))))))\n",
      "(lambda (inc (dec (inc (inc (dec $0))))))\n",
      "(lambda (inc (dec (inc (dec (inc $0))))))\n",
      "(lambda (inc (dec (inc (dec (dec $0))))))\n",
      "(lambda (inc (dec (dec (inc (inc $0))))))\n",
      "(lambda (inc (dec (dec (inc (dec $0))))))\n",
      "(lambda (inc (dec (dec (dec (inc $0))))))\n",
      "(lambda (inc (dec (dec (dec (dec $0))))))\n",
      "(lambda (dec (inc (inc (inc (inc $0))))))\n",
      "(lambda (dec (inc (inc (inc (dec $0))))))\n",
      "(lambda (dec (inc (inc (dec (inc $0))))))\n",
      "(lambda (dec (inc (inc (dec (dec $0))))))\n",
      "(lambda (dec (inc (dec (inc (inc $0))))))\n",
      "(lambda (dec (inc (dec (inc (dec $0))))))\n",
      "(lambda (dec (inc (dec (dec (inc $0))))))\n",
      "(lambda (dec (inc (dec (dec (dec $0))))))\n",
      "(lambda (dec (dec (inc (inc (inc $0))))))\n",
      "(lambda (dec (dec (inc (inc (dec $0))))))\n",
      "(lambda (dec (dec (inc (dec (inc $0))))))\n",
      "(lambda (dec (dec (inc (dec (dec $0))))))\n",
      "(lambda (dec (dec (dec (inc (inc $0))))))\n",
      "(lambda (dec (dec (dec (inc (dec $0))))))\n",
      "(lambda (dec (dec (dec (dec (inc $0))))))\n",
      "(lambda (dec (dec (dec (dec (dec $0))))))\n",
      "(lambda (inc (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (dec $0)))))))\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in iterator:\n",
    "    counter +=1\n",
    "    if counter<100:\n",
    "        print(i)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start symbol: (tcircuit, (tsize,))\n",
      "\n",
      "(tcircuit, (tsize,)) ::= mv\t0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= mv_r\t0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= minv\t0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= no_op\t0x(tsize, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= h\t0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= cnot\t0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "(tcircuit, (tsize,)) ::= rep\t0x(int, (tsize,)) 1x(tcircuit, (tcircuit, tsize)) 0x(tcircuit, (tsize,))\t\t-1.9459101490553132\n",
      "\n",
      "(tsize, (tsize,)) ::= $0\t\t\t0.0\n",
      "\n",
      "(int, (tsize,)) ::= 0\t\t\t-1.3862943611198906\n",
      "(int, (tsize,)) ::= inc\t0x(int, (tsize,))\t\t-1.3862943611198906\n",
      "(int, (tsize,)) ::= dec\t0x(int, (tsize,))\t\t-1.3862943611198906\n",
      "(int, (tsize,)) ::= size_to_int\t0x(tsize, (tsize,))\t\t-1.3862943611198906\n",
      "\n",
      "(tcircuit, (tcircuit, tsize)) ::= mv\t0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= mv_r\t0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= minv\t0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= no_op\t0x(tsize, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= h\t0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= cnot\t0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= rep\t0x(int, (tcircuit, tsize)) 1x(tcircuit, (tcircuit, tcircuit, tsize)) 0x(tcircuit, (tcircuit, tsize))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit, tsize)) ::= $0\t\t\t-2.0794415416798357\n",
      "\n",
      "(tsize, (tcircuit, tsize)) ::= $1\t\t\t0.0\n",
      "\n",
      "(int, (tcircuit, tsize)) ::= 0\t\t\t-1.3862943611198906\n",
      "(int, (tcircuit, tsize)) ::= inc\t0x(int, (tcircuit, tsize))\t\t-1.3862943611198906\n",
      "(int, (tcircuit, tsize)) ::= dec\t0x(int, (tcircuit, tsize))\t\t-1.3862943611198906\n",
      "(int, (tcircuit, tsize)) ::= size_to_int\t0x(tsize, (tcircuit, tsize))\t\t-1.3862943611198906\n",
      "\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= mv\t0x(tcircuit, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= mv_r\t0x(tcircuit, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= minv\t0x(tcircuit, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= no_op\t0x(tsize, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= h\t0x(tcircuit, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= cnot\t0x(tcircuit, (tcircuit, tcircuit, tsize))\t\t-1.9459101490553132\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= $0\t\t\t-2.6390573296152584\n",
      "(tcircuit, (tcircuit, tcircuit, tsize)) ::= $1\t\t\t-2.6390573296152584\n",
      "\n",
      "(tsize, (tcircuit, tcircuit, tsize)) ::= $2\t\t\t0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n",
      "Enumerated 6124 programs\n",
      "[(lambda 0)]\n",
      "Enumerated 6656 programs\n"
     ]
    }
   ],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "print(restricted_pcfg)\n",
    "restricted_dictionary = dc.enumeration.enumerate_pcfg(restricted_pcfg,timeout=60, circuit_execution_function=state_circuit_to_mat)\n",
    "\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit_full))\n",
    "full_dictionary = dc.enumeration.enumerate_pcfg(full_pcfg,timeout=60, circuit_execution_function=full_circuit_to_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerated 2226 programs\n"
     ]
    }
   ],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(4))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(4))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"matched_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, []]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(matched_programs[0][0]).evaluate([])(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for the recognition network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [3,5]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar)\n",
    "lr=0.000001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [03:41<17:59, 13.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_9274/3989586621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrecognition_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognition_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognition_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammarBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchedLogLikelihoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in trange(100):\n",
    "    for matched_program in matched_programs:\n",
    "        i = np.random.randint(0, len(matched_programs))\n",
    "        task = QuantumTask(\"generated_task\", lambda n_qubit:dc.program.Program.parse(matched_programs[i][0]).evaluate([])(n_qubit))\n",
    "        embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "        \n",
    "        simple_program = dc.program.Program.parse(matched_programs[i][1])\n",
    "        summary = grammar.closedLikelihoodSummary(simple_program.infer(),simple_program)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recognition_model.zero_grad()\n",
    "        \n",
    "        feature = recognition_model._MLP(embedding)\n",
    "        features = feature.expand(1, feature.size(-1))\n",
    "        lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, [summary])\n",
    "        loss = -lls.max()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8219feec10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4237,  0.0233,  0.1348, -0.3718,  0.0440,  0.7508, -1.2073,  0.8207,\n",
       "         0.1788,  0.2635,  0.1615,  0.1921], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognition_model.grammarBuilder.logProductions(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.783640596221253, tensor([-7.3444], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-15.567281192442506, tensor([-14.8894], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-52.145060152057745, tensor([-51.4628], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# profile running time, enumeration speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_quantum(matched_dictionary={unitaries: simple_program, complicated_list},)\n",
    "# for each sample\n",
    "#     embedding= feature_extractor([unitary, complicated_list]) (i.e. encoder)  #in the case of great we first need an embedding and here we get the final embedding\n",
    "    \n",
    "#     # apply the recognition model\n",
    "#     [from frontierBiasOptimal]\n",
    "#     features = self._MLP(features)\n",
    "#     features = features.expand(batchSize, features.size(-1))  # TODO\n",
    "#     lls = self.grammarBuilder.batchedLogLikelihoods(features, [simple_program])\n",
    "        \n",
    "#     # train (optimize -lls  adam)\n",
    "#     lls.backward\n",
    "    \n",
    "# # look at the new likelihoods\n",
    "#     recognitionmodel.grammarOfTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more enumerated tasks (10k)\n",
    "\n",
    "# bags of words (Gates) e.g. number of occurrences for each gate\n",
    "# great https://github.com/google-research/crossbeam/blob/main/crossbeam/model/great.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observational equivalence\n",
    "# https://cseweb.ucsd.edu/~npolikarpova/publications/oopsla20-probe.pdf\n",
    "\n",
    "# let's start from arithmetic expressions\n",
    "\n",
    "# remove no_op to enable continuation type in grammar\n",
    "\n",
    "# continuationtype: only most recent of this type can be called"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3b58914974b8dde835498c747ea4f1aaf3fb4cb185c0609e0c7a19c91a9bce2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
