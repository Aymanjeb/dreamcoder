{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "import dreamcoder as dc\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_qubit = 2\n",
    "full_circuit = [n_qubit,\n",
    "           [[\"cnot\", 0, 1],\n",
    "           [\"swap\", 0, 1],\n",
    "           [\"hadamard\", 1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -1, 3], [['cnot', 1, 0]]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(n_qubit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -2.1972245773362196)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h (no_op $0)))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cnot Not in candidates\n",
      "Candidates is {mv: (0.0, tcircuit -> tcircuit, Context(next = 0, {})), no_op: (0.0, tsize -> tcircuit, Context(next = 0, {})), h: (0.0, tcircuit -> tcircuit, Context(next = 0, {}))}\n",
      "request is tcircuit\n",
      "xs [(no_op $0)]\n",
      "environment [tsize]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_2941/426728557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_task_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cnot_01\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(lambda (cnot (no_op $0)))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlogLikelihood\u001b[0;34m(self, request, expression)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosedLikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             eprint(\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mclosedLikelihoodSummary\u001b[0;34m(self, request, expression, silent)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosedLikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGrammarFailure\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             failureExport = 'failures/grammarFailure%s.pickle' % (\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlikelihoodSummary\u001b[0;34m(self, context, environment, request, expression, silent)\u001b[0m\n\u001b[1;32m    257\u001b[0m                                           \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                                           \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                                           silent=silent)\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Build the candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         candidates = self.buildCandidates(request, context, environment,\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlikelihoodSummary\u001b[0;34m(self, context, environment, request, expression, silent)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"environment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (no_op $0)))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cnot Not in candidates\n",
      "Candidates is {mv: (0.0, tcircuit -> tcircuit, Context(next = 0, {})), no_op: (0.0, tsize -> tcircuit, Context(next = 0, {}))}\n",
      "request is tcircuit\n",
      "xs [(minv (mv (no_op $0)))]\n",
      "environment [tsize]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_12645/3022334248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_task_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cnot_10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(lambda (cnot (minv(mv(no_op $0)))))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlogLikelihood\u001b[0;34m(self, request, expression)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosedLikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             eprint(\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mclosedLikelihoodSummary\u001b[0;34m(self, request, expression, silent)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosedLikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihoodSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGrammarFailure\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             failureExport = 'failures/grammarFailure%s.pickle' % (\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlikelihoodSummary\u001b[0;34m(self, context, environment, request, expression, silent)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                           \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                           \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                           silent=silent)\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Build the candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         candidates = self.buildCandidates(request, context, environment,\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mlikelihoodSummary\u001b[0;34m(self, context, environment, request, expression, silent)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"environment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -15.567281192442506)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv (no_op $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(2)),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(3)) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(2)) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -14.155496613885283)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size_to_int $0))) (lambda (mv $0))) (no_op $0))))\")\n",
    "code.evaluate([])(3)\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -52.145060152057745)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(5))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(5))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 5],\n",
       " [['swap', 0, 1],\n",
       "  ['swap', 1, 2],\n",
       "  ['swap', 2, 3],\n",
       "  ['swap', 3, 4],\n",
       "  ['swap', 2, 3],\n",
       "  ['swap', 1, 2]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.evaluate([])(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"0b25c009-f150-4ead-acf3-e43bb5ac7d58\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-13877Hi74RHe7pQ3s.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"python\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-03-25 12:32:35.820498 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  python\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 225517568\n",
      "Currently using this much memory: 225517568\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.966272.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.933642.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.888042.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.754496.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.417176.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.360445.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 1.203866.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [168, 168, 869, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.783641 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 5.189094 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 1\n",
      "Currently using this much memory: 225927168\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225927168\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.28\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-4.17\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "-4.17\t(lambda (cnot (h (h (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.89\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.89\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.83\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.83\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "-2.83\t(lambda (mv_r (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -15.567281\tNew joint = -14.998451\n",
      "\n",
      "1.202724 / 8.778653\tmv\n",
      "0.052910 / 8.778653\tmv_r\n",
      "1.425419 / 8.778653\tminv\n",
      "3.000000 / 8.778653\tno_op\n",
      "1.029770 / 8.778653\th\n",
      "2.067830 / 8.778653\tcnot\n",
      "0.000000 / 8.778653\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 1:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225865728\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=1_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_unordered.pdf\n",
      "Currently using this much memory: 225714176\n",
      "Currently using this much memory: 225714176\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971279.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.943310.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.898743.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.803303.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.686891.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.128656.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.464150.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 226070528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 226070528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.7 seconds\n",
      "Grammar after iteration 2:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225996800\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=2_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_unordered.pdf\n",
      "Currently using this much memory: 225853440\n",
      "Currently using this much memory: 225853440\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.965786.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.932314.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.880273.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775636.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.634202.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.900280.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.251888.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225558528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225558528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 3:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225497088\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=3_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_unordered.pdf\n",
      "Currently using this much memory: 225415168\n",
      "Currently using this much memory: 225415168\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.970709.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.916057.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.866513.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775666.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.648860.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.043345.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.101726.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225435648\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225435648\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 4:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225370112\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=4_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_unordered.pdf\n",
      "Currently using this much memory: 225239040\n",
      "Currently using this much memory: 225239040\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.973917.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.946072.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.905853.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.816774.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.683275.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.117403.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.566357.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225259520\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225259520\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 5:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225193984\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=5_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_unordered.pdf\n",
      "Currently using this much memory: 225054720\n",
      "Currently using this much memory: 225054720\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971404.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.944928.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.907639.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.822110.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.702229.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.167367.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.800816.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225075200\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225075200\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 6:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 224989184\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=6_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_unordered.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 1.06798 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: tensor_contraction at line 44\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    44                                           def tensor_contraction(A, B, indices):\n",
      "    45      8907      18291.0      2.1      1.7      n_qubits = get_qubit_number(A)\n",
      "    46      8907      18792.0      2.1      1.8      idx = [i + n_qubits for i in indices]\n",
      "    47      8907     774326.0     86.9     72.5      out = np.tensordot(A, B, (idx, np.arange(len(indices))))\n",
      "    48      8907     256571.0     28.8     24.0      return np.moveaxis(out, np.arange(-len(indices), 0, 1), idx)\n",
      "\n",
      "Total time: 1.31214 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: full_circuit_to_mat at line 129\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   129                                           def full_circuit_to_mat(full_circuit):\n",
      "   130      6181       3203.0      0.5      0.2      n_qubit, op_list = full_circuit\n",
      "   131                                               \n",
      "   132      6181     138071.0     22.3     10.5      tensor = eye(n_qubit)\n",
      "   133     15088       9797.0      0.6      0.7      for op in op_list:\n",
      "   134                                                   \n",
      "   135      8907    1126483.0    126.5     85.9          tensor = full_op_names[op[0]](tensor, *op[1:])\n",
      "   136                                                   \n",
      "   137      6181      34585.0      5.6      2.6      return tensor_to_mat(tensor)\n",
      "\n",
      "Total time: 2.70419 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: execute_quantum_algorithm at line 425\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   425                                           def execute_quantum_algorithm(p, n_qubits, timeout=None):\n",
      "   426     13278       7764.0      0.6      0.3      try:\n",
      "   427     13278      13906.0      1.0      0.5          circuit =  dc.utilities.runWithTimeout(\n",
      "   428     13278      12040.0      0.9      0.4              lambda: p.evaluate([])(n_qubits),\n",
      "   429     13278    1322929.0     99.6     48.9              timeout=timeout\n",
      "   430                                                   )\n",
      "   431      6124    1335440.0    218.1     49.4          return state_circuit_to_mat(circuit)\n",
      "   432      7154       8300.0      1.2      0.3      except dc.utilities.RunWithTimeout: return None\n",
      "   433      7154       3814.0      0.5      0.1      except: return None\n",
      "\n",
      "Total time: 5.14877 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/tasks.py\n",
      "Function: logLikelihood at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                               def logLikelihood(self, e, timeout=None):\n",
      "    22    203252     132890.0      0.7      2.6          if QuantumTask.last_algorithm is not e:\n",
      "    23     12152      15143.0      1.2      0.3              QuantumTask.last_algorithm = e\n",
      "    24     12152      14729.0      1.2      0.3              QuantumTask.last_algorithm_evaluations = {}\n",
      "    25                                           \n",
      "    26    204620     205369.0      1.0      4.0          for n in range(self.min_size, self.max_size):\n",
      "    27    204378     162548.0      0.8      3.2              if n not in QuantumTask.last_algorithm_evaluations.keys():\n",
      "    28     13278    2797987.0    210.7     54.3                  QuantumTask.last_algorithm_evaluations[n] = execute_quantum_algorithm(e, n, timeout)\n",
      "    29                                           \n",
      "    30    204378     112376.0      0.5      2.2              yh = QuantumTask.last_algorithm_evaluations[n]\n",
      "    31    204378     153265.0      0.7      3.0              yh_true = self.target_algorithm_evaluations[n]\n",
      "    32                                           \n",
      "    33    204378      94276.0      0.5      1.8              if yh is None:\n",
      "    34    119090      65833.0      0.6      1.3                  return dc.utilities.NEGATIVEINFINITY\n",
      "    35                                                       \n",
      "    36     85288    1318634.0     15.5     25.6              if not np.all(np.abs(yh-yh_true)<= 1e-5):\n",
      "    37     83920      75608.0      0.9      1.5                  return dc.utilities.NEGATIVEINFINITY\n",
      "    38                                                           \n",
      "    39       242        112.0      0.5      0.0          return 0.\n",
      "\n",
      "Total time: 36.3868 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\n",
      "Function: multicoreEnumeration at line 10\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    10                                           def multicoreEnumeration(g, tasks, _=None,\n",
      "    11                                                                    enumerationTimeout=None,\n",
      "    12                                                                    solver='ocaml',\n",
      "    13                                                                    CPUs=1,\n",
      "    14                                                                    maximumFrontier=None,\n",
      "    15                                                                    verbose=True,\n",
      "    16                                                                    evaluationTimeout=None,\n",
      "    17                                                                    testing=False):\n",
      "    18                                               '''g: Either a Grammar, or a map from task to grammar.\n",
      "    19                                               Returns (list-of-frontiers, map-from-task-to-search-time)'''\n",
      "    20                                           \n",
      "    21                                               # We don't use actual threads but instead use the multiprocessing\n",
      "    22                                               # library. This is because we need to be able to kill workers.\n",
      "    23                                               #from multiprocess import Process, Queue\n",
      "    24                                           \n",
      "    25         6        499.0     83.2      0.0      from multiprocessing import Queue\n",
      "    26                                           \n",
      "    27                                                # everything that gets sent between processes will be dilled\n",
      "    28         6         84.0     14.0      0.0      import dill\n",
      "    29                                               \n",
      "    30         6         44.0      7.3      0.0      solvers = {\"ocaml\": solveForTask_ocaml,\n",
      "    31         6         33.0      5.5      0.0                 \"bottom\": solveForTask_bottom,   \n",
      "    32         6         43.0      7.2      0.0                 \"pypy\": solveForTask_pypy,   \n",
      "    33         6        312.0     52.0      0.0                 \"python\": solveForTask_python}   \n",
      "    34         6         29.0      4.8      0.0      assert solver in solvers, \"You must specify a valid solver. options are ocaml, pypy, or python.\" \n",
      "    35                                           \n",
      "    36         6         22.0      3.7      0.0      likelihoodModel = None\n",
      "    37         6         27.0      4.5      0.0      if solver == 'pypy' or solver == 'python':\n",
      "    38                                                 # Use an all or nothing likelihood model.\n",
      "    39         6        422.0     70.3      0.0        likelihoodModel = AllOrNothingLikelihoodModel(timeout=evaluationTimeout) \n",
      "    40                                                 \n",
      "    41                                           \n",
      "    42         6        101.0     16.8      0.0      if not isinstance(g, dict):\n",
      "    43         6        578.0     96.3      0.0          g = {t: g for t in tasks}\n",
      "    44                                               \n",
      "    45                                               \n",
      "    46         6         41.0      6.8      0.0      if solver == \"bottom\":\n",
      "    47                                                   for t, _g in g.items():\n",
      "    48                                                       _g.unrolled = PCFG.from_grammar(_g, t.request).number_rules()\n",
      "    49                                                           \n",
      "    50         6         23.0      3.8      0.0      task2grammar = g\n",
      "    51                                           \n",
      "    52         6         42.0      7.0      0.0      solver_str = solver\n",
      "    53         6         29.0      4.8      0.0      solver = solvers[solver]\n",
      "    54                                           \n",
      "    55                                               # If we are not evaluating on held out testing tasks:\n",
      "    56                                               # Bin the tasks by request type and grammar\n",
      "    57                                               # If these are the same then we can enumerate for multiple tasks simultaneously\n",
      "    58                                               # If we are evaluating testing tasks:\n",
      "    59                                               # Make sure that each job corresponds to exactly one task\n",
      "    60         6         23.0      3.8      0.0      jobs = {}\n",
      "    61       120        467.0      3.9      0.0      for i, t in enumerate(tasks):\n",
      "    62       114        408.0      3.6      0.0          if testing:\n",
      "    63                                                       k = (task2grammar[t], t.request, i)\n",
      "    64                                                   else:\n",
      "    65       114        688.0      6.0      0.0              k = (task2grammar[t], t.request)\n",
      "    66       114      10581.0     92.8      0.0          jobs[k] = jobs.get(k, []) + [t]\n",
      "    67                                           \n",
      "    68         6         40.0      6.7      0.0      disableParallelism = len(jobs) == 1\n",
      "    69         6         21.0      3.5      0.0      parallelCallback = launchParallelProcess if not disableParallelism else lambda f, * \\\n",
      "    70                                                   a, **k: f(*a, **k)\n",
      "    71         6         27.0      4.5      0.0      if disableParallelism:\n",
      "    72         6       7150.0   1191.7      0.0          eprint(\"Disabling parallelism on the Python side because we only have one job.\")\n",
      "    73         6       5959.0    993.2      0.0          eprint(\"If you are using ocaml or bottom, there could still be parallelism.\")\n",
      "    74                                           \n",
      "    75                                               # Map from task to the shortest time to find a program solving it\n",
      "    76         6        221.0     36.8      0.0      bestSearchTime = {t: None for t in task2grammar}\n",
      "    77                                           \n",
      "    78         6        479.0     79.8      0.0      lowerBounds = {k: 0. for k in jobs}\n",
      "    79                                           \n",
      "    80         6        527.0     87.8      0.0      frontiers = {t: Frontier([], task=t) for t in task2grammar}\n",
      "    81                                           \n",
      "    82                                               # For each job we keep track of how long we have been working on it\n",
      "    83         6        480.0     80.0      0.0      stopwatches = {t: Stopwatch() for t in jobs}\n",
      "    84                                           \n",
      "    85                                               # Map from task to how many programs we enumerated for that task\n",
      "    86         6        129.0     21.5      0.0      taskToNumberOfPrograms = {t: 0 for t in tasks }\n",
      "    87                                           \n",
      "    88         6         33.0      5.5      0.0      def numberOfHits(f):\n",
      "    89                                                   return sum(e.logLikelihood > -0.01 for e in f)\n",
      "    90                                           \n",
      "    91         6         32.0      5.3      0.0      def budgetIncrement(lb):\n",
      "    92                                                   nonlocal solver_str\n",
      "    93                                                   if solver_str==\"bottom\":\n",
      "    94                                                       return 6\n",
      "    95                                                   else:\n",
      "    96                                                       return 1.5\n",
      "    97                                           \n",
      "    98         6         34.0      5.7      0.0      def maximumFrontiers(j):\n",
      "    99                                                   tasks = jobs[j]\n",
      "   100                                                   return {t: maximumFrontier - numberOfHits(frontiers[t]) for t in tasks}\n",
      "   101                                           \n",
      "   102         6         19.0      3.2      0.0      def allocateCPUs(n, tasks):\n",
      "   103                                                   allocation = {t: 0 for t in tasks}\n",
      "   104                                                   while n > 0:\n",
      "   105                                                       for t in tasks:\n",
      "   106                                                           # During testing we use exactly one CPU per task\n",
      "   107                                                           if testing and allocation[t] > 0:\n",
      "   108                                                               return allocation\n",
      "   109                                                           allocation[t] += 1\n",
      "   110                                                           n -= 1\n",
      "   111                                                           if n == 0:\n",
      "   112                                                               break\n",
      "   113                                                   return allocation\n",
      "   114                                           \n",
      "   115         6         21.0      3.5      0.0      def refreshJobs():\n",
      "   116                                                   for k in list(jobs.keys()):\n",
      "   117                                                       v = [t for t in jobs[k]\n",
      "   118                                                            if numberOfHits(frontiers[t]) < maximumFrontier\n",
      "   119                                                            and stopwatches[k].elapsed <= enumerationTimeout]\n",
      "   120                                                       if v:\n",
      "   121                                                           jobs[k] = v\n",
      "   122                                                       else:\n",
      "   123                                                           del jobs[k]\n",
      "   124                                           \n",
      "   125                                               # Workers put their messages in here\n",
      "   126         6       6756.0   1126.0      0.0      q = Queue()\n",
      "   127                                           \n",
      "   128                                               # How many CPUs are we using?\n",
      "   129         6         29.0      4.8      0.0      activeCPUs = 0\n",
      "   130                                           \n",
      "   131                                               # How many CPUs was each job allocated?\n",
      "   132         6         22.0      3.7      0.0      id2CPUs = {}\n",
      "   133                                               # What job was each ID working on?\n",
      "   134         6         21.0      3.5      0.0      id2job = {}\n",
      "   135         6         22.0      3.7      0.0      nextID = 0\n",
      "   136                                           \n",
      "   137         6         22.0      3.7      0.0      while True:\n",
      "   138        54      35212.0    652.1      0.1          refreshJobs()\n",
      "   139                                                   # Don't launch a job that we are already working on\n",
      "   140                                                   # We run the stopwatch whenever the job is being worked on\n",
      "   141                                                   # freeJobs are things that we are not working on but could be\n",
      "   142        54       3357.0     62.2      0.0          freeJobs = [j for j in jobs if not stopwatches[j].running\n",
      "   143                                                               and stopwatches[j].elapsed < enumerationTimeout - 0.5]\n",
      "   144        54        206.0      3.8      0.0          if freeJobs and activeCPUs < CPUs:\n",
      "   145                                                       # Allocate a CPU to each of the jobs that we have made the least\n",
      "   146                                                       # progress on\n",
      "   147        48       1753.0     36.5      0.0              freeJobs.sort(key=lambda j: lowerBounds[j])\n",
      "   148                                                       # Launch some more jobs until all of the CPUs are being used\n",
      "   149        48        193.0      4.0      0.0              availableCPUs = CPUs - activeCPUs\n",
      "   150        48      24117.0    502.4      0.1              allocation = allocateCPUs(availableCPUs, freeJobs)\n",
      "   151        96        358.0      3.7      0.0              for j in freeJobs:\n",
      "   152        48       1477.0     30.8      0.0                  if allocation[j] == 0:\n",
      "   153                                                               continue\n",
      "   154        48        200.0      4.2      0.0                  g, request = j[:2]\n",
      "   155        48       1541.0     32.1      0.0                  bi = budgetIncrement(lowerBounds[j])\n",
      "   156        48       2248.0     46.8      0.0                  thisTimeout = enumerationTimeout - stopwatches[j].elapsed\n",
      "   157        48        246.0      5.1      0.0                  eprint(\"(frontend) Launching %s (%d tasks) w/ %d CPUs. %f <= MDL < %f. Timeout %f.\" %\n",
      "   158        48      68289.0   1422.7      0.2                         (request, len(jobs[j]), allocation[j], lowerBounds[j], lowerBounds[j] + bi, thisTimeout))\n",
      "   159        48       2655.0     55.3      0.0                  stopwatches[j].start()\n",
      "   160        48        541.0     11.3      0.0                  parallelCallback(wrapInThread(solver),\n",
      "   161        48        183.0      3.8      0.0                                   q=q, g=g, ID=nextID,\n",
      "   162        48       1815.0     37.8      0.0                                   elapsedTime=stopwatches[j].elapsed,\n",
      "   163        48       1581.0     32.9      0.0                                   CPUs=allocation[j],\n",
      "   164        48       1840.0     38.3      0.0                                   tasks=jobs[j],\n",
      "   165        48       1563.0     32.6      0.0                                   lowerBound=lowerBounds[j],\n",
      "   166        48       1618.0     33.7      0.0                                   upperBound=lowerBounds[j] + bi,\n",
      "   167        48        166.0      3.5      0.0                                   budgetIncrement=bi,\n",
      "   168        48        177.0      3.7      0.0                                   timeout=thisTimeout,\n",
      "   169        48        167.0      3.5      0.0                                   evaluationTimeout=evaluationTimeout,\n",
      "   170        48       4845.0    100.9      0.0                                   maximumFrontiers=maximumFrontiers(j),\n",
      "   171        48        176.0      3.7      0.0                                   testing=testing,\n",
      "   172        48   36032441.0 750675.9     99.0                                   likelihoodModel=likelihoodModel)\n",
      "   173        48       2892.0     60.2      0.0                  id2CPUs[nextID] = allocation[j]\n",
      "   174        48        236.0      4.9      0.0                  id2job[nextID] = j\n",
      "   175        48        194.0      4.0      0.0                  nextID += 1\n",
      "   176                                           \n",
      "   177        48       1749.0     36.4      0.0                  activeCPUs += allocation[j]\n",
      "   178        48       2907.0     60.6      0.0                  lowerBounds[j] += bi\n",
      "   179                                           \n",
      "   180                                                   # If nothing is running, and we just tried to launch jobs,\n",
      "   181                                                   # then that means we are finished\n",
      "   182        54        581.0     10.8      0.0          if all(not s.running for s in stopwatches.values()):\n",
      "   183         6         20.0      3.3      0.0              break\n",
      "   184                                           \n",
      "   185                                                   # Wait to get a response\n",
      "   186        48      81904.0   1706.3      0.2          message = Bunch(dill.loads(q.get()))\n",
      "   187                                           \n",
      "   188        48        232.0      4.8      0.0          if message.result == \"failure\":\n",
      "   189                                                       eprint(\"PANIC! Exception in child worker:\", message.exception)\n",
      "   190                                                       eprint(message.stacktrace)\n",
      "   191                                                       assert False\n",
      "   192        48        170.0      3.5      0.0          elif message.result == \"success\":\n",
      "   193                                                       # Mark the CPUs is no longer being used and pause the stopwatch\n",
      "   194        48        197.0      4.1      0.0              activeCPUs -= id2CPUs[message.ID]\n",
      "   195        48       2370.0     49.4      0.0              stopwatches[id2job[message.ID]].stop()\n",
      "   196                                           \n",
      "   197        48       1880.0     39.2      0.0              newFrontiers, searchTimes, pc = message.value\n",
      "   198       930       3672.0      3.9      0.0              for t, f in newFrontiers.items():\n",
      "   199       882       3080.0      3.5      0.0                  oldBest = None if len(\n",
      "   200       882       6247.0      7.1      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   201       882      14902.0     16.9      0.0                  frontiers[t] = frontiers[t].combine(f)\n",
      "   202       882       3350.0      3.8      0.0                  newBest = None if len(\n",
      "   203       882       6328.0      7.2      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   204                                           \n",
      "   205       882       4746.0      5.4      0.0                  taskToNumberOfPrograms[t] += pc\n",
      "   206                                           \n",
      "   207       882       3599.0      4.1      0.0                  dt = searchTimes[t]\n",
      "   208       882       3140.0      3.6      0.0                  if dt is not None:\n",
      "   209        53        238.0      4.5      0.0                      if bestSearchTime[t] is None:\n",
      "   210        18         85.0      4.7      0.0                          bestSearchTime[t] = dt\n",
      "   211                                                               else:\n",
      "   212                                                                   # newBest & oldBest should both be defined\n",
      "   213        35        113.0      3.2      0.0                          assert oldBest is not None\n",
      "   214        35        111.0      3.2      0.0                          assert newBest is not None\n",
      "   215        35        128.0      3.7      0.0                          newScore = newBest.logPrior + newBest.logLikelihood\n",
      "   216        35        117.0      3.3      0.0                          oldScore = oldBest.logPrior + oldBest.logLikelihood\n",
      "   217                                           \n",
      "   218        35        112.0      3.2      0.0                          if newScore > oldScore:\n",
      "   219                                                                       bestSearchTime[t] = dt\n",
      "   220        35        115.0      3.3      0.0                          elif newScore == oldScore:\n",
      "   221        35        227.0      6.5      0.0                              bestSearchTime[t] = min(bestSearchTime[t], dt)\n",
      "   222                                                   else:\n",
      "   223                                                       eprint(\"Unknown message result:\", message.result)\n",
      "   224                                                       assert False\n",
      "   225                                           \n",
      "   226         6         22.0      3.7      0.0      eprint(\"We enumerated this many programs, for each task:\\n\\t\",\n",
      "   227         6      15539.0   2589.8      0.0             list(taskToNumberOfPrograms.values()))\n",
      "   228                                           \n",
      "   229         6        133.0     22.2      0.0      return [frontiers[t] for t in tasks], bestSearchTime"
     ]
    }
   ],
   "source": [
    "%lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid repetition number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_12129/3624976763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(lambda ((rep (dec(dec(dec 0))) (lambda (mv $0))) (no_op $0)))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbetaReduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalseBranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minferType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeVariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalseBranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minferType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeVariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/utilities.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCurried\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36m_repeat\u001b[0;34m(n_times, body)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_times\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid repetition number.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0;32mreturn\u001b[0m   \u001b[0m_repeat_help\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Invalid repetition number."
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (dec(dec(dec 0))) (lambda (mv $0))) (no_op $0)))\")\n",
    "code.evaluate([])(3)\n",
    "code.infer()\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuationtype = tcircuit\n",
    "#avoid  no _ op "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dreamcoder.grammar.Grammar at 0x7fd0c6849950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000\tt0\t$_\n",
      "0.000000\ttcircuit -> tcircuit\tmv\n",
      "0.000000\ttsize -> tcircuit\tno_op\n",
      "0.000000\ttcircuit -> tcircuit\th\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "primitives = [\n",
    "    p_move_next,\n",
    "    p_no_op,\n",
    "    p_hadamard,\n",
    "]\n",
    "\n",
    "\n",
    "grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "\n",
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (no_op $0))\n",
      "(lambda (mv (no_op $0)))\n",
      "(lambda (h (no_op $0)))\n",
      "(lambda (mv (mv (no_op $0))))\n",
      "(lambda (mv (h (no_op $0))))\n",
      "(lambda (h (mv (no_op $0))))\n",
      "(lambda (h (h (no_op $0))))\n",
      "(lambda (mv (mv (mv (no_op $0)))))\n",
      "(lambda (mv (mv (h (no_op $0)))))\n",
      "(lambda (mv (h (mv (no_op $0)))))\n",
      "(lambda (mv (h (h (no_op $0)))))\n",
      "(lambda (h (mv (mv (no_op $0)))))\n",
      "(lambda (h (mv (h (no_op $0)))))\n",
      "(lambda (h (h (mv (no_op $0)))))\n",
      "(lambda (h (h (h (no_op $0)))))\n",
      "(lambda (mv (mv (mv (mv (no_op $0))))))\n",
      "(lambda (mv (mv (mv (h (no_op $0))))))\n",
      "(lambda (mv (mv (h (mv (no_op $0))))))\n",
      "(lambda (mv (mv (h (h (no_op $0))))))\n",
      "(lambda (mv (h (mv (mv (no_op $0))))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 3], [['hadamard', 0], ['hadamard', 0]]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(\"(lambda (mv (h (h (no_op $0)))))\").evaluate([])(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (no_op $0))\n",
      "(lambda (mv (no_op $0)))\n",
      "(lambda (h (no_op $0)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "observational equivalent:(h (h (no_op $0))) to (no_op $0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (mv (mv (no_op $0))))\n",
      "(lambda (mv (h (no_op $0))))\n",
      "(lambda (h (mv (no_op $0))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "observational equivalent:(h (h (mv (no_op $0)))) to (mv (no_op $0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (mv (mv (mv (no_op $0)))))\n",
      "(lambda (mv (mv (h (no_op $0)))))\n",
      "(lambda (mv (h (mv (no_op $0)))))\n",
      "(lambda (h (mv (mv (no_op $0)))))\n",
      "(lambda (h (mv (h (no_op $0)))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid circuit will be ignored (mv (mv (mv (mv (no_op $0)))))\n",
      "observational equivalent:(h (h (mv (mv (no_op $0))))) to (mv (mv (no_op $0)))\n",
      "observational equivalent:(h (h (mv (h (no_op $0))))) to (mv (h (no_op $0)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (mv (mv (mv (h (no_op $0))))))\n",
      "(lambda (mv (mv (h (mv (no_op $0))))))\n",
      "(lambda (mv (h (mv (mv (no_op $0))))))\n",
      "(lambda (mv (h (mv (h (no_op $0))))))\n",
      "(lambda (h (mv (mv (mv (no_op $0))))))\n",
      "(lambda (h (mv (mv (h (no_op $0))))))\n",
      "(lambda (h (mv (h (mv (no_op $0))))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid circuit will be ignored (mv (mv (mv (mv (h (no_op $0))))))\n",
      "Invalid circuit will be ignored (mv (mv (mv (h (mv (no_op $0))))))\n",
      "Invalid circuit will be ignored (mv (mv (h (mv (mv (no_op $0))))))\n",
      "Invalid circuit will be ignored (mv (h (mv (mv (mv (no_op $0))))))\n",
      "observational equivalent:(h (h (mv (mv (mv (no_op $0)))))) to (mv (mv (mv (no_op $0))))\n",
      "observational equivalent:(h (h (mv (mv (h (no_op $0)))))) to (mv (mv (h (no_op $0))))\n",
      "observational equivalent:(h (h (mv (h (mv (no_op $0)))))) to (mv (h (mv (no_op $0))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (mv (mv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (h (mv (mv (h (no_op $0)))))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3713083796995235906"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerating arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    # p_0,\n",
    "    p_inc,\n",
    "    p_dec,\n",
    "]\n",
    "\n",
    "grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(dc.type.tint, dc.type.tint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = pcfg.quantized_enumeration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda $0)\n",
      "(lambda (inc $0))\n",
      "(lambda (dec $0))\n",
      "(lambda (inc (inc $0)))\n",
      "(lambda (inc (dec $0)))\n",
      "(lambda (dec (inc $0)))\n",
      "(lambda (dec (dec $0)))\n",
      "(lambda (inc (inc (inc $0))))\n",
      "(lambda (inc (inc (dec $0))))\n",
      "(lambda (inc (dec (inc $0))))\n",
      "(lambda (inc (dec (dec $0))))\n",
      "(lambda (dec (inc (inc $0))))\n",
      "(lambda (dec (inc (dec $0))))\n",
      "(lambda (dec (dec (inc $0))))\n",
      "(lambda (dec (dec (dec $0))))\n",
      "(lambda (inc (inc (inc (inc $0)))))\n",
      "(lambda (inc (inc (inc (dec $0)))))\n",
      "(lambda (inc (inc (dec (inc $0)))))\n",
      "(lambda (inc (inc (dec (dec $0)))))\n",
      "(lambda (inc (dec (inc (inc $0)))))\n",
      "(lambda (inc (dec (inc (dec $0)))))\n",
      "(lambda (inc (dec (dec (inc $0)))))\n",
      "(lambda (inc (dec (dec (dec $0)))))\n",
      "(lambda (dec (inc (inc (inc $0)))))\n",
      "(lambda (dec (inc (inc (dec $0)))))\n",
      "(lambda (dec (inc (dec (inc $0)))))\n",
      "(lambda (dec (inc (dec (dec $0)))))\n",
      "(lambda (dec (dec (inc (inc $0)))))\n",
      "(lambda (dec (dec (inc (dec $0)))))\n",
      "(lambda (dec (dec (dec (inc $0)))))\n",
      "(lambda (dec (dec (dec (dec $0)))))\n",
      "(lambda (inc (inc (inc (inc (inc $0))))))\n",
      "(lambda (inc (inc (inc (inc (dec $0))))))\n",
      "(lambda (inc (inc (inc (dec (inc $0))))))\n",
      "(lambda (inc (inc (inc (dec (dec $0))))))\n",
      "(lambda (inc (inc (dec (inc (inc $0))))))\n",
      "(lambda (inc (inc (dec (inc (dec $0))))))\n",
      "(lambda (inc (inc (dec (dec (inc $0))))))\n",
      "(lambda (inc (inc (dec (dec (dec $0))))))\n",
      "(lambda (inc (dec (inc (inc (inc $0))))))\n",
      "(lambda (inc (dec (inc (inc (dec $0))))))\n",
      "(lambda (inc (dec (inc (dec (inc $0))))))\n",
      "(lambda (inc (dec (inc (dec (dec $0))))))\n",
      "(lambda (inc (dec (dec (inc (inc $0))))))\n",
      "(lambda (inc (dec (dec (inc (dec $0))))))\n",
      "(lambda (inc (dec (dec (dec (inc $0))))))\n",
      "(lambda (inc (dec (dec (dec (dec $0))))))\n",
      "(lambda (dec (inc (inc (inc (inc $0))))))\n",
      "(lambda (dec (inc (inc (inc (dec $0))))))\n",
      "(lambda (dec (inc (inc (dec (inc $0))))))\n",
      "(lambda (dec (inc (inc (dec (dec $0))))))\n",
      "(lambda (dec (inc (dec (inc (inc $0))))))\n",
      "(lambda (dec (inc (dec (inc (dec $0))))))\n",
      "(lambda (dec (inc (dec (dec (inc $0))))))\n",
      "(lambda (dec (inc (dec (dec (dec $0))))))\n",
      "(lambda (dec (dec (inc (inc (inc $0))))))\n",
      "(lambda (dec (dec (inc (inc (dec $0))))))\n",
      "(lambda (dec (dec (inc (dec (inc $0))))))\n",
      "(lambda (dec (dec (inc (dec (dec $0))))))\n",
      "(lambda (dec (dec (dec (inc (inc $0))))))\n",
      "(lambda (dec (dec (dec (inc (dec $0))))))\n",
      "(lambda (dec (dec (dec (dec (inc $0))))))\n",
      "(lambda (dec (dec (dec (dec (dec $0))))))\n",
      "(lambda (inc (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (dec $0)))))))\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in iterator:\n",
    "    counter +=1\n",
    "    if counter<100:\n",
    "        print(i)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start symbol: (tcircuit, (tsize,))\n",
      "\n",
      "(tcircuit, (tsize,)) ::= no_op\t0x(tsize, (tsize,))\t\t-0.6931471805599453\n",
      "(tcircuit, (tsize,)) ::= h\t0x(tcircuit, (tsize,))\t\t-0.6931471805599453\n",
      "\n",
      "(tsize, (tsize,)) ::= $0\t\t\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(restricted_pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda (mv (mv 0))), (lambda (h 0)), (lambda (mv (mv_r 0))), (lambda (cnot 0)), (lambda (mv (minv 0))), (lambda (rep 2 (lambda 3) 0)), (lambda (mv (no_op 1))), (lambda (mv (h 0))), (lambda (mv (cnot 0))), (lambda (mv (rep 2 (lambda 3) 0))), (lambda (mv_r 0)), (lambda (minv 0)), (lambda (no_op 1))]\n",
      "Enumerated 1786 programs\n",
      "[(lambda (fh (fno_op 1) 2)), (lambda (fh (fh 0 2) 2)), (lambda (fh (fcnot 0 2 2) 2)), (lambda (fh (fswap 0 2 2) 2)), (lambda (fh 0 0)), (lambda (fh 0 (inc 2))), (lambda (fh 0 (dec 2))), (lambda (fh 0 (size_to_int 1))), (lambda (fcnot 0 2 2)), (lambda (fswap 0 2 2))]\n",
      "Enumerated 588 programs\n"
     ]
    }
   ],
   "source": [
    "restricted_dictionary = enumerate_grammar(grammar,timeout=600, circuit_execution_function=state_circuit_to_mat)\n",
    "full_dictionary = enumerate_grammar(full_grammar,timeout=600, circuit_execution_function=full_circuit_to_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerated 78 programs\n"
     ]
    }
   ],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(4))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(4))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"matched_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, [['hadamard', 1], ['swap', 1, 0], ['swap', 1, 0]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc.program.Program.parse(matched_programs[0][0]).evaluate([])(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [3,5]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar)\n",
    "lr=0.000001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:08<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(100):\n",
    "    for matched_program in matched_programs:\n",
    "        i = np.random.randint(0, len(matched_programs))\n",
    "        task = QuantumTask(\"generated_task\", lambda n_qubit:dc.program.Program.parse(matched_programs[i][0]).evaluate([])(n_qubit))\n",
    "        embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "        \n",
    "        simple_program = dc.program.Program.parse(matched_programs[i][1])\n",
    "        summary = grammar.closedLikelihoodSummary(simple_program.infer(),simple_program)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recognition_model.zero_grad()\n",
    "        \n",
    "        feature = recognition_model._MLP(embedding)\n",
    "        features = feature.expand(1, feature.size(-1))\n",
    "        lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, [summary])\n",
    "        loss = -lls.max()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdc31514250>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0950, -0.1797,  0.0424, -0.4200, -0.1315,  0.5482, -1.0439, -0.3015,\n",
       "        -0.3296,  0.3371, -0.2783, -0.0099], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognition_model.grammarBuilder.logProductions(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.783640596221253, tensor([-7.4431], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-15.567281192442506, tensor([-14.6762], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-52.145060152057745, tensor([-51.7950], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# profile running time, enumeration speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_quantum(matched_dictionary={unitaries: simple_program, complicated_list},)\n",
    "# for each sample\n",
    "#     embedding= feature_extractor([unitary, complicated_list]) (i.e. encoder)  #in the case of great we first need an embedding and here we get the final embedding\n",
    "    \n",
    "#     # apply the recognition model\n",
    "#     [from frontierBiasOptimal]\n",
    "#     features = self._MLP(features)\n",
    "#     features = features.expand(batchSize, features.size(-1))  # TODO\n",
    "#     lls = self.grammarBuilder.batchedLogLikelihoods(features, [simple_program])\n",
    "        \n",
    "#     # train (optimize -lls  adam)\n",
    "#     lls.backward\n",
    "    \n",
    "# # look at the new likelihoods\n",
    "#     recognitionmodel.grammarOfTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more enumerated tasks (10k)\n",
    "\n",
    "# bags of words (Gates) e.g. number of occurrences for each gate\n",
    "# great https://github.com/google-research/crossbeam/blob/main/crossbeam/model/great.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observational equivalence\n",
    "https://cseweb.ucsd.edu/~npolikarpova/publications/oopsla20-probe.pdf\n",
    "\n",
    "let's start from arithmetic expressions\n",
    "\n",
    "\n",
    "remove no_op to enable continuation type in grammar\n",
    "\n",
    "continuationtype: only most recent of this type can be called"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3b58914974b8dde835498c747ea4f1aaf3fb4cb185c0609e0c7a19c91a9bce2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
