{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:07.396057Z",
     "iopub.status.busy": "2022-04-26T18:19:07.395857Z",
     "iopub.status.idle": "2022-04-26T18:19:07.402513Z",
     "shell.execute_reply": "2022-04-26T18:19:07.401897Z",
     "shell.execute_reply.started": "2022-04-26T18:19:07.396033Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dreamcoder as dc\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:46.815077Z",
     "iopub.status.busy": "2022-04-25T18:28:46.814683Z",
     "iopub.status.idle": "2022-04-25T18:28:46.817838Z",
     "shell.execute_reply": "2022-04-25T18:28:46.817473Z",
     "shell.execute_reply.started": "2022-04-25T18:28:46.815035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (('cnot', 0, 1), ('swap', 0, 1), ('hadamard', 1)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit = 2\n",
    "full_circuit = (n_qubit,\n",
    "           ((\"cnot\", 0, 1),\n",
    "           (\"swap\", 0, 1),\n",
    "           (\"hadamard\", 1))\n",
    ")\n",
    "full_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:47.410256Z",
     "iopub.status.busy": "2022-04-25T18:28:47.409861Z",
     "iopub.status.idle": "2022-04-25T18:28:47.415882Z",
     "shell.execute_reply": "2022-04-25T18:28:47.415468Z",
     "shell.execute_reply.started": "2022-04-25T18:28:47.410236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:58.544879Z",
     "iopub.status.busy": "2022-04-25T18:28:58.544688Z",
     "iopub.status.idle": "2022-04-25T18:28:58.549754Z",
     "shell.execute_reply": "2022-04-25T18:28:58.549327Z",
     "shell.execute_reply.started": "2022-04-25T18:28:58.544856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.176362Z",
     "iopub.status.busy": "2022-04-25T18:28:59.175938Z",
     "iopub.status.idle": "2022-04-25T18:28:59.490576Z",
     "shell.execute_reply": "2022-04-25T18:28:59.490076Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.176338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.875600Z",
     "iopub.status.busy": "2022-04-25T18:28:59.875358Z",
     "iopub.status.idle": "2022-04-25T18:28:59.886662Z",
     "shell.execute_reply": "2022-04-25T18:28:59.886239Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.875580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:01.068751Z",
     "iopub.status.busy": "2022-04-25T18:29:01.068535Z",
     "iopub.status.idle": "2022-04-25T18:29:01.072992Z",
     "shell.execute_reply": "2022-04-25T18:29:01.072599Z",
     "shell.execute_reply.started": "2022-04-25T18:29:01.068732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(no_op(n_qubit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T23:20:35.960776Z",
     "iopub.status.busy": "2022-04-25T23:20:35.960513Z",
     "iopub.status.idle": "2022-04-25T23:20:35.965165Z",
     "shell.execute_reply": "2022-04-25T23:20:35.964700Z",
     "shell.execute_reply.started": "2022-04-25T23:20:35.960751Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h $0))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot $0))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -8.317766166719343)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))\")\n",
    "code.evaluate([])(no_op(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding primitive\n",
    "code = dc.program.Program.parse(\"(lambda (mv (emb (lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))  $0 )))\")\n",
    "\n",
    "code.evaluate([])(no_op(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv $0)))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(no_op(2))),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(3))) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(2))) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size $0))) (lambda (mv $0))) $0)))\")\n",
    "code.evaluate([])(no_op(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -56.838068805915505)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) $0 )))))\")\n",
    "print_circuit(code.evaluate([])(no_op(3)))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) ) $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) )  $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile bottom-up enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1536060b-098c-4fd5-b891-f22aa0311306\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-23320Afm1Zw1Bm3I3.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"bottom\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-04-03 20:06:17.653038 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  bottom\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 208424960\n",
      "Currently using this much memory: 208429056\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching int -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 6.000000. Timeout 6.000000.\n",
      "PANIC! Exception in child worker: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 243, in _f\n",
      "    r = f(*a, **k)\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 407, in solveForTask_bottom\n",
      "    compile_me=False,\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/utilities.py\", line 404, in callCompiled\n",
      "    stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 800, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 1551, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_23556/2686176463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     41\u001b[0m                            \u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                            **arguments)\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mecIterator\u001b[0;34m(grammar, tasks, _, useDSL, noConsolidation, mask, seed, addFullTaskMetrics, matrixRank, solver, compressor, biasOptimal, contextual, testingTasks, iterations, resume, enumerationTimeout, testingTimeout, testEvery, reuseRecognition, ensembleSize, useRecognitionModel, recognitionTimeout, recognitionSteps, helmholtzRatio, featureExtractor, activation, topK, topk_use_only_likelihood, use_map_search_times, maximumFrontier, pseudoCounts, aic, structurePenalty, arity, evaluationTimeout, taskBatchSize, taskReranker, CPUs, cuda, message, outputPrefix, storeTaskMetrics, rewriteTaskMetrics, auxiliaryLoss, custom_wake_generative)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                                       \u001b[0menumerationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menumerationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                                                       \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                                                       evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSearchTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mdefault_wake_generative\u001b[0;34m(grammar, tasks, maximumFrontier, enumerationTimeout, CPUs, solver, evaluationTimeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m                                                    \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                                                    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                                                    evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generative model enumeration results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrontier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopDownFrontiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\u001b[0m in \u001b[0;36mmulticoreEnumeration\u001b[0;34m(g, tasks, _, enumerationTimeout, solver, CPUs, maximumFrontier, verbose, evaluationTimeout, testing)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PANIC! Exception in child worker:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"success\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Mark the CPUs is no longer being used and pause the stopwatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\n",
    "main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -13.862943611198904)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (inc(inc(dec 0))) (lambda (mv $0))) $0))\")\n",
    "code.evaluate([])(no_op(5))\n",
    "code.infer()\n",
    "tasks[0].logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:57.433325Z",
     "iopub.status.busy": "2022-04-25T18:29:57.432928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pcfg compilation: distinct non terminals 2 ; distinct environments 2\n",
      "start symbol: (tcircuit, (tcircuit,))\n",
      "\n",
      "(tcircuit, (tcircuit,)) ::= mv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= mv_r\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= minv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= h\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= cnot\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= rep\t0x(int, (tcircuit,)) 1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= emb\t1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= $0\t\t\t-2.0794415416798357\n",
      "\n",
      "(int, (tcircuit,)) ::= 0\t\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= inc\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= dec\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= size\t0x(tcircuit, (tcircuit,))\t\t-1.3862943611198906\n",
      "[(lambda 0)]\n",
      " -- Bottom up enumeration, cost 0\n",
      " -- Bottom up enumeration, cost 1\n",
      " -- Bottom up enumeration, cost 2\n",
      " -- Bottom up enumeration, cost 3\n",
      " -- Bottom up enumeration, cost 4\n",
      " -- Bottom up enumeration, cost 5\n",
      " -- Bottom up enumeration, cost 6\n",
      " -- Bottom up enumeration, cost 7\n",
      " -- Bottom up enumeration, cost 8\n",
      " -- Bottom up enumeration, cost 9\n",
      " -- Bottom up enumeration, cost 10\n",
      " -- Bottom up enumeration, cost 11\n",
      " -- Bottom up enumeration, cost 12\n",
      " -- Bottom up enumeration, cost 13\n",
      " -- Bottom up enumeration, cost 14\n",
      " -- Bottom up enumeration, cost 15\n",
      " -- Bottom up enumeration, cost 16\n",
      " -- Bottom up enumeration, cost 17\n",
      " -- Bottom up enumeration, cost 18\n",
      " -- Bottom up enumeration, cost 19\n",
      " -- Bottom up enumeration, cost 20\n",
      " -- Bottom up enumeration, cost 21\n",
      " -- Bottom up enumeration, cost 22\n",
      " -- Bottom up enumeration, cost 23\n",
      " -- Bottom up enumeration, cost 24\n",
      " -- Bottom up enumeration, cost 25\n",
      " -- Bottom up enumeration, cost 26\n",
      " -- Bottom up enumeration, cost 27\n",
      " -- Bottom up enumeration, cost 28\n",
      " -- Bottom up enumeration, cost 29\n",
      " -- Bottom up enumeration, cost 30\n",
      " -- Bottom up enumeration, cost 31\n",
      " -- Bottom up enumeration, cost 32\n",
      " -- Bottom up enumeration, cost 33\n",
      " -- Bottom up enumeration, cost 34\n",
      " -- Bottom up enumeration, cost 35\n",
      " -- Bottom up enumeration, cost 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m restricted_pcfg \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mPCFG\u001b[39m.\u001b[39mfrom_grammar(grammar, request\u001b[39m=\u001b[39mdc\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39marrow(tcircuit, tcircuit))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m restricted_dictionary \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49menumeration\u001b[39m.\u001b[39;49menumerate_pcfg(restricted_pcfg,timeout\u001b[39m=\u001b[39;49m\u001b[39m3600\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m                                                       circuit_execution_function\u001b[39m=\u001b[39;49mstate_circuit_to_mat,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=3'>4</a>\u001b[0m                                                       no_op\u001b[39m=\u001b[39;49mno_op,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=4'>5</a>\u001b[0m                                                       observational_equivalence\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=5'>6</a>\u001b[0m                                                       sound\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py:656\u001b[0m, in \u001b[0;36menumerate_pcfg\u001b[0;34m(pcfg, timeout, circuit_execution_function, no_op, observational_equivalence, sound)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=652'>653</a>\u001b[0m n_min \u001b[39m=\u001b[39m QuantumTask\u001b[39m.\u001b[39mmin_size\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=653'>654</a>\u001b[0m n_max \u001b[39m=\u001b[39m  QuantumTask\u001b[39m.\u001b[39mmax_size\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=655'>656</a>\u001b[0m \u001b[39mfor\u001b[39;00m code \u001b[39min\u001b[39;00m pcfg\u001b[39m.\u001b[39mquantized_enumeration(observational_equivalence\u001b[39m=\u001b[39mobservational_equivalence,\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=656'>657</a>\u001b[0m                                        inputs\u001b[39m=\u001b[39m[[no_op(\u001b[39m3\u001b[39m)],[no_op(\u001b[39m4\u001b[39m)]],\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=657'>658</a>\u001b[0m                                        sound\u001b[39m=\u001b[39msound):\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=658'>659</a>\u001b[0m     \u001b[39mif\u001b[39;00m (time\u001b[39m.\u001b[39mtime()\u001b[39m>\u001b[39mt_0\u001b[39m+\u001b[39mtimeout): \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=659'>660</a>\u001b[0m     \u001b[39m# check if it is a valid circuit\u001b[39;00m\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1902\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration\u001b[0;34m(self, resolution, skeletons, observational_equivalence, sound, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1899'>1900</a>\u001b[0m eprint(\u001b[39m\"\u001b[39m\u001b[39m -- Bottom up enumeration, cost\u001b[39m\u001b[39m\"\u001b[39m, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1900'>1901</a>\u001b[0m \u001b[39mfor\u001b[39;00m skeleton, skeleton_cost \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(skeletons, skeleton_costs):\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1901'>1902</a>\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m complete_skeleton(cost\u001b[39m-\u001b[39mskeleton_cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1902'>1903</a>\u001b[0m         \u001b[39myield\u001b[39;00m e\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1884\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1881'>1882</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete_skeleton\u001b[39m(cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1882'>1883</a>\u001b[0m     \u001b[39mif\u001b[39;00m skeleton\u001b[39m.\u001b[39misAbstraction:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1883'>1884</a>\u001b[0m         \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m complete_skeleton(cost, skeleton\u001b[39m.\u001b[39mbody):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1884'>1885</a>\u001b[0m             \u001b[39myield\u001b[39;00m Abstraction(b)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1885'>1886</a>\u001b[0m     \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misApplication:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1892\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1889'>1890</a>\u001b[0m                 \u001b[39myield\u001b[39;00m Application(f, x)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1890'>1891</a>\u001b[0m \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misNamedHole:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1891'>1892</a>\u001b[0m     \u001b[39myield from\u001b[39;00m expressions_of_size(skeleton\u001b[39m.\u001b[39;49mname, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1892'>1893</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1893'>1894</a>\u001b[0m     \u001b[39mif\u001b[39;00m cost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1865\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.expressions_of_size\u001b[0;34m(symbol, size)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1862'>1863</a>\u001b[0m accepted_new \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1863'>1864</a>\u001b[0m \u001b[39mfor\u001b[39;00m proposed_expression \u001b[39min\u001b[39;00m new:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1864'>1865</a>\u001b[0m     key \u001b[39m=\u001b[39m test_generator\u001b[39m.\u001b[39;49mcompute_signature(proposed_expression,\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1865'>1866</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_type[symbol],\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1866'>1867</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfree_variable_types[symbol])\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1868'>1869</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m equivalences[symbol]:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1869'>1870</a>\u001b[0m         equivalences[symbol][key] \u001b[39m=\u001b[39m proposed_expression\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:92\u001b[0m, in \u001b[0;36mSloppy.compute_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_signature\u001b[39m(\u001b[39mself\u001b[39m, expression, tp, arguments):\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=91'>92</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msound_signature(expression, tp, arguments)\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=93'>94</a>\u001b[0m     outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=94'>95</a>\u001b[0m     \u001b[39mfor\u001b[39;00m test_input \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_inputs(arguments):\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:86\u001b[0m, in \u001b[0;36mSloppy.sound_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=83'>84</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=84'>85</a>\u001b[0m \u001b[39m#eprint(\"output\", tuple(outputs))\u001b[39;00m\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(o \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m outputs):\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=86'>87</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tcircuit, tcircuit))\n",
    "restricted_dictionary = dc.enumeration.enumerate_pcfg(restricted_pcfg,timeout=3600, \n",
    "                                                      circuit_execution_function=state_circuit_to_mat,\n",
    "                                                      no_op=no_op,\n",
    "                                                      observational_equivalence=True,\n",
    "                                                      sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tcircuit_full, tcircuit_full))\n",
    "full_dictionary = dc.enumeration.enumerate_pcfg(full_pcfg,\n",
    "                                                timeout=3600, \n",
    "                                                circuit_execution_function=full_circuit_to_mat,\n",
    "                                                no_op=f_no_op,\n",
    "                                                observational_equivalence=True,\n",
    "                                                sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(f_no_op(4)))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(no_op(4)))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "    # else: print(full_dictionary[unitary][\"task\"])\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m code \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(\u001b[39mlist\u001b[39m(full_dictionary\u001b[39m.\u001b[39mvalues())[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=1'>2</a>\u001b[0m print_circuit(code\u001b[39m.\u001b[39mevaluate([])(f_no_op(\u001b[39m4\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(list(full_dictionary.values())[-1][\"task\"])\n",
    "print_circuit(code.evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          \n",
      "q_0: ─────\n",
      "          \n",
      "q_1: ─────\n",
      "     ┌───┐\n",
      "q_2: ┤ H ├\n",
      "     └───┘\n",
      "q_3: ─────\n",
      "          \n",
      "q_4: ─────\n",
      "     ┌───┐\n",
      "q_5: ┤ H ├\n",
      "     └───┘\n"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda (fh (fh $0 (inc (inc 0))) (dec (fsize $0))))\")\n",
    "print_circuit(code.evaluate([])(f_no_op(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_programs(str_e1, str_e2, reset_state=True): # embed to reset state (i.e. if restricted_set)\n",
    "    if reset_state:\n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "        state_changed = 0\n",
    "        for n_qubit in range(QuantumTask.min_size,  QuantumTask.max_size):\n",
    "            if e1.evaluate([])(no_op(n_qubit))[0][0] !=0:\n",
    "                state_changed +=1\n",
    "        if state_changed:\n",
    "            e1 = dc.program.Program.parse(f\"(lambda (emb {str_e1} $0))\") # if it is already at the beginning do not embed\n",
    "\n",
    "    else: \n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "    e2 = dc.program.Program.parse(str_e2)\n",
    "\n",
    "    return dc.program.Abstraction(\n",
    "        dc.program.Application(e2,\n",
    "        dc.program.Application(e1, dc.program.Index(0)))\n",
    "    ).betaNormalForm(reduceInventions=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_timeout = 1000\n",
    "time_0 = time.time()\n",
    "merged_programs = []\n",
    "for i in range(len(matched_programs)):\n",
    "    for j in range(len(matched_programs)):\n",
    "        ii = np.random.randint(0,len(matched_programs))\n",
    "        jj = np.random.randint(0,len(matched_programs))\n",
    "        if (time.time()>time_0+merging_timeout): break\n",
    "        \n",
    "        full_program = merge_two_programs(matched_programs[ii][0], matched_programs[jj][0], reset_state=False)\n",
    "        restricted_program = merge_two_programs(matched_programs[ii][1], matched_programs[jj][1], reset_state=True)\n",
    "        merged_programs.append([\n",
    "            str(full_program),\n",
    "            str(restricted_program),\n",
    "            -1\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_programs = matched_programs + merged_programs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"training_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(dataset_programs, f)\n",
    "    \n",
    "with open(save_path+\"_matched\",\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)\n",
    "    \n",
    "with open(save_path+\"_restricted\",\"wb\") as f:\n",
    "    pickle.dump(restricted_dictionary, f)\n",
    "    \n",
    "with open(save_path+\"_full\",\"wb\") as f:\n",
    "    pickle.dump(full_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened dictionary with 4.05e+05 restricted programs and 1.04e+06 high-level programs\n",
      "Opened file with 1527579 programs\n"
     ]
    }
   ],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        dataset_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_matched\",\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_restricted\",\"rb\") as f:\n",
    "        restricted_dictionary = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_full\",\"rb\") as f:\n",
    "        full_dictionary = pickle.load(f)\n",
    "        \n",
    "print(f\"Opened dictionary with {len(restricted_dictionary):1.2e} restricted programs and {len(full_dictionary):1.2e} high-level programs\")\n",
    "print(f\"Opened file with {len(dataset_programs)} programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset in 1132723 training programs and 125859 testing programs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(dataset_programs)\n",
    "training_split = int(0.9*len(dataset_programs))\n",
    "training_programs = dataset_programs[:training_split]\n",
    "testing_programs = dataset_programs[training_split:]\n",
    "print(f\"Split dataset in {len(training_programs)} training programs and {len(testing_programs)} testing programs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractors for Recognition Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:47.800176Z",
     "iopub.status.busy": "2022-04-25T22:50:47.799722Z",
     "iopub.status.idle": "2022-04-25T22:50:47.805016Z",
     "shell.execute_reply": "2022-04-25T22:50:47.804479Z",
     "shell.execute_reply.started": "2022-04-25T22:50:47.800125Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import dreamcoder.great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [QuantumTask.min_size,QuantumTask.max_size]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GREAT feature for recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:54.744552Z",
     "iopub.status.busy": "2022-04-25T22:50:54.744330Z",
     "iopub.status.idle": "2022-04-25T22:50:54.768748Z",
     "shell.execute_reply": "2022-04-25T22:50:54.768221Z",
     "shell.execute_reply.started": "2022-04-25T22:50:54.744526Z"
    }
   },
   "outputs": [],
   "source": [
    "class GreatFeatureExtractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, tasks, full_op_names, d_model):\n",
    "        super(GreatFeatureExtractor, self).__init__()\n",
    "        \n",
    "        # number of qubits of the circuits to consider \n",
    "        self.n_min = QuantumTask.min_size\n",
    "        self.n_max =  QuantumTask.max_size\n",
    "        \n",
    "        self.outputDimensionality = d_model\n",
    "        self.feature_extr = dc.great.Great(layers=4, d_model=self.outputDimensionality, batch_first=True)\n",
    "        \n",
    "        # make list of lexicons (possible gate names)\n",
    "        self.vertex_lexicon = list(full_op_names.keys()) + [\"input\", \"aggregate\"]\n",
    "        # define embedding network for the lexicons\n",
    "        self.vertex_lexicon_embedding = nn.Embedding(len(self.vertex_lexicon), self.outputDimensionality)\n",
    "        self.vertex_lexicon_embedding_eval = torch.stack([\n",
    "            self.vertex_lexicon_embedding(torch.tensor(n)) for n in range(self.vertex_lexicon_embedding.num_embeddings)\n",
    "        ])\n",
    "        \n",
    "        # define embedding network for the input type numbers (last one is aggregate)\n",
    "        self.vertex_kind_embeddings = {n_qubits:nn.Embedding(n_qubits+1, self.outputDimensionality) \n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "        self.vertex_kind_embeddings_eval = {n_qubits:torch.stack([\n",
    "            self.vertex_kind_embeddings[n_qubits](torch.tensor(n)) for n in range(self.vertex_kind_embeddings[n_qubits].num_embeddings)\n",
    "            ])\n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "\n",
    "\n",
    "        # make edge lexicon list\n",
    "        self.edge_lexicon = sorted([\"nothing\", \"input\", \"io\", \"output\", \"aggregator\"])\n",
    "        # define embedding network for lexicon\n",
    "        self.edge_lexicon_embedding = nn.Embedding(len(self.edge_lexicon), self.outputDimensionality)\n",
    "        self.edge_lexicon_embedding_eval = torch.stack(\n",
    "            [self.edge_lexicon_embedding(torch.tensor(n)) for n in range(self.edge_lexicon_embedding.num_embeddings)]\n",
    "            )\n",
    "\n",
    "        # define many embedding neural networks for the node id\n",
    "        self.max_gate_size = 2\n",
    "        self.edge_kind_embeddings = [nn.Embedding(self.max_gate_size, self.outputDimensionality),\n",
    "                                     nn.Embedding(self.max_gate_size, self.outputDimensionality)]\n",
    "        self.edge_kind_embeddings_eval = torch.stack(\n",
    "            [torch.stack(\n",
    "                [emb(torch.tensor(n)) for n in range(self.max_gate_size)]\n",
    "                ) for emb in self.edge_kind_embeddings]\n",
    "            )\n",
    "        \n",
    "        # define the no_relation tensor\n",
    "        self.edge_no_relation = self.edge_lexicon.index(\"nothing\")\n",
    "\n",
    "    def add_vertex(self,type, kind, vertices):\n",
    "        # VERTEX: #, type, kind\n",
    "        # Type = gate type\n",
    "        # kind = qubit id of that gate\n",
    "        idx = len(vertices) \n",
    "        vertices.append((idx, type, kind))\n",
    "        return idx\n",
    "\n",
    "    def get_initial_bindings(self,n_bindings, vertices):\n",
    "        return {i:self.add_vertex(self.vertex_lexicon.index(\"input\"),i, vertices) for i in range(n_bindings)}\n",
    "\n",
    "    def get_relations(self,changed_vertices):\n",
    "        relations = []\n",
    "        changed_vertices_array = np.array(changed_vertices)\n",
    "        \n",
    "        # among inputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"input\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][0]) )\n",
    "        \n",
    "        # among outputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"output\"),i,j, changed_vertices_array[i][1], changed_vertices_array[j][1] ))\n",
    "        \n",
    "        # input - output\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"io\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][1]))\n",
    "        \n",
    "        # EDGES row: type kind1 kind2 vertex_from vertex_to\n",
    "        # Type = input/output/io\n",
    "        # kind = #1 -> #2\n",
    "        return relations\n",
    "\n",
    "    def get_graph(self, circuit, bindings, vertices, edges):\n",
    "        if len(circuit)>0:\n",
    "            current_op = circuit[0]\n",
    "            new_bindings = bindings.copy()\n",
    "            changed_vertices = []\n",
    "            for idx, i in enumerate(current_op[1:]): \n",
    "                # current_op[1:] contains qubit_1, qubit_2, ... on which the gate is applied\n",
    "                new_bindings[i] = self.add_vertex(self.vertex_lexicon.index(current_op[0]), idx, vertices) \n",
    "                changed_vertices.append([bindings[i], new_bindings[i]])\n",
    "                \n",
    "            relations = self.get_relations(changed_vertices)\n",
    "            edges.extend(relations)\n",
    "            self.get_graph(circuit[1:], new_bindings, vertices, edges)\n",
    "            \n",
    "    # define total embedding\n",
    "    def get_vertex_list_embedding(self,vertex_list,n_qubits):\n",
    "        vertex_array = np.array(vertex_list) # IDX, GATE, KIND\n",
    "        vertex_embedding = (self.vertex_lexicon_embedding_eval[vertex_array[:,1]] + \n",
    "                            self.vertex_kind_embeddings_eval[n_qubits][vertex_array[:,2]])\n",
    "        return vertex_embedding\n",
    "\n",
    "    def get_edge_list_embedding(self, edges, vertices):\n",
    "        edges_array = np.array(edges,dtype=int)\n",
    "        # EDGES: type, kind1, kind2, v1, v2\n",
    "        # no relation embedding\n",
    "        edge_embedding = self.edge_lexicon_embedding_eval[self.edge_no_relation].repeat(len(vertices),len(vertices),1)\n",
    "\n",
    "        # add type embedding (gate type)\n",
    "        edge_type_embedding = self.edge_lexicon_embedding_eval[edges_array[:,0]]\n",
    "        edge_embedding[edges_array[:,-2], edges_array[:,-1]] = edge_type_embedding\n",
    "\n",
    "        # non aggregated edges also have \"kind\" = 0,1... (qubit index in input/output)\n",
    "        # select non aggregator edges\n",
    "        non_aggregated_edges = edges_array[ edges_array[:,0]!=self.edge_lexicon.index(\"aggregator\") ]\n",
    "        # calculate edge kind embedding (according to qubit id)\n",
    "        edge_kind_embedding= (self.edge_kind_embeddings_eval[(0,non_aggregated_edges[:,1])] \n",
    "                            + self.edge_kind_embeddings_eval[(1,non_aggregated_edges[:,2])])\n",
    "        # add also kind embedding\n",
    "        edge_embedding[non_aggregated_edges[:,-2], non_aggregated_edges[:,-1]] += edge_kind_embedding\n",
    "        return edge_embedding\n",
    "\n",
    "\n",
    "    def full_circuit_to_VE_embeddings(self, full_circuit):\n",
    "        n_qubits, circuit = full_circuit\n",
    "        \n",
    "        vertices = []\n",
    "        edges = []\n",
    "        \n",
    "        # add aggregator vertex\n",
    "        self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
    "\n",
    "        bindings = self.get_initial_bindings(n_qubits, vertices)\n",
    "        self.get_graph(circuit, bindings, vertices, edges)\n",
    "        \n",
    "        # make vertex list\n",
    "        # sort it\n",
    "        vertex_embedding = self.get_vertex_list_embedding(vertices, n_qubits)\n",
    "        \n",
    "        # add aggregator edges between all vertices\n",
    "        for vertex_2 in vertices[1:]: # start from 1 to exclude aggregate vertex\n",
    "            edges.append((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
    "        \n",
    "        # make edges embedding\n",
    "        edge_embedding = self.get_edge_list_embedding(edges, vertices)\n",
    "        return vertex_embedding, edge_embedding\n",
    "    \n",
    "    # Batch embedding calculation\n",
    "    def full_circuits_to_feature(self, full_circuits):\n",
    "        Vs = []\n",
    "        Es = []\n",
    "        \n",
    "        # Prepare the graph for each circuit\n",
    "        for full_circuit in full_circuits:\n",
    "            vertex_embedding, edge_embedding = self.full_circuit_to_VE_embeddings(full_circuit)\n",
    "            \n",
    "            Vs.append(vertex_embedding)\n",
    "            Es.append(edge_embedding)\n",
    "            \n",
    "        # Pad the sequences in the batch to largest\n",
    "        Vs_padded = torch.nn.utils.rnn.pad_sequence(Vs, batch_first=True)\n",
    "        Es_padded = torch.zeros([Vs_padded.shape[0],Vs_padded.shape[1],Vs_padded.shape[1],Vs_padded.shape[2]])\n",
    "        for i in range(len(Es)):\n",
    "            Es_padded[i,:len(Es[i]),:len(Es[i])] = Es[i]\n",
    "            \n",
    "        # Calculate associated mask\n",
    "        Vs_mask = torch.ones(Vs_padded.shape[0],Vs_padded.shape[1])\n",
    "        for i in range(len(Vs)):\n",
    "            Vs_mask[i,:len(Vs[i])] = 0\n",
    "        \n",
    "        # Batch calculation of embedding by applying the transformer\n",
    "        return gr.feature_extr(Vs_padded, Es_padded, mask=Vs_mask)[:,0] # take only aggregator vertex\n",
    "            \n",
    "    def featuresOfTask(self, t):\n",
    "        return self.featuresOfTasks([t])[0]\n",
    "    \n",
    "    def featuresOfTasks(self, ts):\n",
    "        embeddings = []\n",
    "        for n_qubit in range(self.n_min, self.n_max):\n",
    "            full_circuits = [t.target_algorithm(n_qubit) for t in ts]\n",
    "            embeddings.append(self.full_circuits_to_feature(full_circuits))\n",
    "        \n",
    "        embedding = sum(embeddings)\n",
    "        return dc.recognition.variable(embedding).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:56.180693Z",
     "iopub.status.busy": "2022-04-25T22:50:56.180547Z",
     "iopub.status.idle": "2022-04-25T22:50:56.204326Z",
     "shell.execute_reply": "2022-04-25T22:50:56.203907Z",
     "shell.execute_reply.started": "2022-04-25T22:50:56.180676Z"
    }
   },
   "outputs": [],
   "source": [
    "gr = GreatFeatureExtractor(None,full_op_names, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:51:13.548669Z",
     "iopub.status.busy": "2022-04-25T22:51:13.548371Z",
     "iopub.status.idle": "2022-04-25T22:51:13.580349Z",
     "shell.execute_reply": "2022-04-25T22:51:13.579965Z",
     "shell.execute_reply.started": "2022-04-25T22:51:13.548641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "feature_extractor = GreatFeatureExtractor(None, full_op_names, d_model=128)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar, contextual=True)\n",
    "\n",
    "lr=0.0001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T00:29:23.684184Z",
     "iopub.status.busy": "2022-04-26T00:29:23.683874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [32:45<00:00,  5.09it/s] \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps = 10000\n",
    "\n",
    "gr.feature_extr.train();\n",
    "for _ in trange(n_steps):\n",
    "    programs_batch = random.sample(matched_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    recognition_model.zero_grad()\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:29:04.366585Z",
     "iopub.status.busy": "2022-04-26T19:29:04.366124Z",
     "iopub.status.idle": "2022-04-26T19:29:04.371498Z",
     "shell.execute_reply": "2022-04-26T19:29:04.370951Z",
     "shell.execute_reply.started": "2022-04-26T19:29:04.366535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr.feature_extr.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:29:05.932779Z",
     "iopub.status.busy": "2022-04-26T19:29:05.932539Z",
     "iopub.status.idle": "2022-04-26T19:29:06.088014Z",
     "shell.execute_reply": "2022-04-26T19:29:06.087539Z",
     "shell.execute_reply.started": "2022-04-26T19:29:05.932756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1136/3933 [07:28<18:25,  2.53it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=6'>7</a>\u001b[0m programs_batch \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(testing_programs, batch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=7'>8</a>\u001b[0m tasks_batch \u001b[39m=\u001b[39m [QuantumTask(i,\u001b[39mlambda\u001b[39;00m n_qubit, program\u001b[39m=\u001b[39mprogram: dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mevaluate([])(f_no_op(n_qubit)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=8'>9</a>\u001b[0m                \u001b[39mfor\u001b[39;00m i, program \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(programs_batch)]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=9'>10</a>\u001b[0m embedding \u001b[39m=\u001b[39m recognition_model\u001b[39m.\u001b[39;49mfeatureExtractor\u001b[39m.\u001b[39;49mfeaturesOfTasks(tasks_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=10'>11</a>\u001b[0m simple_programs \u001b[39m=\u001b[39m [dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m program \u001b[39min\u001b[39;00m programs_batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000059vscode-remote?line=11'>12</a>\u001b[0m contextual_grammar \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mContextualGrammar\u001b[39m.\u001b[39mfromGrammar(grammar)\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 50'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.featuresOfTasks\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=182'>183</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_qubit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_min, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_max):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=183'>184</a>\u001b[0m     full_circuits \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mtarget_algorithm(n_qubit) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=184'>185</a>\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_circuits_to_feature(full_circuits))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=186'>187</a>\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(embeddings)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=187'>188</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dc\u001b[39m.\u001b[39mrecognition\u001b[39m.\u001b[39mvariable(embedding)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 50'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.full_circuits_to_feature\u001b[0;34m(self, full_circuits)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=172'>173</a>\u001b[0m     Vs_mask[i,:\u001b[39mlen\u001b[39m(Vs[i])] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=174'>175</a>\u001b[0m \u001b[39m# Batch calculation of embedding by applying the transformer\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg001/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=175'>176</a>\u001b[0m \u001b[39mreturn\u001b[39;00m gr\u001b[39m.\u001b[39;49mfeature_extr(Vs_padded, Es_padded, mask\u001b[39m=\u001b[39;49mVs_mask)[:,\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:288\u001b[0m, in \u001b[0;36mGreat.forward\u001b[0;34m(self, x, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=285'>286</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, relation: Tensor, mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=286'>287</a>\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=287'>288</a>\u001b[0m         x \u001b[39m=\u001b[39m l(x, relation, mask)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:252\u001b[0m, in \u001b[0;36mGreatLayer.forward\u001b[0;34m(self, src, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=239'>240</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src: Tensor, relation: Tensor, mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=240'>241</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Pass the input through the encoder layer.\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=241'>242</a>\u001b[0m \n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=242'>243</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=249'>250</a>\u001b[0m \u001b[39m        see the docs in Transformer class.\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=250'>251</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=251'>252</a>\u001b[0m     src2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(src, src, src, relation, attn_mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=252'>253</a>\u001b[0m                           key_padding_mask\u001b[39m=\u001b[39;49mmask)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=253'>254</a>\u001b[0m     src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(src2)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=254'>255</a>\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(src)\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:186\u001b[0m, in \u001b[0;36mMultiheadAttentionRelation.forward\u001b[0;34m(self, query, key, value, relation, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=181'>182</a>\u001b[0m \u001b[39m# incorporate relation\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=182'>183</a>\u001b[0m \u001b[39m# masking does not matter because we will handle it later\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=183'>184</a>\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m) \u001b[39m+\u001b[39m r\u001b[39m.\u001b[39mview(B, L, L, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=185'>186</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meinsum(\u001b[39m'\u001b[39;49m\u001b[39mbqkhe,bkhe->bqkh\u001b[39;49m\u001b[39m'\u001b[39;49m, q, k)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=186'>187</a>\u001b[0m a \u001b[39m=\u001b[39m a \u001b[39m/\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=188'>189</a>\u001b[0m \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/functional.py:330\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/functional.py?line=325'>326</a>\u001b[0m     \u001b[39m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[1;32m    <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/functional.py?line=326'>327</a>\u001b[0m     \u001b[39m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[1;32m    <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/functional.py?line=327'>328</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[0;32m--> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/functional.py?line=329'>330</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps_test = int(len(testing_programs)/batch_size)\n",
    "\n",
    "gr.feature_extr.eval();\n",
    "test_losses = []\n",
    "for _ in trange(n_steps_test):\n",
    "    programs_batch = random.sample(testing_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() \n",
    "    test_losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test dataset: 45.38146969298242\n",
      "Last training losses: 16.449935665130614\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performance on test dataset: {np.mean(test_losses)}\")\n",
    "print(f\"Last training losses: {np.mean(losses[-50:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:23.299842Z",
     "iopub.status.busy": "2022-04-26T18:19:23.299363Z",
     "iopub.status.idle": "2022-04-26T18:19:23.380903Z",
     "shell.execute_reply": "2022-04-26T18:19:23.380458Z",
     "shell.execute_reply.started": "2022-04-26T18:19:23.299794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29.1121815835177, tensor([-22.6289], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8000 # program we are testing\n",
    "task = QuantumTask(i,lambda n_qubit, program=matched_programs[i]: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "code =  dc.program.Program.parse(matched_programs[i][1])\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:25.164529Z",
     "iopub.status.busy": "2022-04-26T18:19:25.164279Z",
     "iopub.status.idle": "2022-04-26T18:19:25.188522Z",
     "shell.execute_reply": "2022-04-26T18:19:25.188119Z",
     "shell.execute_reply.started": "2022-04-26T18:19:25.164509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     ┌───┐     ┌───┐               \n",
      "q_0: ┤ H ├──■──┤ X ├───────────────\n",
      "     ├───┤┌─┴─┐└─┬─┘┌───┐     ┌───┐\n",
      "q_1: ┤ H ├┤ X ├──■──┤ H ├──■──┤ X ├\n",
      "     ├───┤└───┘     └───┘┌─┴─┐└─┬─┘\n",
      "q_2: ┤ H ├───────────────┤ X ├──■──\n",
      "     └───┘               └───┘     \n",
      "q_3: ──────────────────────────────\n",
      "                                   \n",
      "             ┌───┐        ┌───┐\n",
      "q_0: ──■───X─┤ H ├──■───X─┤ H ├\n",
      "     ┌─┴─┐ │ └───┘  │   │ └───┘\n",
      "q_1: ┤ X ├─┼────────┼───X──────\n",
      "     └───┘ │      ┌─┴─┐        \n",
      "q_2: ──────X──────┤ X ├────────\n",
      "                  └───┘        \n",
      "q_3: ──────────────────────────\n",
      "                               \n"
     ]
    }
   ],
   "source": [
    "print_circuit(dc.program.Program.parse(matched_programs[i][1]).evaluate([])(no_op(4)))\n",
    "print_circuit(dc.program.Program.parse(matched_programs[i][0]).evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:37:45.516189Z",
     "iopub.status.busy": "2022-04-26T19:37:45.515743Z",
     "iopub.status.idle": "2022-04-26T19:37:45.562522Z",
     "shell.execute_reply": "2022-04-26T19:37:45.562092Z",
     "shell.execute_reply.started": "2022-04-26T19:37:45.516161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.317766166719343, tensor([-5.9396], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (mv(minv( $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:26.677832Z",
     "iopub.status.busy": "2022-04-26T18:19:26.677368Z",
     "iopub.status.idle": "2022-04-26T18:19:26.714873Z",
     "shell.execute_reply": "2022-04-26T18:19:26.714468Z",
     "shell.execute_reply.started": "2022-04-26T18:19:26.677784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.635532333438686, tensor([-21.4344], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot  $0))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T20:04:03.555071Z",
     "iopub.status.busy": "2022-04-26T20:04:03.554552Z",
     "iopub.status.idle": "2022-04-26T20:04:03.597859Z",
     "shell.execute_reply": "2022-04-26T20:04:03.597393Z",
     "shell.execute_reply.started": "2022-04-26T20:04:03.555019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-56.838068805915505, tensor([-67.8985], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) )  $0 )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.logLikelihood(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    batch_size = 32\n",
    "    n_steps = 1000\n",
    "\n",
    "    gr.feature_extr.train();\n",
    "    for _ in trange(n_steps):\n",
    "        programs_batch = random.sample(matched_programs, batch_size)\n",
    "        tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                    for i, program in enumerate(programs_batch)]\n",
    "        embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "        simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "        contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "        \n",
    "        summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "        \n",
    "        # if not using contextual grammar\n",
    "        # summaries = [grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recognition_model.zero_grad()\n",
    "        \n",
    "        features = recognition_model._MLP(embedding)\n",
    "        lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "        loss = -lls.mean() \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:20<07:57,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 2.77232 s\n",
      "File: /tmp/ipykernel_5224/1500948551.py\n",
      "Function: full_circuit_to_embeddings at line 126\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   126                                               def full_circuit_to_embeddings(self, full_circuit):\n",
      "   127      4032       7131.0      1.8      0.3          n_qubits, circuit = full_circuit\n",
      "   128                                                   \n",
      "   129      4032       6016.0      1.5      0.2          vertices = set()\n",
      "   130      4032       3139.0      0.8      0.1          edges = set()\n",
      "   131                                                   \n",
      "   132                                                   # add aggregator vertex\n",
      "   133      4032      19337.0      4.8      0.7          self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
      "   134                                           \n",
      "   135      4032      45828.0     11.4      1.7          bindings = self.get_initial_bindings(n_qubits, vertices)\n",
      "   136      4032     489074.0    121.3     17.6          self.get_graph(circuit, bindings, vertices, edges)\n",
      "   137                                                   \n",
      "   138                                                   # make vertex list\n",
      "   139                                                   # sort it\n",
      "   140      4032      32831.0      8.1      1.2          vertex_list = sorted(list(vertices), key=lambda vertex: vertex[0])\n",
      "   141      4032     332576.0     82.5     12.0          vertex_embedding = self.get_vertex_list_embedding(vertex_list, n_qubits)\n",
      "   142                                                   \n",
      "   143                                                   # add aggregator edges between all vertices\n",
      "   144     52278      45104.0      0.9      1.6          for vertex_2 in vertex_list[1:]:\n",
      "   145     48246      61617.0      1.3      2.2              edges.add((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
      "   146                                                   \n",
      "   147                                                   # make edges embedding\n",
      "   148      4032    1723674.0    427.5     62.2          edge_embedding = self.get_edge_list_embedding(list(edges), vertex_list)\n",
      "   149      4032       5998.0      1.5      0.2          return vertex_embedding, edge_embedding\n",
      "   150                                                   # return self.feature_extr(vertex_embedding[None], edge_embedding[None])[0][0] # squeeze and take aggregate vertex"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f gr.full_circuit_to_embeddings train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Try to merge two low-level programs and see if we find one solution in the full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - X Split training/test dataset\n",
    "# - X Fix dataset augmentation by removing EMBED gate when not needed\n",
    "# - X Fix graph generation with aggregator edges (all vertices connected to AGGREGATOR!)\n",
    "# - X Masking to allow batch processing (1=masked, 0=allowed)\n",
    "# - Refactor notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v[\"task\"] for v in restricted_dictionary.values()], len(restricted_dictionary)\n",
    "[v[\"task\"] for v in full_dictionary.values()], len(full_dictionary)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21ea1a886259afbd8a118ef6898db29b8a19fae78d92613d0ae3d877be73df6a"
  },
  "kernelspec": {
   "display_name": "dc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
