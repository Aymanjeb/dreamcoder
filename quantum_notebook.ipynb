{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "import dreamcoder as dc\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_qubit = 2\n",
    "full_circuit = [n_qubit,\n",
    "           [[\"cnot\", 0, 1],\n",
    "           [\"swap\", 0, 1],\n",
    "           [\"hadamard\", 1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -1, 3], [['cnot', 1, 0]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(n_qubit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h (no_op $0)))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (no_op $0)))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -7.783640596221253)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -15.567281192442506)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv (no_op $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(2)),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(3)) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(2)) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -14.155496613885283)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size_to_int $0))) (lambda (mv $0))) (no_op $0))))\")\n",
    "code.evaluate([])(3)\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -52.145060152057745)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(5))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(5))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 5],\n",
       " [['swap', 0, 1],\n",
       "  ['swap', 1, 2],\n",
       "  ['swap', 2, 3],\n",
       "  ['swap', 3, 4],\n",
       "  ['swap', 2, 3],\n",
       "  ['swap', 1, 2]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.evaluate([])(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9023 --control=9021 --hb=9020 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"4cb5eb83-e838-4fe0-a4a8-4506e04e814d\" --shell=9022 --transport=\"tcp\" --iopub=9024 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-54657SX5ZpwcBlRtD.json\n",
      "Running EC on 01-mar-grp-0020 @ 2022-03-08 17:21:15.619996 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  500\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  python\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 201879552\n",
      "Currently using this much memory: 201883648\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 500.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 499.974098.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 499.944821.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 499.901035.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 499.803395.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 499.664259.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 498.930671.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 496.257107.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 12.000000 <= MDL < 13.500000. Timeout 484.440078.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 13.500000 <= MDL < 15.000000. Timeout 443.864152.\n",
      "(frontend) Launching tsize -> tcircuit (15 tasks) w/ 8 CPUs. 15.000000 <= MDL < 16.500000. Timeout 290.974542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 17.6378 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/tasks.py\n",
      "Function: logLikelihood at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                               def logLikelihood(self, e, timeout=None):\n",
      "    22    912398     552896.0      0.6      3.1          if QuantumTask.last_algorithm is not e:\n",
      "    23     57970      67900.0      1.2      0.4              QuantumTask.last_algorithm = e\n",
      "    24     57970      59239.0      1.0      0.3              QuantumTask.last_algorithm_evaluations = {}\n",
      "    25                                           \n",
      "    26    914625     803899.0      0.9      4.6          for n in range(self.min_size, self.max_size):\n",
      "    27    914568     616811.0      0.7      3.5              if n not in QuantumTask.last_algorithm_evaluations.keys():\n",
      "    28     60140    9599297.0    159.6     54.4                  QuantumTask.last_algorithm_evaluations[n] = execute_quantum_algorithm(e, n, timeout)\n",
      "    29                                           \n",
      "    30    914568     460415.0      0.5      2.6              yh = QuantumTask.last_algorithm_evaluations[n]\n",
      "    31    914568     541759.0      0.6      3.1              yh_true = self.target_algorithm_evaluations[n]\n",
      "    32                                           \n",
      "    33    914568     381355.0      0.4      2.2              if yh is None:\n",
      "    34    626129     314727.0      0.5      1.8                  return dc.utilities.NEGATIVEINFINITY\n",
      "    35                                                       \n",
      "    36                                                       \n",
      "    37                                                       ## THIS IS THE BOTTLENECK! \n",
      "    38                                                       # if not np.allclose(yh, yh_true):\n",
      "    39                                                       #     return dc.utilities.NEGATIVEINFINITY\n",
      "    40    288439    4014005.0     13.9     22.8              if not np.all(np.abs(yh-yh_true)<= 1e-5):\n",
      "    41    286212     225430.0      0.8      1.3                  return dc.utilities.NEGATIVEINFINITY\n",
      "    42                                                           \n",
      "    43                                                       # return dc.utilities.NEGATIVEINFINITY\n",
      "    44                                            \n",
      "    45                                                       # try:\n",
      "    46                                                       #     np.testing.assert_almost_equal(yh, yh_true, decimal=5)\n",
      "    47                                                       # except AssertionError:\n",
      "    48                                                       #     return dc.utilities.NEGATIVEINFINITY\n",
      "    49        57         45.0      0.8      0.0          return 0."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=3600,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"python\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=500,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n",
    "%lprun -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid repetition number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_12129/3624976763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(lambda ((rep (dec(dec(dec 0))) (lambda (mv $0))) (no_op $0)))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbetaReduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalseBranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minferType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeVariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/program.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalseBranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minferType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeVariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/utilities.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCurried\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36m_repeat\u001b[0;34m(n_times, body)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_times\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid repetition number.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0;32mreturn\u001b[0m   \u001b[0m_repeat_help\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Invalid repetition number."
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (dec(dec(dec 0))) (lambda (mv $0))) (no_op $0)))\")\n",
    "code.evaluate([])(3)\n",
    "code.infer()\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting implementation of Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuationtype = tcircuit\n",
    "#avoid  no _ op \n",
    "\n",
    "# GREAT  graph relational transformer\n",
    "\n",
    "# Probabilistic CFG "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Free Grammar\n",
    "\n",
    "quantized grammar\n",
    "\n",
    "--> Create dataset (U, high level program)\n",
    "Recognition network proposes the likelihood of low level program generating U\n",
    "contextual -> bigrams\n",
    "\n",
    "--> create new train function for the recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_grammar(grammar, timeout, circuit_execution_function): #circuit execution function either full_circuit_to_mat or state_circuit_to_mat\n",
    "    pcfg =  dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "    enum_dictionary = {}\n",
    "    t_0 = time.time()\n",
    "    for i in pcfg.quantized_enumeration():\n",
    "        if (time.time()>t_0+timeout): break\n",
    "    \n",
    "        code = dc.program.Program.parse(str(i))\n",
    "        \n",
    "        # check if it is a valid circuit\n",
    "        try:\n",
    "            circuit = code.evaluate([])(3)\n",
    "            unitary = circuit_execution_function(circuit)\n",
    "            enum_dictionary[str(unitary)]={\"task\":str(code), \"circuit_3\":circuit}\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "    eprint(f\"Enumerated {len(enum_dictionary)} programs\")\n",
    "    return enum_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda (mv (mv 0))), (lambda (h 0)), (lambda (mv (mv_r 0))), (lambda (cnot 0)), (lambda (mv (minv 0))), (lambda (rep 2 (lambda 3) 0)), (lambda (mv (no_op 1))), (lambda (mv (h 0))), (lambda (mv (cnot 0))), (lambda (mv (rep 2 (lambda 3) 0))), (lambda (mv_r 0)), (lambda (minv 0)), (lambda (no_op 1))]\n",
      "Enumerated 432 programs\n",
      "[(lambda (fh (fno_op 1) 2)), (lambda (fh (fh 0 2) 2)), (lambda (fh (fcnot 0 2 2) 2)), (lambda (fh (fswap 0 2 2) 2)), (lambda (fh 0 0)), (lambda (fh 0 (inc 2))), (lambda (fh 0 (dec 2))), (lambda (fh 0 (size_to_int 1))), (lambda (fcnot 0 2 2)), (lambda (fswap 0 2 2))]\n",
      "Enumerated 269 programs\n"
     ]
    }
   ],
   "source": [
    "restricted_dictionary = enumerate_grammar(grammar,timeout=60, circuit_execution_function=state_circuit_to_mat)\n",
    "full_dictionary = enumerate_grammar(full_grammar,timeout=60, circuit_execution_function=full_circuit_to_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerated 23 programs\n"
     ]
    }
   ],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(4))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(4))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, restricted_task])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"matched_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [3,4]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, [['hadamard', 2], ['hadamard', 2], ['hadamard', 1]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(matched_programs[0][0]).evaluate([])(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar)\n",
    "lr=0.001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "task = QuantumTask(\"generated_task\", lambda n_qubit:dc.program.Program.parse(matched_programs[i][0]).evaluate([])(n_qubit))\n",
    "simple_program = dc.program.Program.parse(matched_programs[i][1])\n",
    "summary = grammar.closedLikelihoodSummary(simple_program.infer(),simple_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = recognition_model.featureExtractor.featuresOfTask(tasks[0])\n",
    "feature = recognition_model._MLP(embedding)\n",
    "features = feature.expand(1, feature.size(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "recognition_model.zero_grad()\n",
    "lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, [summary])\n",
    "loss = -lls.max()\n",
    "loss.backward(retain_graph=True)\n",
    "optimizer.step()\n",
    "losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3282,  0.3197, -0.2162,  0.3532,  0.3219, -1.0270,  0.3279, -0.6923,\n",
       "        -0.6563,  0.6296,  0.3022, -0.3592], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognition_model.grammarBuilder.logProductions(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grammar_of_task = recognition_model(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# profile running time, enumeration speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_quantum(matched_dictionary={unitaries: simple_program, complicated_list},)\n",
    "# for each sample\n",
    "#     embedding= feature_extractor([unitary, complicated_list]) (i.e. encoder)  #in the case of great we first need an embedding and here we get the final embedding\n",
    "    \n",
    "#     # apply the recognition model\n",
    "#     [from frontierBiasOptimal]\n",
    "#     features = self._MLP(features)\n",
    "#     features = features.expand(batchSize, features.size(-1))  # TODO\n",
    "#     lls = self.grammarBuilder.batchedLogLikelihoods(features, [simple_program])\n",
    "        \n",
    "#     # train (optimize -lls  adam)\n",
    "#     lls.backward\n",
    "    \n",
    "# # look at the new likelihoods\n",
    "#     recognitionmodel.grammarOfTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more enumerated tasks (10k)\n",
    "\n",
    "# bags of words (Gates) e.g. number of occurrences for each gate\n",
    "# great https://github.com/google-research/crossbeam/blob/main/crossbeam/model/great.py\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3b58914974b8dde835498c747ea4f1aaf3fb4cb185c0609e0c7a19c91a9bce2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
