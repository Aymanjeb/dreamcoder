{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:07.396057Z",
     "iopub.status.busy": "2022-04-26T18:19:07.395857Z",
     "iopub.status.idle": "2022-04-26T18:19:07.402513Z",
     "shell.execute_reply": "2022-04-26T18:19:07.401897Z",
     "shell.execute_reply.started": "2022-04-26T18:19:07.396033Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dreamcoder as dc\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:46.815077Z",
     "iopub.status.busy": "2022-04-25T18:28:46.814683Z",
     "iopub.status.idle": "2022-04-25T18:28:46.817838Z",
     "shell.execute_reply": "2022-04-25T18:28:46.817473Z",
     "shell.execute_reply.started": "2022-04-25T18:28:46.815035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (('cnot', 0, 1), ('swap', 0, 1), ('hadamard', 1)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit = 2\n",
    "full_circuit = (n_qubit,\n",
    "           ((\"cnot\", 0, 1),\n",
    "           (\"swap\", 0, 1),\n",
    "           (\"hadamard\", 1))\n",
    ")\n",
    "full_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:47.410256Z",
     "iopub.status.busy": "2022-04-25T18:28:47.409861Z",
     "iopub.status.idle": "2022-04-25T18:28:47.415882Z",
     "shell.execute_reply": "2022-04-25T18:28:47.415468Z",
     "shell.execute_reply.started": "2022-04-25T18:28:47.410236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:58.544879Z",
     "iopub.status.busy": "2022-04-25T18:28:58.544688Z",
     "iopub.status.idle": "2022-04-25T18:28:58.549754Z",
     "shell.execute_reply": "2022-04-25T18:28:58.549327Z",
     "shell.execute_reply.started": "2022-04-25T18:28:58.544856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.176362Z",
     "iopub.status.busy": "2022-04-25T18:28:59.175938Z",
     "iopub.status.idle": "2022-04-25T18:28:59.490576Z",
     "shell.execute_reply": "2022-04-25T18:28:59.490076Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.176338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.875600Z",
     "iopub.status.busy": "2022-04-25T18:28:59.875358Z",
     "iopub.status.idle": "2022-04-25T18:28:59.886662Z",
     "shell.execute_reply": "2022-04-25T18:28:59.886239Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.875580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:01.068751Z",
     "iopub.status.busy": "2022-04-25T18:29:01.068535Z",
     "iopub.status.idle": "2022-04-25T18:29:01.072992Z",
     "shell.execute_reply": "2022-04-25T18:29:01.072599Z",
     "shell.execute_reply.started": "2022-04-25T18:29:01.068732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(no_op(n_qubit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T23:20:35.960776Z",
     "iopub.status.busy": "2022-04-25T23:20:35.960513Z",
     "iopub.status.idle": "2022-04-25T23:20:35.965165Z",
     "shell.execute_reply": "2022-04-25T23:20:35.964700Z",
     "shell.execute_reply.started": "2022-04-25T23:20:35.960751Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h $0))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot $0))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -8.317766166719343)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))\")\n",
    "code.evaluate([])(no_op(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding primitive\n",
    "code = dc.program.Program.parse(\"(lambda (mv (emb (lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))  $0 )))\")\n",
    "\n",
    "code.evaluate([])(no_op(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv $0)))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(no_op(2))),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(3))) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(2))) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size $0))) (lambda (mv $0))) $0)))\")\n",
    "code.evaluate([])(no_op(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -56.838068805915505)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) $0 )))))\")\n",
    "print_circuit(code.evaluate([])(no_op(3)))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) ) $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) )  $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile bottom-up enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1536060b-098c-4fd5-b891-f22aa0311306\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-23320Afm1Zw1Bm3I3.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"bottom\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-04-03 20:06:17.653038 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  bottom\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 208424960\n",
      "Currently using this much memory: 208429056\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching int -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 6.000000. Timeout 6.000000.\n",
      "PANIC! Exception in child worker: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 243, in _f\n",
      "    r = f(*a, **k)\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 407, in solveForTask_bottom\n",
      "    compile_me=False,\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/utilities.py\", line 404, in callCompiled\n",
      "    stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 800, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 1551, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_23556/2686176463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     41\u001b[0m                            \u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                            **arguments)\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mecIterator\u001b[0;34m(grammar, tasks, _, useDSL, noConsolidation, mask, seed, addFullTaskMetrics, matrixRank, solver, compressor, biasOptimal, contextual, testingTasks, iterations, resume, enumerationTimeout, testingTimeout, testEvery, reuseRecognition, ensembleSize, useRecognitionModel, recognitionTimeout, recognitionSteps, helmholtzRatio, featureExtractor, activation, topK, topk_use_only_likelihood, use_map_search_times, maximumFrontier, pseudoCounts, aic, structurePenalty, arity, evaluationTimeout, taskBatchSize, taskReranker, CPUs, cuda, message, outputPrefix, storeTaskMetrics, rewriteTaskMetrics, auxiliaryLoss, custom_wake_generative)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                                       \u001b[0menumerationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menumerationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                                                       \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                                                       evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSearchTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mdefault_wake_generative\u001b[0;34m(grammar, tasks, maximumFrontier, enumerationTimeout, CPUs, solver, evaluationTimeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m                                                    \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                                                    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                                                    evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generative model enumeration results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrontier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopDownFrontiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\u001b[0m in \u001b[0;36mmulticoreEnumeration\u001b[0;34m(g, tasks, _, enumerationTimeout, solver, CPUs, maximumFrontier, verbose, evaluationTimeout, testing)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PANIC! Exception in child worker:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"success\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Mark the CPUs is no longer being used and pause the stopwatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\n",
    "main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -13.862943611198904)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (inc(inc(dec 0))) (lambda (mv $0))) $0))\")\n",
    "code.evaluate([])(no_op(5))\n",
    "code.infer()\n",
    "tasks[0].logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:57.433325Z",
     "iopub.status.busy": "2022-04-25T18:29:57.432928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pcfg compilation: distinct non terminals 2 ; distinct environments 2\n",
      "start symbol: (tcircuit, (tcircuit,))\n",
      "\n",
      "(tcircuit, (tcircuit,)) ::= mv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= mv_r\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= minv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= h\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= cnot\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= rep\t0x(int, (tcircuit,)) 1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= emb\t1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= $0\t\t\t-2.0794415416798357\n",
      "\n",
      "(int, (tcircuit,)) ::= 0\t\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= inc\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= dec\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= size\t0x(tcircuit, (tcircuit,))\t\t-1.3862943611198906\n",
      "[(lambda 0)]\n",
      " -- Bottom up enumeration, cost 0\n",
      " -- Bottom up enumeration, cost 1\n",
      " -- Bottom up enumeration, cost 2\n",
      " -- Bottom up enumeration, cost 3\n",
      " -- Bottom up enumeration, cost 4\n",
      " -- Bottom up enumeration, cost 5\n",
      " -- Bottom up enumeration, cost 6\n",
      " -- Bottom up enumeration, cost 7\n",
      " -- Bottom up enumeration, cost 8\n",
      " -- Bottom up enumeration, cost 9\n",
      " -- Bottom up enumeration, cost 10\n",
      " -- Bottom up enumeration, cost 11\n",
      " -- Bottom up enumeration, cost 12\n",
      " -- Bottom up enumeration, cost 13\n",
      " -- Bottom up enumeration, cost 14\n",
      " -- Bottom up enumeration, cost 15\n",
      " -- Bottom up enumeration, cost 16\n",
      " -- Bottom up enumeration, cost 17\n",
      " -- Bottom up enumeration, cost 18\n",
      " -- Bottom up enumeration, cost 19\n",
      " -- Bottom up enumeration, cost 20\n",
      " -- Bottom up enumeration, cost 21\n",
      " -- Bottom up enumeration, cost 22\n",
      " -- Bottom up enumeration, cost 23\n",
      " -- Bottom up enumeration, cost 24\n",
      " -- Bottom up enumeration, cost 25\n",
      " -- Bottom up enumeration, cost 26\n",
      " -- Bottom up enumeration, cost 27\n",
      " -- Bottom up enumeration, cost 28\n",
      " -- Bottom up enumeration, cost 29\n",
      " -- Bottom up enumeration, cost 30\n",
      " -- Bottom up enumeration, cost 31\n",
      " -- Bottom up enumeration, cost 32\n",
      " -- Bottom up enumeration, cost 33\n",
      " -- Bottom up enumeration, cost 34\n",
      " -- Bottom up enumeration, cost 35\n",
      " -- Bottom up enumeration, cost 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m restricted_pcfg \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mPCFG\u001b[39m.\u001b[39mfrom_grammar(grammar, request\u001b[39m=\u001b[39mdc\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39marrow(tcircuit, tcircuit))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m restricted_dictionary \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49menumeration\u001b[39m.\u001b[39;49menumerate_pcfg(restricted_pcfg,timeout\u001b[39m=\u001b[39;49m\u001b[39m3600\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m                                                       circuit_execution_function\u001b[39m=\u001b[39;49mstate_circuit_to_mat,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=3'>4</a>\u001b[0m                                                       no_op\u001b[39m=\u001b[39;49mno_op,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=4'>5</a>\u001b[0m                                                       observational_equivalence\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=5'>6</a>\u001b[0m                                                       sound\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py:656\u001b[0m, in \u001b[0;36menumerate_pcfg\u001b[0;34m(pcfg, timeout, circuit_execution_function, no_op, observational_equivalence, sound)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=652'>653</a>\u001b[0m n_min \u001b[39m=\u001b[39m QuantumTask\u001b[39m.\u001b[39mmin_size\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=653'>654</a>\u001b[0m n_max \u001b[39m=\u001b[39m  QuantumTask\u001b[39m.\u001b[39mmax_size\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=655'>656</a>\u001b[0m \u001b[39mfor\u001b[39;00m code \u001b[39min\u001b[39;00m pcfg\u001b[39m.\u001b[39mquantized_enumeration(observational_equivalence\u001b[39m=\u001b[39mobservational_equivalence,\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=656'>657</a>\u001b[0m                                        inputs\u001b[39m=\u001b[39m[[no_op(\u001b[39m3\u001b[39m)],[no_op(\u001b[39m4\u001b[39m)]],\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=657'>658</a>\u001b[0m                                        sound\u001b[39m=\u001b[39msound):\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=658'>659</a>\u001b[0m     \u001b[39mif\u001b[39;00m (time\u001b[39m.\u001b[39mtime()\u001b[39m>\u001b[39mt_0\u001b[39m+\u001b[39mtimeout): \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=659'>660</a>\u001b[0m     \u001b[39m# check if it is a valid circuit\u001b[39;00m\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1902\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration\u001b[0;34m(self, resolution, skeletons, observational_equivalence, sound, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1899'>1900</a>\u001b[0m eprint(\u001b[39m\"\u001b[39m\u001b[39m -- Bottom up enumeration, cost\u001b[39m\u001b[39m\"\u001b[39m, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1900'>1901</a>\u001b[0m \u001b[39mfor\u001b[39;00m skeleton, skeleton_cost \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(skeletons, skeleton_costs):\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1901'>1902</a>\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m complete_skeleton(cost\u001b[39m-\u001b[39mskeleton_cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1902'>1903</a>\u001b[0m         \u001b[39myield\u001b[39;00m e\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1884\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1881'>1882</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete_skeleton\u001b[39m(cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1882'>1883</a>\u001b[0m     \u001b[39mif\u001b[39;00m skeleton\u001b[39m.\u001b[39misAbstraction:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1883'>1884</a>\u001b[0m         \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m complete_skeleton(cost, skeleton\u001b[39m.\u001b[39mbody):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1884'>1885</a>\u001b[0m             \u001b[39myield\u001b[39;00m Abstraction(b)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1885'>1886</a>\u001b[0m     \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misApplication:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1892\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1889'>1890</a>\u001b[0m                 \u001b[39myield\u001b[39;00m Application(f, x)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1890'>1891</a>\u001b[0m \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misNamedHole:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1891'>1892</a>\u001b[0m     \u001b[39myield from\u001b[39;00m expressions_of_size(skeleton\u001b[39m.\u001b[39;49mname, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1892'>1893</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1893'>1894</a>\u001b[0m     \u001b[39mif\u001b[39;00m cost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1865\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.expressions_of_size\u001b[0;34m(symbol, size)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1862'>1863</a>\u001b[0m accepted_new \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1863'>1864</a>\u001b[0m \u001b[39mfor\u001b[39;00m proposed_expression \u001b[39min\u001b[39;00m new:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1864'>1865</a>\u001b[0m     key \u001b[39m=\u001b[39m test_generator\u001b[39m.\u001b[39;49mcompute_signature(proposed_expression,\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1865'>1866</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_type[symbol],\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1866'>1867</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfree_variable_types[symbol])\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1868'>1869</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m equivalences[symbol]:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1869'>1870</a>\u001b[0m         equivalences[symbol][key] \u001b[39m=\u001b[39m proposed_expression\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:92\u001b[0m, in \u001b[0;36mSloppy.compute_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_signature\u001b[39m(\u001b[39mself\u001b[39m, expression, tp, arguments):\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=91'>92</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msound_signature(expression, tp, arguments)\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=93'>94</a>\u001b[0m     outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=94'>95</a>\u001b[0m     \u001b[39mfor\u001b[39;00m test_input \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_inputs(arguments):\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:86\u001b[0m, in \u001b[0;36mSloppy.sound_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=83'>84</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=84'>85</a>\u001b[0m \u001b[39m#eprint(\"output\", tuple(outputs))\u001b[39;00m\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(o \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m outputs):\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=86'>87</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tcircuit, tcircuit))\n",
    "restricted_dictionary = dc.enumeration.enumerate_pcfg(restricted_pcfg,timeout=3600, \n",
    "                                                      circuit_execution_function=state_circuit_to_mat,\n",
    "                                                      no_op=no_op,\n",
    "                                                      observational_equivalence=True,\n",
    "                                                      sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tcircuit_full, tcircuit_full))\n",
    "full_dictionary = dc.enumeration.enumerate_pcfg(full_pcfg,\n",
    "                                                timeout=3600, \n",
    "                                                circuit_execution_function=full_circuit_to_mat,\n",
    "                                                no_op=f_no_op,\n",
    "                                                observational_equivalence=True,\n",
    "                                                sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(f_no_op(4)))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(no_op(4)))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "    # else: print(full_dictionary[unitary][\"task\"])\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m code \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(\u001b[39mlist\u001b[39m(full_dictionary\u001b[39m.\u001b[39mvalues())[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=1'>2</a>\u001b[0m print_circuit(code\u001b[39m.\u001b[39mevaluate([])(f_no_op(\u001b[39m4\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(list(full_dictionary.values())[-1][\"task\"])\n",
    "print_circuit(code.evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          \n",
      "q_0: ─────\n",
      "          \n",
      "q_1: ─────\n",
      "     ┌───┐\n",
      "q_2: ┤ H ├\n",
      "     └───┘\n",
      "q_3: ─────\n",
      "          \n",
      "q_4: ─────\n",
      "     ┌───┐\n",
      "q_5: ┤ H ├\n",
      "     └───┘\n"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda (fh (fh $0 (inc (inc 0))) (dec (fsize $0))))\")\n",
    "print_circuit(code.evaluate([])(f_no_op(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_programs(str_e1, str_e2, reset_state=True): # embed to reset state (i.e. if restricted_set)\n",
    "    if reset_state:\n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "        state_changed = 0\n",
    "        for n_qubit in range(QuantumTask.min_size,  QuantumTask.max_size):\n",
    "            if e1.evaluate([])(no_op(n_qubit))[0][0] !=0:\n",
    "                state_changed +=1\n",
    "        if state_changed:\n",
    "            e1 = dc.program.Program.parse(f\"(lambda (emb {str_e1} $0))\") # if it is already at the beginning do not embed\n",
    "\n",
    "    else: \n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "    e2 = dc.program.Program.parse(str_e2)\n",
    "\n",
    "    return dc.program.Abstraction(\n",
    "        dc.program.Application(e2,\n",
    "        dc.program.Application(e1, dc.program.Index(0)))\n",
    "    ).betaNormalForm(reduceInventions=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_timeout = 10\n",
    "time_0 = time.time()\n",
    "merged_programs = []\n",
    "for i in range(len(matched_programs)):\n",
    "    for j in range(len(matched_programs)):\n",
    "        ii = np.random.randint(0,len(matched_programs))\n",
    "        jj = np.random.randint(0,len(matched_programs))\n",
    "        if (time.time()>time_0+merging_timeout): break\n",
    "        \n",
    "        full_program = merge_two_programs(matched_programs[ii][0], matched_programs[jj][0], reset_state=False)\n",
    "        restricted_program = merge_two_programs(matched_programs[ii][1], matched_programs[jj][1], reset_state=True)\n",
    "        merged_programs.append([\n",
    "            str(full_program),\n",
    "            str(restricted_program),\n",
    "            -1\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_program = merge_two_programs(matched_programs[i][1], matched_programs[j][1], reset_state=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_e1 = matched_programs[i][1]\n",
    "e1 = dc.program.Program.parse(str_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1, 5),\n",
       " (('hadamard', 0),\n",
       "  ('cnot', 0, 1),\n",
       "  ('hadamard', 0),\n",
       "  ('cnot', 0, 1),\n",
       "  ('cnot', 3, 4),\n",
       "  ('hadamard', 3)))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.evaluate([])(no_op(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_programs = matched_programs + merged_programs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"training_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(dataset_programs, f)\n",
    "    \n",
    "with open(save_path+\"_matched\",\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)\n",
    "    \n",
    "with open(save_path+\"_restricted\",\"wb\") as f:\n",
    "    pickle.dump(restricted_dictionary, f)\n",
    "    \n",
    "with open(save_path+\"_full\",\"wb\") as f:\n",
    "    pickle.dump(full_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened dictionary with 4.05e+05 restricted programs and 1.04e+06 high-level programs\n",
      "Opened file with 1527579 programs\n"
     ]
    }
   ],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        dataset_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_matched\",\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_restricted\",\"rb\") as f:\n",
    "        restricted_dictionary = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_full\",\"rb\") as f:\n",
    "        full_dictionary = pickle.load(f)\n",
    "        \n",
    "print(f\"Opened dictionary with {len(restricted_dictionary):1.2e} restricted programs and {len(full_dictionary):1.2e} high-level programs\")\n",
    "print(f\"Opened file with {len(dataset_programs)} programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset in 1374821 training programs and 152758 testing programs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(dataset_programs)\n",
    "training_split = int(0.9*len(dataset_programs))\n",
    "training_programs = dataset_programs[:training_split]\n",
    "testing_programs = dataset_programs[training_split:]\n",
    "print(f\"Split dataset in {len(training_programs)} training programs and {len(testing_programs)} testing programs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractors for Recognition Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:47.800176Z",
     "iopub.status.busy": "2022-04-25T22:50:47.799722Z",
     "iopub.status.idle": "2022-04-25T22:50:47.805016Z",
     "shell.execute_reply": "2022-04-25T22:50:47.804479Z",
     "shell.execute_reply.started": "2022-04-25T22:50:47.800125Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import dreamcoder.great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [3,5]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GREAT feature for recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:54.744552Z",
     "iopub.status.busy": "2022-04-25T22:50:54.744330Z",
     "iopub.status.idle": "2022-04-25T22:50:54.768748Z",
     "shell.execute_reply": "2022-04-25T22:50:54.768221Z",
     "shell.execute_reply.started": "2022-04-25T22:50:54.744526Z"
    }
   },
   "outputs": [],
   "source": [
    "class GreatFeatureExtractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, tasks, full_op_names, d_model):\n",
    "        super(GreatFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        # number of qubits of the circuits to consider \n",
    "        self.n_min = QuantumTask.min_size\n",
    "        self.n_max =  QuantumTask.max_size\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = d_model\n",
    "        self.tasks=tasks\n",
    "        \n",
    "        self.feature_extr = dc.great.Great(layers=4, d_model=self.outputDimensionality, batch_first=True)\n",
    "        \n",
    "        # make list of lexicons (possible gate names)\n",
    "        self.vertex_lexicon = list(full_op_names.keys()) + [\"input\", \"aggregate\"]\n",
    "        # define embedding network for the lexicons\n",
    "        self.vertex_lexicon_embedding = nn.Embedding(len(self.vertex_lexicon), self.outputDimensionality)\n",
    "        self.vertex_lexicon_embedding_eval = torch.stack([\n",
    "            self.vertex_lexicon_embedding(torch.tensor(n)) for n in range(self.vertex_lexicon_embedding.num_embeddings)\n",
    "        ])\n",
    "        \n",
    "        # define embedding network for the input type numbers (last one is aggregate)\n",
    "        self.vertex_kind_embeddings = {n_qubits:nn.Embedding(n_qubits+1, self.outputDimensionality) \n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "        self.vertex_kind_embeddings_eval = {n_qubits:torch.stack([\n",
    "            self.vertex_kind_embeddings[n_qubits](torch.tensor(n)) for n in range(self.vertex_kind_embeddings[n_qubits].num_embeddings)\n",
    "            ])\n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "\n",
    "        # make edge lexicon list\n",
    "        self.edge_lexicon = sorted([\"nothing\", \"input\", \"io\", \"output\", \"aggregator\"])\n",
    "        # define embedding network for lexicon\n",
    "        self.edge_lexicon_embedding = nn.Embedding(len(self.edge_lexicon), self.outputDimensionality)\n",
    "        self.edge_lexicon_embedding_eval = torch.stack(\n",
    "            [self.edge_lexicon_embedding(torch.tensor(n)) for n in range(self.edge_lexicon_embedding.num_embeddings)]\n",
    "            )\n",
    "\n",
    "        # define many embedding neural networks for the node id\n",
    "        self.max_gate_size = 2\n",
    "        self.edge_kind_embeddings = [nn.Embedding(self.max_gate_size, self.outputDimensionality),\n",
    "                                     nn.Embedding(self.max_gate_size, self.outputDimensionality)]\n",
    "        self.edge_kind_embeddings_eval = torch.stack(\n",
    "            [torch.stack(\n",
    "                [emb(torch.tensor(n)) for n in range(self.max_gate_size)]\n",
    "                ) for emb in self.edge_kind_embeddings]\n",
    "            )\n",
    "        \n",
    "        # define the no_relation tensor\n",
    "        self.edge_no_relation = self.edge_lexicon.index(\"nothing\")\n",
    "\n",
    "    # define total embedding\n",
    "    def get_vertex_list_embedding(self,vertex_list,n_qubits):\n",
    "        vertex_array = np.array(vertex_list) # IDX, GATE, KIND\n",
    "        vertex_embedding = (self.vertex_lexicon_embedding_eval[vertex_array[:,1]] + \n",
    "                            self.vertex_kind_embeddings_eval[n_qubits][vertex_array[:,2]])\n",
    "        return vertex_embedding\n",
    "\n",
    "    def get_edge_list_embedding(self, edges, vertices):\n",
    "        edges_array = np.array(list(edges),dtype=int)\n",
    "        edge_embedding = self.edge_lexicon_embedding_eval[self.edge_no_relation].repeat(len(vertices),len(vertices),1)\n",
    "\n",
    "        # put correct relations where they exist\n",
    "        edge_type_embedding = self.edge_lexicon_embedding_eval[edges_array[:,0]]\n",
    "        edge_embedding[edges_array[:,-2], edges_array[:,-1]] = edge_type_embedding\n",
    "\n",
    "        # non aggregated edges also have \"kind\" = 0,1... (qubit index in input/output)\n",
    "        non_aggregated_edges = edges_array[ edges_array[:,0]!=self.edge_lexicon.index(\"aggregator\") ]\n",
    "        edge_kind_embedding= (self.edge_kind_embeddings_eval[(0,non_aggregated_edges[:,1])] \n",
    "                            + self.edge_kind_embeddings_eval[(1,non_aggregated_edges[:,2])])\n",
    "        edge_embedding[non_aggregated_edges[:,-2], non_aggregated_edges[:,-1]] += edge_kind_embedding\n",
    "        return edge_embedding\n",
    "\n",
    "    def add_vertex(self,type, kind, vertices):\n",
    "        idx = len(vertices) \n",
    "        vertices.add((idx, type, kind))\n",
    "        # VERTEX: #, type, kind\n",
    "        # Type = gate type\n",
    "        # kind = qubit id of that gate\n",
    "        return idx\n",
    "\n",
    "    def get_initial_bindings(self,n_bindings, vertices):\n",
    "        return {i:self.add_vertex(self.vertex_lexicon.index(\"input\"),i, vertices) for i in range(n_bindings)}\n",
    "\n",
    "    def get_relations(self,changed_vertices):\n",
    "        relations = []\n",
    "        changed_vertices_array = np.array(changed_vertices)\n",
    "        \n",
    "        # among inputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"input\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][0]) )\n",
    "        \n",
    "        # among outputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"output\"),i,j, changed_vertices_array[i][1], changed_vertices_array[j][1] ))\n",
    "        \n",
    "        # input - output\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"io\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][1]))\n",
    "        \n",
    "        # EDGES row: type kind1 kind2 vertex_from vertex_to\n",
    "        # Type = input/output/io\n",
    "        # kind = #1 -> #2\n",
    "        return relations\n",
    "\n",
    "    def get_graph(self, circuit, bindings, vertices, edges):\n",
    "        if len(circuit)>0:\n",
    "            current_op = circuit[0]\n",
    "            new_bindings = bindings.copy()\n",
    "            changed_vertices = []\n",
    "            for idx, i in enumerate(current_op[1:]):\n",
    "                new_bindings[i] = self.add_vertex(self.vertex_lexicon.index(current_op[0]), idx, vertices)  # CHANGE TO INPUT LEFT/RIGHT\n",
    "                changed_vertices.append([bindings[i], new_bindings[i]])\n",
    "                \n",
    "            relations = self.get_relations(changed_vertices)\n",
    "            edges.update(relations)\n",
    "            self.get_graph(circuit[1:], new_bindings, vertices, edges)\n",
    "            \n",
    "    def full_circuit_to_VE_embeddings(self, full_circuit):\n",
    "        n_qubits, circuit = full_circuit\n",
    "        \n",
    "        vertices = set()\n",
    "        edges = set()\n",
    "        \n",
    "        # add aggregator vertex\n",
    "        self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
    "\n",
    "        bindings = self.get_initial_bindings(n_qubits, vertices)\n",
    "        self.get_graph(circuit, bindings, vertices, edges)\n",
    "        \n",
    "        # make vertex list\n",
    "        # sort it\n",
    "        vertex_list = sorted(list(vertices), key=lambda vertex: vertex[0])\n",
    "        vertex_embedding = self.get_vertex_list_embedding(vertex_list, n_qubits)\n",
    "        \n",
    "        # add aggregator edges between all vertices\n",
    "        for vertex_2 in vertex_list[1:]:\n",
    "            edges.add((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
    "        \n",
    "        # make edges embedding\n",
    "        edge_embedding = self.get_edge_list_embedding(list(edges), vertex_list)\n",
    "        return vertex_embedding, edge_embedding\n",
    "        # return self.feature_extr(vertex_embedding[None], edge_embedding[None])[0][0] # squeeze and take aggregate vertex\n",
    "    \n",
    "    def full_circuits_to_embedding(self, full_circuits):\n",
    "        Vs = []\n",
    "        Es = []\n",
    "        for full_circuit in full_circuits:\n",
    "            vertex_embedding, edge_embedding = self.full_circuit_to_VE_embeddings(full_circuit)\n",
    "            \n",
    "            Vs.append(vertex_embedding)\n",
    "            Es.append(edge_embedding)\n",
    "            \n",
    "            Vs_padded = torch.nn.utils.rnn.pad_sequence(Vs, batch_first=True)\n",
    "            Es_padded = torch.zeros([Vs_padded.shape[0],Vs_padded.shape[1],Vs_padded.shape[1],Vs_padded.shape[2]])\n",
    "            for i in range(len(Es)):\n",
    "                Es_padded[i,:len(Es[i]),:len(Es[i])] = Es[i]\n",
    "                \n",
    "            Vs_mask = torch.ones(Vs_padded.shape[0],Vs_padded.shape[1])\n",
    "            for i in range(len(Vs)):\n",
    "                Vs_mask[i,:len(Vs[i])] = 0\n",
    "                \n",
    "        return gr.feature_extr(Vs_padded, Es_padded, mask=Vs_mask)[:,0] # take only aggregator vertex\n",
    "            \n",
    "    def featuresOfTask(self, t):\n",
    "        return self.featuresOfTasks([t])[0]\n",
    "    \n",
    "    def featuresOfTasks(self, ts):\n",
    "        embeddings = []\n",
    "        for n_qubit in range(self.n_min, self.n_max):\n",
    "            full_circuits = [t.target_algorithm(n_qubit) for t in ts]\n",
    "            embeddings.append(self.full_circuits_to_embedding(full_circuits))\n",
    "        \n",
    "        embedding = sum(embeddings)\n",
    "        return dc.recognition.variable(embedding).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:56.180693Z",
     "iopub.status.busy": "2022-04-25T22:50:56.180547Z",
     "iopub.status.idle": "2022-04-25T22:50:56.204326Z",
     "shell.execute_reply": "2022-04-25T22:50:56.203907Z",
     "shell.execute_reply.started": "2022-04-25T22:50:56.180676Z"
    }
   },
   "outputs": [],
   "source": [
    "gr = GreatFeatureExtractor(None,full_op_names, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:51:13.548669Z",
     "iopub.status.busy": "2022-04-25T22:51:13.548371Z",
     "iopub.status.idle": "2022-04-25T22:51:13.580349Z",
     "shell.execute_reply": "2022-04-25T22:51:13.579965Z",
     "shell.execute_reply.started": "2022-04-25T22:51:13.548641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "feature_extractor = GreatFeatureExtractor(None, full_op_names, d_model=128)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar, contextual=True)\n",
    "\n",
    "lr=0.0001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T00:29:23.684184Z",
     "iopub.status.busy": "2022-04-26T00:29:23.683874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2234/10000 [10:44<37:18,  3.47it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=5'>6</a>\u001b[0m programs_batch \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(matched_programs, batch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=6'>7</a>\u001b[0m tasks_batch \u001b[39m=\u001b[39m [QuantumTask(i,\u001b[39mlambda\u001b[39;00m n_qubit, program\u001b[39m=\u001b[39mprogram: dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mevaluate([])(f_no_op(n_qubit)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=7'>8</a>\u001b[0m                \u001b[39mfor\u001b[39;00m i, program \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(programs_batch)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=8'>9</a>\u001b[0m embedding \u001b[39m=\u001b[39m recognition_model\u001b[39m.\u001b[39;49mfeatureExtractor\u001b[39m.\u001b[39;49mfeaturesOfTasks(tasks_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=9'>10</a>\u001b[0m simple_programs \u001b[39m=\u001b[39m [dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m program \u001b[39min\u001b[39;00m programs_batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=10'>11</a>\u001b[0m contextual_grammar \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mContextualGrammar\u001b[39m.\u001b[39mfromGrammar(grammar)\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.featuresOfTasks\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=176'>177</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_qubit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_min, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_max):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=177'>178</a>\u001b[0m     full_circuits \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mtarget_algorithm(n_qubit) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=178'>179</a>\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_circuits_to_embedding(full_circuits))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=180'>181</a>\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(embeddings)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=181'>182</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dc\u001b[39m.\u001b[39mrecognition\u001b[39m.\u001b[39mvariable(embedding)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.full_circuits_to_embedding\u001b[0;34m(self, full_circuits)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=153'>154</a>\u001b[0m Es \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=154'>155</a>\u001b[0m \u001b[39mfor\u001b[39;00m full_circuit \u001b[39min\u001b[39;00m full_circuits:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=155'>156</a>\u001b[0m     vertex_embedding, edge_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_circuit_to_VE_embeddings(full_circuit)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=157'>158</a>\u001b[0m     Vs\u001b[39m.\u001b[39mappend(vertex_embedding)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=158'>159</a>\u001b[0m     Es\u001b[39m.\u001b[39mappend(edge_embedding)\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.full_circuit_to_VE_embeddings\u001b[0;34m(self, full_circuit)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=144'>145</a>\u001b[0m     edges\u001b[39m.\u001b[39madd((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_lexicon\u001b[39m.\u001b[39mindex(\u001b[39m\"\u001b[39m\u001b[39maggregator\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m137\u001b[39m, \u001b[39m137\u001b[39m, \u001b[39m0\u001b[39m, vertex_2[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=146'>147</a>\u001b[0m \u001b[39m# make edges embedding\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=147'>148</a>\u001b[0m edge_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_edge_list_embedding(\u001b[39mlist\u001b[39;49m(edges), vertex_list)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=148'>149</a>\u001b[0m \u001b[39mreturn\u001b[39;00m vertex_embedding, edge_embedding\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.get_edge_list_embedding\u001b[0;34m(self, edges, vertices)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=64'>65</a>\u001b[0m edge_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_lexicon_embedding_eval[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_no_relation]\u001b[39m.\u001b[39mrepeat(\u001b[39mlen\u001b[39m(vertices),\u001b[39mlen\u001b[39m(vertices),\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=66'>67</a>\u001b[0m \u001b[39m# put correct relations where they exist\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=67'>68</a>\u001b[0m edge_type_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_lexicon_embedding_eval[edges_array[:,\u001b[39m0\u001b[39;49m]]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=68'>69</a>\u001b[0m edge_embedding[edges_array[:,\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], edges_array[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m edge_type_embedding\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=70'>71</a>\u001b[0m \u001b[39m# non aggregated edges also have \"kind\" = 0,1... (qubit index in input/output)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps = 10000\n",
    "\n",
    "gr.feature_extr.train();\n",
    "for _ in trange(n_steps):\n",
    "    programs_batch = random.sample(matched_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    recognition_model.zero_grad()\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:29:04.366585Z",
     "iopub.status.busy": "2022-04-26T19:29:04.366124Z",
     "iopub.status.idle": "2022-04-26T19:29:04.371498Z",
     "shell.execute_reply": "2022-04-26T19:29:04.370951Z",
     "shell.execute_reply.started": "2022-04-26T19:29:04.366535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr.feature_extr.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:29:05.932779Z",
     "iopub.status.busy": "2022-04-26T19:29:05.932539Z",
     "iopub.status.idle": "2022-04-26T19:29:06.088014Z",
     "shell.execute_reply": "2022-04-26T19:29:06.087539Z",
     "shell.execute_reply.started": "2022-04-26T19:29:05.932756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:23.299842Z",
     "iopub.status.busy": "2022-04-26T18:19:23.299363Z",
     "iopub.status.idle": "2022-04-26T18:19:23.380903Z",
     "shell.execute_reply": "2022-04-26T18:19:23.380458Z",
     "shell.execute_reply.started": "2022-04-26T18:19:23.299794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29.1121815835177, tensor([-22.6289], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8000 # program we are testing\n",
    "task = QuantumTask(i,lambda n_qubit, program=matched_programs[i]: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "code =  dc.program.Program.parse(matched_programs[i][1])\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:25.164529Z",
     "iopub.status.busy": "2022-04-26T18:19:25.164279Z",
     "iopub.status.idle": "2022-04-26T18:19:25.188522Z",
     "shell.execute_reply": "2022-04-26T18:19:25.188119Z",
     "shell.execute_reply.started": "2022-04-26T18:19:25.164509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     ┌───┐     ┌───┐               \n",
      "q_0: ┤ H ├──■──┤ X ├───────────────\n",
      "     ├───┤┌─┴─┐└─┬─┘┌───┐     ┌───┐\n",
      "q_1: ┤ H ├┤ X ├──■──┤ H ├──■──┤ X ├\n",
      "     ├───┤└───┘     └───┘┌─┴─┐└─┬─┘\n",
      "q_2: ┤ H ├───────────────┤ X ├──■──\n",
      "     └───┘               └───┘     \n",
      "q_3: ──────────────────────────────\n",
      "                                   \n",
      "             ┌───┐        ┌───┐\n",
      "q_0: ──■───X─┤ H ├──■───X─┤ H ├\n",
      "     ┌─┴─┐ │ └───┘  │   │ └───┘\n",
      "q_1: ┤ X ├─┼────────┼───X──────\n",
      "     └───┘ │      ┌─┴─┐        \n",
      "q_2: ──────X──────┤ X ├────────\n",
      "                  └───┘        \n",
      "q_3: ──────────────────────────\n",
      "                               \n"
     ]
    }
   ],
   "source": [
    "print_circuit(dc.program.Program.parse(matched_programs[i][1]).evaluate([])(no_op(4)))\n",
    "print_circuit(dc.program.Program.parse(matched_programs[i][0]).evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:37:45.516189Z",
     "iopub.status.busy": "2022-04-26T19:37:45.515743Z",
     "iopub.status.idle": "2022-04-26T19:37:45.562522Z",
     "shell.execute_reply": "2022-04-26T19:37:45.562092Z",
     "shell.execute_reply.started": "2022-04-26T19:37:45.516161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.317766166719343, tensor([-5.9396], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (mv(minv( $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:26.677832Z",
     "iopub.status.busy": "2022-04-26T18:19:26.677368Z",
     "iopub.status.idle": "2022-04-26T18:19:26.714873Z",
     "shell.execute_reply": "2022-04-26T18:19:26.714468Z",
     "shell.execute_reply.started": "2022-04-26T18:19:26.677784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.635532333438686, tensor([-21.4344], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot  $0))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T20:04:03.555071Z",
     "iopub.status.busy": "2022-04-26T20:04:03.554552Z",
     "iopub.status.idle": "2022-04-26T20:04:03.597859Z",
     "shell.execute_reply": "2022-04-26T20:04:03.597393Z",
     "shell.execute_reply.started": "2022-04-26T20:04:03.555019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-56.838068805915505, tensor([-67.8985], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) )  $0 )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.logLikelihood(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    batch_size = 32\n",
    "    n_steps = 1000\n",
    "\n",
    "    gr.feature_extr.train();\n",
    "    for _ in trange(n_steps):\n",
    "        programs_batch = random.sample(matched_programs, batch_size)\n",
    "        tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                    for i, program in enumerate(programs_batch)]\n",
    "        embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "        simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "        contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "        \n",
    "        summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "        \n",
    "        # if not using contextual grammar\n",
    "        # summaries = [grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recognition_model.zero_grad()\n",
    "        \n",
    "        features = recognition_model._MLP(embedding)\n",
    "        lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "        loss = -lls.mean() \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:20<07:57,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 2.77232 s\n",
      "File: /tmp/ipykernel_5224/1500948551.py\n",
      "Function: full_circuit_to_embeddings at line 126\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   126                                               def full_circuit_to_embeddings(self, full_circuit):\n",
      "   127      4032       7131.0      1.8      0.3          n_qubits, circuit = full_circuit\n",
      "   128                                                   \n",
      "   129      4032       6016.0      1.5      0.2          vertices = set()\n",
      "   130      4032       3139.0      0.8      0.1          edges = set()\n",
      "   131                                                   \n",
      "   132                                                   # add aggregator vertex\n",
      "   133      4032      19337.0      4.8      0.7          self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
      "   134                                           \n",
      "   135      4032      45828.0     11.4      1.7          bindings = self.get_initial_bindings(n_qubits, vertices)\n",
      "   136      4032     489074.0    121.3     17.6          self.get_graph(circuit, bindings, vertices, edges)\n",
      "   137                                                   \n",
      "   138                                                   # make vertex list\n",
      "   139                                                   # sort it\n",
      "   140      4032      32831.0      8.1      1.2          vertex_list = sorted(list(vertices), key=lambda vertex: vertex[0])\n",
      "   141      4032     332576.0     82.5     12.0          vertex_embedding = self.get_vertex_list_embedding(vertex_list, n_qubits)\n",
      "   142                                                   \n",
      "   143                                                   # add aggregator edges between all vertices\n",
      "   144     52278      45104.0      0.9      1.6          for vertex_2 in vertex_list[1:]:\n",
      "   145     48246      61617.0      1.3      2.2              edges.add((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
      "   146                                                   \n",
      "   147                                                   # make edges embedding\n",
      "   148      4032    1723674.0    427.5     62.2          edge_embedding = self.get_edge_list_embedding(list(edges), vertex_list)\n",
      "   149      4032       5998.0      1.5      0.2          return vertex_embedding, edge_embedding\n",
      "   150                                                   # return self.feature_extr(vertex_embedding[None], edge_embedding[None])[0][0] # squeeze and take aggregate vertex"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f gr.full_circuit_to_embeddings train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Try to merge two low-level programs and see if we find one solution in the full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - X Split training/test dataset\n",
    "# - X Fix dataset augmentation by removing EMBED gate when not needed\n",
    "# - X Fix graph generation with aggregator edges (all vertices connected to AGGREGATOR!)\n",
    "# - X Masking to allow batch processing (1=masked, 0=allowed)\n",
    "# - Refactor notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v[\"task\"] for v in restricted_dictionary.values()], len(restricted_dictionary)\n",
    "[v[\"task\"] for v in full_dictionary.values()], len(full_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-26T19:51:39.308675Z",
     "iopub.status.busy": "2022-04-26T19:51:39.307983Z",
     "iopub.status.idle": "2022-04-26T19:51:39.441889Z",
     "shell.execute_reply": "2022-04-26T19:51:39.441136Z",
     "shell.execute_reply.started": "2022-04-26T19:51:39.308647Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2759, -0.9362, -0.9602,  ...,  0.6412,  0.4378, -0.7729],\n",
       "         [ 1.7919, -0.6928, -0.9339,  ...,  0.8708,  1.3383, -1.1959],\n",
       "         [ 1.2987, -0.6996,  0.0477,  ...,  0.3061,  1.1436, -1.6745],\n",
       "         [ 1.2819,  0.2977, -1.0037,  ...,  0.4054,  1.5640, -0.7430],\n",
       "         [ 1.7916,  0.0230, -0.8343,  ...,  1.0366,  1.3168, -1.8804]],\n",
       "\n",
       "        [[ 2.0887, -0.1400,  0.0943,  ...,  0.9963,  1.7624, -2.4135],\n",
       "         [ 1.4391,  0.5386, -0.4229,  ...,  2.0502,  1.9189, -1.3506],\n",
       "         [ 1.6665,  0.8416,  1.2304,  ...,  0.8859,  0.6563, -2.1701],\n",
       "         [ 1.5891, -0.5968, -0.0885,  ...,  1.3230,  0.4269, -0.0181],\n",
       "         [ 1.8056,  0.2443, -1.2259,  ...,  0.9780,  0.1213, -0.8895]],\n",
       "\n",
       "        [[ 0.8442,  0.1006,  0.0183,  ...,  1.8837,  0.5749, -0.5465],\n",
       "         [ 2.5495, -0.1414,  0.4686,  ...,  1.7190,  1.0287, -1.3964],\n",
       "         [ 1.8204, -0.5687,  0.1718,  ...,  0.3555,  1.1992, -1.9379],\n",
       "         [ 0.5032, -0.4394,  0.1243,  ...,  0.9252,  0.4069, -1.3862],\n",
       "         [ 0.3281, -0.9118,  1.0388,  ...,  1.8198,  0.3727, -1.3449]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.3547,  0.3113, -1.0753,  ...,  1.2877,  0.4014, -0.3564],\n",
       "         [ 0.6609,  0.1625,  0.1371,  ...,  1.2780,  0.9802, -1.6158],\n",
       "         [ 1.4975, -0.7608, -0.8684,  ...,  1.5775, -0.1982, -1.9023],\n",
       "         [ 1.5495, -0.6564, -0.6223,  ...,  2.0482,  0.7048, -0.4304],\n",
       "         [ 0.3180, -0.5374, -0.1619,  ...,  2.0027,  0.7437, -1.5314]],\n",
       "\n",
       "        [[ 1.4287, -0.4453,  0.5868,  ...,  1.3229, -0.5583, -1.2987],\n",
       "         [ 1.7313, -0.4392, -0.9725,  ...,  1.3026, -0.0118, -1.4333],\n",
       "         [ 1.4873, -1.5506,  0.4468,  ...,  1.1709, -0.4355, -0.2878],\n",
       "         [ 1.1434, -0.2029, -0.0112,  ...,  1.1371,  0.4448, -0.0070],\n",
       "         [ 1.6713, -1.0351,  0.0396,  ...,  2.2492, -0.6135, -0.4507]],\n",
       "\n",
       "        [[ 1.4418,  0.3296, -0.0159,  ...,  0.8935,  0.5671, -3.1858],\n",
       "         [ 0.9681,  0.8472, -0.8943,  ...,  0.5434, -0.2662, -1.9399],\n",
       "         [ 1.1947,  0.3078, -0.4165,  ..., -0.0205,  0.0526, -1.9974],\n",
       "         [ 2.0432,  0.3872,  0.3145,  ...,  0.2231,  0.2443, -2.2678],\n",
       "         [ 1.6737, -0.1154,  0.1803,  ...,  0.4033,  0.4201, -1.9801]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc.great.Great(layers=4,batch_first=True)(torch.rand(9,5,512),\n",
    "                        torch.rand(9,5,5,512),torch.rand(9,5)>0.5 )\n",
    "\n",
    "# check output batched with mask and not batched\n",
    "# SHOULD the edge relation matrix be symmetric?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21ea1a886259afbd8a118ef6898db29b8a19fae78d92613d0ae3d877be73df6a"
  },
  "kernelspec": {
   "display_name": "dc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
