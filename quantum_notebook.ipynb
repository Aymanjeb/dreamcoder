{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dreamcoder as dc\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_qubit = 2\n",
    "full_circuit = [n_qubit,\n",
    "           [[\"cnot\", 0, 1],\n",
    "           [\"swap\", 0, 1],\n",
    "           [\"hadamard\", 1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -1, 3], [['cnot', 1, 0]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(n_qubit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(n_qubit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h (no_op $0)))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.8918202981106265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (no_op $0)))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -7.783640596221253)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -15.567281192442506)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv (no_op $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(2)),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(3)) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(2)) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -14.155496613885283)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size_to_int $0))) (lambda (mv $0))) (no_op $0))))\")\n",
    "code.evaluate([])(3)\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -52.145060152057745)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "print_circuit(code.evaluate([])(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "# print_circuit(code.evaluate([])(5))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv(swap $0))) ) (no_op $0) )))))\")\n",
    "# print_circuit(code.evaluate([])(5))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile bottom-up enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1f4e4906-5d93-4dac-bb9d-d3451e884483\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-16124TUAIB3uwrM27.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"python\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-03-25 12:32:35.820498 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  python\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 225517568\n",
      "Currently using this much memory: 225517568\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.966272.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.933642.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.888042.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.754496.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.417176.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.360445.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 1.203866.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [168, 168, 869, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372, 1372]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.891820 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.783641 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 5.189094 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 1\n",
      "Currently using this much memory: 225927168\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225927168\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.28\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-4.17\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "-4.17\t(lambda (cnot (h (h (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.89\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.89\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.83\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.83\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "-2.83\t(lambda (mv_r (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -15.567281\tNew joint = -14.998451\n",
      "\n",
      "1.202724 / 8.778653\tmv\n",
      "0.052910 / 8.778653\tmv_r\n",
      "1.425419 / 8.778653\tminv\n",
      "3.000000 / 8.778653\tno_op\n",
      "1.029770 / 8.778653\th\n",
      "2.067830 / 8.778653\tcnot\n",
      "0.000000 / 8.778653\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 1:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225865728\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=1_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_0_unordered.pdf\n",
      "Currently using this much memory: 225714176\n",
      "Currently using this much memory: 225714176\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971279.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.943310.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.898743.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.803303.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.686891.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.128656.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.464150.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092, 2092]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 226070528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 226070528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.7 seconds\n",
      "Grammar after iteration 2:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225996800\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=2_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_1_unordered.pdf\n",
      "Currently using this much memory: 225853440\n",
      "Currently using this much memory: 225853440\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.965786.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.932314.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.880273.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775636.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.634202.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 4.900280.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.251888.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069, 2069]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225558528\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225558528\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 3:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225497088\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=3_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_2_unordered.pdf\n",
      "Currently using this much memory: 225415168\n",
      "Currently using this much memory: 225415168\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.970709.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.916057.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.866513.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.775666.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.648860.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.043345.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.101726.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956, 1956]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225435648\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225435648\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 4:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225370112\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=4_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_3_unordered.pdf\n",
      "Currently using this much memory: 225239040\n",
      "Currently using this much memory: 225239040\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.973917.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.946072.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.905853.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.816774.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.683275.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.117403.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.566357.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225259520\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225259520\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.3 seconds\n",
      "Grammar after iteration 5:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 225193984\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=5_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_4_unordered.pdf\n",
      "Currently using this much memory: 225054720\n",
      "Currently using this much memory: 225054720\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 1.500000. Timeout 6.000000.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 1.500000 <= MDL < 3.000000. Timeout 5.971404.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 3.000000 <= MDL < 4.500000. Timeout 5.944928.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 4.500000 <= MDL < 6.000000. Timeout 5.907639.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 6.000000 <= MDL < 7.500000. Timeout 5.822110.\n",
      "(frontend) Launching tsize -> tcircuit (19 tasks) w/ 8 CPUs. 7.500000 <= MDL < 9.000000. Timeout 5.702229.\n",
      "(frontend) Launching tsize -> tcircuit (17 tasks) w/ 8 CPUs. 9.000000 <= MDL < 10.500000. Timeout 5.167367.\n",
      "(frontend) Launching tsize -> tcircuit (16 tasks) w/ 8 CPUs. 10.500000 <= MDL < 12.000000. Timeout 2.800816.\n",
      "We enumerated this many programs, for each task:\n",
      "\t [202, 202, 1119, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321, 2321]\n",
      "Generative model enumeration results:\n",
      "HIT hadamard_0 w/ (lambda (h (no_op $0))) ; log prior = -3.756973 ; log likelihood = 0.000000\n",
      "HIT cnot_01 w/ (lambda (cnot (no_op $0))) ; log prior = -3.669962 ; log likelihood = 0.000000\n",
      "HIT cnot_10 w/ (lambda (cnot (minv (mv (no_op $0))))) ; log prior = -7.571516 ; log likelihood = 0.000000\n",
      "MISS cnot_02\n",
      "MISS cnot_20\n",
      "MISS swap_01\n",
      "MISS swap_02\n",
      "MISS swap_12\n",
      "MISS cz_01\n",
      "MISS cz_12\n",
      "MISS cz_02\n",
      "MISS hadamard_n\n",
      "MISS hadamard_n_1\n",
      "MISS cnot_nn_1\n",
      "MISS swap_nn_1\n",
      "MISS cz_nn_1\n",
      "MISS swap_0n\n",
      "MISS swap_0n_1\n",
      "MISS cnot_0n\n",
      "Hits 3/19 tasks\n",
      "Average description length of a program solving a task: 4.999484 nats\n",
      "Generative model average:  0 sec.\tmedian: 0 \tmax: 1 \tstandard deviation 0\n",
      "Currently using this much memory: 225075200\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.506977\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (minv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.696514\n",
      "WARNING: \tThe program is (lambda (h (minv (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.756973\n",
      "WARNING: \tThe program is (lambda (h (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.718987\n",
      "WARNING: \tThe program is (lambda (mv (h (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -3.891820 vs -3.669962\n",
      "WARNING: \tThe program is (lambda (cnot (no_op $0)))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.631975\n",
      "WARNING: \tThe program is (lambda (mv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.419966\n",
      "WARNING: \tThe program is (lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -5.837730 vs -5.609502\n",
      "WARNING: \tThe program is (lambda (minv (cnot (no_op $0))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (mv (minv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -7.783641 vs -7.571516\n",
      "WARNING: \tThe program is (lambda (cnot (minv (mv (no_op $0)))))\n",
      "\n",
      "WARNING: Log priors differed during frontier combining: -9.729551 vs -9.511057\n",
      "WARNING: \tThe program is (lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "Frontiers discovered top down: 3\n",
      "Total frontiers: 3\n",
      "Currently using this much memory: 225075200\n",
      "Showing the top 5 programs in each frontier being sent to the compressor:\n",
      "hadamard_0\n",
      "-0.37\t(lambda (h (no_op $0)))\n",
      "-2.32\t(lambda (h (minv (no_op $0))))\n",
      "-2.32\t(lambda (minv (h (no_op $0))))\n",
      "-2.32\t(lambda (mv (h (no_op $0))))\n",
      "-4.26\t(lambda (cnot (cnot (h (no_op $0)))))\n",
      "\n",
      "cnot_01\n",
      "-0.29\t(lambda (cnot (no_op $0)))\n",
      "-2.23\t(lambda (minv (cnot (no_op $0))))\n",
      "-2.23\t(lambda (mv (cnot (no_op $0))))\n",
      "-3.94\t(lambda (cnot (minv (minv (no_op $0)))))\n",
      "-4.18\t(lambda (cnot (cnot (cnot (no_op $0)))))\n",
      "\n",
      "cnot_10\n",
      "-0.90\t(lambda (cnot (minv (mv (no_op $0)))))\n",
      "-0.90\t(lambda (cnot (mv (minv (no_op $0)))))\n",
      "-2.65\t(lambda (mv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (minv (mv (no_op $0))))))\n",
      "-2.85\t(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Failure loading recognition - only acceptable if using pypy \n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import recognition. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "WARNING: Could not import torch. This is only okay when doing pypy compression.\n",
      "Inducing a grammar from 3 frontiers\n",
      "Starting score -36.99845058915432\n",
      "Proposed 10 fragments.\n",
      "Old joint = -14.998451\tNew joint = -14.998451\n",
      "\n",
      "1.260546 / 8.784187\tmv\n",
      "0.000000 / 8.784187\tmv_r\n",
      "1.455835 / 8.784187\tminv\n",
      "3.000000 / 8.784187\tno_op\n",
      "1.000000 / 8.784187\th\n",
      "2.067806 / 8.784187\tcnot\n",
      "0.000000 / 8.784187\trep\n",
      "0.000000 / 0.000000\t0\n",
      "0.000000 / 0.000000\tinc\n",
      "0.000000 / 0.000000\tdec\n",
      "0.000000 / 0.000000\tsize_to_int\n",
      "Induced a grammar in 1.6 seconds\n",
      "Grammar after iteration 6:\n",
      "1.466337\tt0\t$_\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n",
      "-0.339216\ttsize -> tcircuit\tno_op\n",
      "-0.419258\ttcircuit -> tcircuit\tcnot\n",
      "-0.483797\ttcircuit -> tcircuit\tminv\n",
      "-0.506270\ttcircuit -> tcircuit\tmv\n",
      "-0.506270\ttcircuit -> tcircuit\th\n",
      "-0.601580\ttcircuit -> tcircuit\tmv_r\n",
      "-0.601580\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "Currently using this much memory: 224989184\n",
      "Exported checkpoint to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_aic=1.0_arity=3_ET=6_it=6_MF=5_noConsolidation=False_pc=10_RW=False_solver=python_STM=True_L=1_TRR=default_K=2_topkNotMAP=False_rec=False.pickle\n",
      "Exporting primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_depth.pdf\n",
      "Exported primitive graph to experimentOutputs/quantum/2022-03-25T12:32:35.806330/quantum_primitives_5_unordered.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 1.06798 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: tensor_contraction at line 44\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    44                                           def tensor_contraction(A, B, indices):\n",
      "    45      8907      18291.0      2.1      1.7      n_qubits = get_qubit_number(A)\n",
      "    46      8907      18792.0      2.1      1.8      idx = [i + n_qubits for i in indices]\n",
      "    47      8907     774326.0     86.9     72.5      out = np.tensordot(A, B, (idx, np.arange(len(indices))))\n",
      "    48      8907     256571.0     28.8     24.0      return np.moveaxis(out, np.arange(-len(indices), 0, 1), idx)\n",
      "\n",
      "Total time: 1.31214 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: full_circuit_to_mat at line 129\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   129                                           def full_circuit_to_mat(full_circuit):\n",
      "   130      6181       3203.0      0.5      0.2      n_qubit, op_list = full_circuit\n",
      "   131                                               \n",
      "   132      6181     138071.0     22.3     10.5      tensor = eye(n_qubit)\n",
      "   133     15088       9797.0      0.6      0.7      for op in op_list:\n",
      "   134                                                   \n",
      "   135      8907    1126483.0    126.5     85.9          tensor = full_op_names[op[0]](tensor, *op[1:])\n",
      "   136                                                   \n",
      "   137      6181      34585.0      5.6      2.6      return tensor_to_mat(tensor)\n",
      "\n",
      "Total time: 2.70419 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\n",
      "Function: execute_quantum_algorithm at line 425\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   425                                           def execute_quantum_algorithm(p, n_qubits, timeout=None):\n",
      "   426     13278       7764.0      0.6      0.3      try:\n",
      "   427     13278      13906.0      1.0      0.5          circuit =  dc.utilities.runWithTimeout(\n",
      "   428     13278      12040.0      0.9      0.4              lambda: p.evaluate([])(n_qubits),\n",
      "   429     13278    1322929.0     99.6     48.9              timeout=timeout\n",
      "   430                                                   )\n",
      "   431      6124    1335440.0    218.1     49.4          return state_circuit_to_mat(circuit)\n",
      "   432      7154       8300.0      1.2      0.3      except dc.utilities.RunWithTimeout: return None\n",
      "   433      7154       3814.0      0.5      0.1      except: return None\n",
      "\n",
      "Total time: 5.14877 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/tasks.py\n",
      "Function: logLikelihood at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                               def logLikelihood(self, e, timeout=None):\n",
      "    22    203252     132890.0      0.7      2.6          if QuantumTask.last_algorithm is not e:\n",
      "    23     12152      15143.0      1.2      0.3              QuantumTask.last_algorithm = e\n",
      "    24     12152      14729.0      1.2      0.3              QuantumTask.last_algorithm_evaluations = {}\n",
      "    25                                           \n",
      "    26    204620     205369.0      1.0      4.0          for n in range(self.min_size, self.max_size):\n",
      "    27    204378     162548.0      0.8      3.2              if n not in QuantumTask.last_algorithm_evaluations.keys():\n",
      "    28     13278    2797987.0    210.7     54.3                  QuantumTask.last_algorithm_evaluations[n] = execute_quantum_algorithm(e, n, timeout)\n",
      "    29                                           \n",
      "    30    204378     112376.0      0.5      2.2              yh = QuantumTask.last_algorithm_evaluations[n]\n",
      "    31    204378     153265.0      0.7      3.0              yh_true = self.target_algorithm_evaluations[n]\n",
      "    32                                           \n",
      "    33    204378      94276.0      0.5      1.8              if yh is None:\n",
      "    34    119090      65833.0      0.6      1.3                  return dc.utilities.NEGATIVEINFINITY\n",
      "    35                                                       \n",
      "    36     85288    1318634.0     15.5     25.6              if not np.all(np.abs(yh-yh_true)<= 1e-5):\n",
      "    37     83920      75608.0      0.9      1.5                  return dc.utilities.NEGATIVEINFINITY\n",
      "    38                                                           \n",
      "    39       242        112.0      0.5      0.0          return 0.\n",
      "\n",
      "Total time: 36.3868 s\n",
      "File: /Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\n",
      "Function: multicoreEnumeration at line 10\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    10                                           def multicoreEnumeration(g, tasks, _=None,\n",
      "    11                                                                    enumerationTimeout=None,\n",
      "    12                                                                    solver='ocaml',\n",
      "    13                                                                    CPUs=1,\n",
      "    14                                                                    maximumFrontier=None,\n",
      "    15                                                                    verbose=True,\n",
      "    16                                                                    evaluationTimeout=None,\n",
      "    17                                                                    testing=False):\n",
      "    18                                               '''g: Either a Grammar, or a map from task to grammar.\n",
      "    19                                               Returns (list-of-frontiers, map-from-task-to-search-time)'''\n",
      "    20                                           \n",
      "    21                                               # We don't use actual threads but instead use the multiprocessing\n",
      "    22                                               # library. This is because we need to be able to kill workers.\n",
      "    23                                               #from multiprocess import Process, Queue\n",
      "    24                                           \n",
      "    25         6        499.0     83.2      0.0      from multiprocessing import Queue\n",
      "    26                                           \n",
      "    27                                                # everything that gets sent between processes will be dilled\n",
      "    28         6         84.0     14.0      0.0      import dill\n",
      "    29                                               \n",
      "    30         6         44.0      7.3      0.0      solvers = {\"ocaml\": solveForTask_ocaml,\n",
      "    31         6         33.0      5.5      0.0                 \"bottom\": solveForTask_bottom,   \n",
      "    32         6         43.0      7.2      0.0                 \"pypy\": solveForTask_pypy,   \n",
      "    33         6        312.0     52.0      0.0                 \"python\": solveForTask_python}   \n",
      "    34         6         29.0      4.8      0.0      assert solver in solvers, \"You must specify a valid solver. options are ocaml, pypy, or python.\" \n",
      "    35                                           \n",
      "    36         6         22.0      3.7      0.0      likelihoodModel = None\n",
      "    37         6         27.0      4.5      0.0      if solver == 'pypy' or solver == 'python':\n",
      "    38                                                 # Use an all or nothing likelihood model.\n",
      "    39         6        422.0     70.3      0.0        likelihoodModel = AllOrNothingLikelihoodModel(timeout=evaluationTimeout) \n",
      "    40                                                 \n",
      "    41                                           \n",
      "    42         6        101.0     16.8      0.0      if not isinstance(g, dict):\n",
      "    43         6        578.0     96.3      0.0          g = {t: g for t in tasks}\n",
      "    44                                               \n",
      "    45                                               \n",
      "    46         6         41.0      6.8      0.0      if solver == \"bottom\":\n",
      "    47                                                   for t, _g in g.items():\n",
      "    48                                                       _g.unrolled = PCFG.from_grammar(_g, t.request).number_rules()\n",
      "    49                                                           \n",
      "    50         6         23.0      3.8      0.0      task2grammar = g\n",
      "    51                                           \n",
      "    52         6         42.0      7.0      0.0      solver_str = solver\n",
      "    53         6         29.0      4.8      0.0      solver = solvers[solver]\n",
      "    54                                           \n",
      "    55                                               # If we are not evaluating on held out testing tasks:\n",
      "    56                                               # Bin the tasks by request type and grammar\n",
      "    57                                               # If these are the same then we can enumerate for multiple tasks simultaneously\n",
      "    58                                               # If we are evaluating testing tasks:\n",
      "    59                                               # Make sure that each job corresponds to exactly one task\n",
      "    60         6         23.0      3.8      0.0      jobs = {}\n",
      "    61       120        467.0      3.9      0.0      for i, t in enumerate(tasks):\n",
      "    62       114        408.0      3.6      0.0          if testing:\n",
      "    63                                                       k = (task2grammar[t], t.request, i)\n",
      "    64                                                   else:\n",
      "    65       114        688.0      6.0      0.0              k = (task2grammar[t], t.request)\n",
      "    66       114      10581.0     92.8      0.0          jobs[k] = jobs.get(k, []) + [t]\n",
      "    67                                           \n",
      "    68         6         40.0      6.7      0.0      disableParallelism = len(jobs) == 1\n",
      "    69         6         21.0      3.5      0.0      parallelCallback = launchParallelProcess if not disableParallelism else lambda f, * \\\n",
      "    70                                                   a, **k: f(*a, **k)\n",
      "    71         6         27.0      4.5      0.0      if disableParallelism:\n",
      "    72         6       7150.0   1191.7      0.0          eprint(\"Disabling parallelism on the Python side because we only have one job.\")\n",
      "    73         6       5959.0    993.2      0.0          eprint(\"If you are using ocaml or bottom, there could still be parallelism.\")\n",
      "    74                                           \n",
      "    75                                               # Map from task to the shortest time to find a program solving it\n",
      "    76         6        221.0     36.8      0.0      bestSearchTime = {t: None for t in task2grammar}\n",
      "    77                                           \n",
      "    78         6        479.0     79.8      0.0      lowerBounds = {k: 0. for k in jobs}\n",
      "    79                                           \n",
      "    80         6        527.0     87.8      0.0      frontiers = {t: Frontier([], task=t) for t in task2grammar}\n",
      "    81                                           \n",
      "    82                                               # For each job we keep track of how long we have been working on it\n",
      "    83         6        480.0     80.0      0.0      stopwatches = {t: Stopwatch() for t in jobs}\n",
      "    84                                           \n",
      "    85                                               # Map from task to how many programs we enumerated for that task\n",
      "    86         6        129.0     21.5      0.0      taskToNumberOfPrograms = {t: 0 for t in tasks }\n",
      "    87                                           \n",
      "    88         6         33.0      5.5      0.0      def numberOfHits(f):\n",
      "    89                                                   return sum(e.logLikelihood > -0.01 for e in f)\n",
      "    90                                           \n",
      "    91         6         32.0      5.3      0.0      def budgetIncrement(lb):\n",
      "    92                                                   nonlocal solver_str\n",
      "    93                                                   if solver_str==\"bottom\":\n",
      "    94                                                       return 6\n",
      "    95                                                   else:\n",
      "    96                                                       return 1.5\n",
      "    97                                           \n",
      "    98         6         34.0      5.7      0.0      def maximumFrontiers(j):\n",
      "    99                                                   tasks = jobs[j]\n",
      "   100                                                   return {t: maximumFrontier - numberOfHits(frontiers[t]) for t in tasks}\n",
      "   101                                           \n",
      "   102         6         19.0      3.2      0.0      def allocateCPUs(n, tasks):\n",
      "   103                                                   allocation = {t: 0 for t in tasks}\n",
      "   104                                                   while n > 0:\n",
      "   105                                                       for t in tasks:\n",
      "   106                                                           # During testing we use exactly one CPU per task\n",
      "   107                                                           if testing and allocation[t] > 0:\n",
      "   108                                                               return allocation\n",
      "   109                                                           allocation[t] += 1\n",
      "   110                                                           n -= 1\n",
      "   111                                                           if n == 0:\n",
      "   112                                                               break\n",
      "   113                                                   return allocation\n",
      "   114                                           \n",
      "   115         6         21.0      3.5      0.0      def refreshJobs():\n",
      "   116                                                   for k in list(jobs.keys()):\n",
      "   117                                                       v = [t for t in jobs[k]\n",
      "   118                                                            if numberOfHits(frontiers[t]) < maximumFrontier\n",
      "   119                                                            and stopwatches[k].elapsed <= enumerationTimeout]\n",
      "   120                                                       if v:\n",
      "   121                                                           jobs[k] = v\n",
      "   122                                                       else:\n",
      "   123                                                           del jobs[k]\n",
      "   124                                           \n",
      "   125                                               # Workers put their messages in here\n",
      "   126         6       6756.0   1126.0      0.0      q = Queue()\n",
      "   127                                           \n",
      "   128                                               # How many CPUs are we using?\n",
      "   129         6         29.0      4.8      0.0      activeCPUs = 0\n",
      "   130                                           \n",
      "   131                                               # How many CPUs was each job allocated?\n",
      "   132         6         22.0      3.7      0.0      id2CPUs = {}\n",
      "   133                                               # What job was each ID working on?\n",
      "   134         6         21.0      3.5      0.0      id2job = {}\n",
      "   135         6         22.0      3.7      0.0      nextID = 0\n",
      "   136                                           \n",
      "   137         6         22.0      3.7      0.0      while True:\n",
      "   138        54      35212.0    652.1      0.1          refreshJobs()\n",
      "   139                                                   # Don't launch a job that we are already working on\n",
      "   140                                                   # We run the stopwatch whenever the job is being worked on\n",
      "   141                                                   # freeJobs are things that we are not working on but could be\n",
      "   142        54       3357.0     62.2      0.0          freeJobs = [j for j in jobs if not stopwatches[j].running\n",
      "   143                                                               and stopwatches[j].elapsed < enumerationTimeout - 0.5]\n",
      "   144        54        206.0      3.8      0.0          if freeJobs and activeCPUs < CPUs:\n",
      "   145                                                       # Allocate a CPU to each of the jobs that we have made the least\n",
      "   146                                                       # progress on\n",
      "   147        48       1753.0     36.5      0.0              freeJobs.sort(key=lambda j: lowerBounds[j])\n",
      "   148                                                       # Launch some more jobs until all of the CPUs are being used\n",
      "   149        48        193.0      4.0      0.0              availableCPUs = CPUs - activeCPUs\n",
      "   150        48      24117.0    502.4      0.1              allocation = allocateCPUs(availableCPUs, freeJobs)\n",
      "   151        96        358.0      3.7      0.0              for j in freeJobs:\n",
      "   152        48       1477.0     30.8      0.0                  if allocation[j] == 0:\n",
      "   153                                                               continue\n",
      "   154        48        200.0      4.2      0.0                  g, request = j[:2]\n",
      "   155        48       1541.0     32.1      0.0                  bi = budgetIncrement(lowerBounds[j])\n",
      "   156        48       2248.0     46.8      0.0                  thisTimeout = enumerationTimeout - stopwatches[j].elapsed\n",
      "   157        48        246.0      5.1      0.0                  eprint(\"(frontend) Launching %s (%d tasks) w/ %d CPUs. %f <= MDL < %f. Timeout %f.\" %\n",
      "   158        48      68289.0   1422.7      0.2                         (request, len(jobs[j]), allocation[j], lowerBounds[j], lowerBounds[j] + bi, thisTimeout))\n",
      "   159        48       2655.0     55.3      0.0                  stopwatches[j].start()\n",
      "   160        48        541.0     11.3      0.0                  parallelCallback(wrapInThread(solver),\n",
      "   161        48        183.0      3.8      0.0                                   q=q, g=g, ID=nextID,\n",
      "   162        48       1815.0     37.8      0.0                                   elapsedTime=stopwatches[j].elapsed,\n",
      "   163        48       1581.0     32.9      0.0                                   CPUs=allocation[j],\n",
      "   164        48       1840.0     38.3      0.0                                   tasks=jobs[j],\n",
      "   165        48       1563.0     32.6      0.0                                   lowerBound=lowerBounds[j],\n",
      "   166        48       1618.0     33.7      0.0                                   upperBound=lowerBounds[j] + bi,\n",
      "   167        48        166.0      3.5      0.0                                   budgetIncrement=bi,\n",
      "   168        48        177.0      3.7      0.0                                   timeout=thisTimeout,\n",
      "   169        48        167.0      3.5      0.0                                   evaluationTimeout=evaluationTimeout,\n",
      "   170        48       4845.0    100.9      0.0                                   maximumFrontiers=maximumFrontiers(j),\n",
      "   171        48        176.0      3.7      0.0                                   testing=testing,\n",
      "   172        48   36032441.0 750675.9     99.0                                   likelihoodModel=likelihoodModel)\n",
      "   173        48       2892.0     60.2      0.0                  id2CPUs[nextID] = allocation[j]\n",
      "   174        48        236.0      4.9      0.0                  id2job[nextID] = j\n",
      "   175        48        194.0      4.0      0.0                  nextID += 1\n",
      "   176                                           \n",
      "   177        48       1749.0     36.4      0.0                  activeCPUs += allocation[j]\n",
      "   178        48       2907.0     60.6      0.0                  lowerBounds[j] += bi\n",
      "   179                                           \n",
      "   180                                                   # If nothing is running, and we just tried to launch jobs,\n",
      "   181                                                   # then that means we are finished\n",
      "   182        54        581.0     10.8      0.0          if all(not s.running for s in stopwatches.values()):\n",
      "   183         6         20.0      3.3      0.0              break\n",
      "   184                                           \n",
      "   185                                                   # Wait to get a response\n",
      "   186        48      81904.0   1706.3      0.2          message = Bunch(dill.loads(q.get()))\n",
      "   187                                           \n",
      "   188        48        232.0      4.8      0.0          if message.result == \"failure\":\n",
      "   189                                                       eprint(\"PANIC! Exception in child worker:\", message.exception)\n",
      "   190                                                       eprint(message.stacktrace)\n",
      "   191                                                       assert False\n",
      "   192        48        170.0      3.5      0.0          elif message.result == \"success\":\n",
      "   193                                                       # Mark the CPUs is no longer being used and pause the stopwatch\n",
      "   194        48        197.0      4.1      0.0              activeCPUs -= id2CPUs[message.ID]\n",
      "   195        48       2370.0     49.4      0.0              stopwatches[id2job[message.ID]].stop()\n",
      "   196                                           \n",
      "   197        48       1880.0     39.2      0.0              newFrontiers, searchTimes, pc = message.value\n",
      "   198       930       3672.0      3.9      0.0              for t, f in newFrontiers.items():\n",
      "   199       882       3080.0      3.5      0.0                  oldBest = None if len(\n",
      "   200       882       6247.0      7.1      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   201       882      14902.0     16.9      0.0                  frontiers[t] = frontiers[t].combine(f)\n",
      "   202       882       3350.0      3.8      0.0                  newBest = None if len(\n",
      "   203       882       6328.0      7.2      0.0                      frontiers[t]) == 0 else frontiers[t].bestPosterior\n",
      "   204                                           \n",
      "   205       882       4746.0      5.4      0.0                  taskToNumberOfPrograms[t] += pc\n",
      "   206                                           \n",
      "   207       882       3599.0      4.1      0.0                  dt = searchTimes[t]\n",
      "   208       882       3140.0      3.6      0.0                  if dt is not None:\n",
      "   209        53        238.0      4.5      0.0                      if bestSearchTime[t] is None:\n",
      "   210        18         85.0      4.7      0.0                          bestSearchTime[t] = dt\n",
      "   211                                                               else:\n",
      "   212                                                                   # newBest & oldBest should both be defined\n",
      "   213        35        113.0      3.2      0.0                          assert oldBest is not None\n",
      "   214        35        111.0      3.2      0.0                          assert newBest is not None\n",
      "   215        35        128.0      3.7      0.0                          newScore = newBest.logPrior + newBest.logLikelihood\n",
      "   216        35        117.0      3.3      0.0                          oldScore = oldBest.logPrior + oldBest.logLikelihood\n",
      "   217                                           \n",
      "   218        35        112.0      3.2      0.0                          if newScore > oldScore:\n",
      "   219                                                                       bestSearchTime[t] = dt\n",
      "   220        35        115.0      3.3      0.0                          elif newScore == oldScore:\n",
      "   221        35        227.0      6.5      0.0                              bestSearchTime[t] = min(bestSearchTime[t], dt)\n",
      "   222                                                   else:\n",
      "   223                                                       eprint(\"Unknown message result:\", message.result)\n",
      "   224                                                       assert False\n",
      "   225                                           \n",
      "   226         6         22.0      3.7      0.0      eprint(\"We enumerated this many programs, for each task:\\n\\t\",\n",
      "   227         6      15539.0   2589.8      0.0             list(taskToNumberOfPrograms.values()))\n",
      "   228                                           \n",
      "   229         6        133.0     22.2      0.0      return [frontiers[t] for t in tasks], bestSearchTime"
     ]
    }
   ],
   "source": [
    "%lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -13.595880825949859)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (inc(inc(dec 0))) (lambda (mv $0))) (no_op $0)))\")\n",
    "code.evaluate([])(5)\n",
    "code.infer()\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuationtype = tcircuit\n",
    "#avoid  no _ op "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000\tt0\t$_\n",
      "0.000000\ttcircuit -> tcircuit\tmv\n",
      "0.000000\ttcircuit -> tcircuit\tmv_r\n",
      "0.000000\ttcircuit -> tcircuit\tminv\n",
      "0.000000\ttsize -> tcircuit\tno_op\n",
      "0.000000\ttcircuit -> tcircuit\th\n",
      "0.000000\ttcircuit -> tcircuit\tcnot\n",
      "0.000000\tint -> (tcircuit -> tcircuit) -> tcircuit -> tcircuit\trep\n",
      "0.000000\tint\t0\n",
      "0.000000\tint -> int\tinc\n",
      "0.000000\tint -> int\tdec\n",
      "0.000000\ttsize -> int\tsize_to_int\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outputs with and without observational equivalence\n",
    "\n",
    "# primitives = [\n",
    "#     p_move_next,\n",
    "#     p_no_op,\n",
    "#     p_hadamard,\n",
    "# ]\n",
    "\n",
    "\n",
    "# grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "\n",
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit_full))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (no_op $0))\n",
      "(lambda (mv (no_op $0)))\n",
      "(lambda (mv_r (no_op $0)))\n",
      "(lambda (minv (no_op $0)))\n",
      "(lambda (h (no_op $0)))\n",
      "(lambda (cnot (no_op $0)))\n",
      "(lambda (mv (mv (no_op $0))))\n",
      "(lambda (mv (mv_r (no_op $0))))\n",
      "(lambda (mv (minv (no_op $0))))\n",
      "(lambda (mv (h (no_op $0))))\n",
      "(lambda (mv (cnot (no_op $0))))\n",
      "(lambda (mv_r (mv (no_op $0))))\n",
      "(lambda (mv_r (mv_r (no_op $0))))\n",
      "(lambda (mv_r (minv (no_op $0))))\n",
      "(lambda (mv_r (h (no_op $0))))\n",
      "(lambda (mv_r (cnot (no_op $0))))\n",
      "(lambda (minv (mv (no_op $0))))\n",
      "(lambda (minv (mv_r (no_op $0))))\n",
      "(lambda (minv (minv (no_op $0))))\n",
      "(lambda (minv (h (no_op $0))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 3], [['hadamard', 0], ['hadamard', 0]]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(\"(lambda (mv (h (h (no_op $0)))))\").evaluate([])(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = restricted_pcfg.quantized_enumeration(observational_equivalence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda (no_op $0))\n",
      "(lambda (mv (no_op $0)))\n",
      "(lambda (mv_r (no_op $0)))\n",
      "(lambda (minv (no_op $0)))\n",
      "(lambda (h (no_op $0)))\n",
      "(lambda (cnot (no_op $0)))\n",
      "(lambda (mv (mv (no_op $0))))\n",
      "(lambda (mv (minv (no_op $0))))\n",
      "(lambda (mv (h (no_op $0))))\n",
      "(lambda (mv (cnot (no_op $0))))\n",
      "(lambda (minv (h (no_op $0))))\n",
      "(lambda (minv (cnot (no_op $0))))\n",
      "(lambda (h (mv (no_op $0))))\n",
      "(lambda (h (cnot (no_op $0))))\n",
      "(lambda (cnot (mv (no_op $0))))\n",
      "(lambda (cnot (h (no_op $0))))\n",
      "(lambda (mv (mv (mv (no_op $0)))))\n",
      "(lambda (mv (mv (minv (no_op $0)))))\n",
      "(lambda (mv (mv (h (no_op $0)))))\n",
      "(lambda (mv (mv (cnot (no_op $0)))))\n",
      "(lambda (mv (minv (h (no_op $0)))))\n",
      "(lambda (mv (minv (cnot (no_op $0)))))\n",
      "(lambda (mv (h (mv (no_op $0)))))\n",
      "(lambda (mv (h (cnot (no_op $0)))))\n",
      "(lambda (mv (cnot (mv (no_op $0)))))\n",
      "(lambda (mv (cnot (h (no_op $0)))))\n",
      "(lambda (mv_r (h (mv (no_op $0)))))\n",
      "(lambda (mv_r (cnot (mv (no_op $0)))))\n",
      "(lambda (minv (h (mv (no_op $0)))))\n",
      "(lambda (minv (h (cnot (no_op $0)))))\n",
      "(lambda (minv (cnot (mv (no_op $0)))))\n",
      "(lambda (minv (cnot (h (no_op $0)))))\n",
      "(lambda (h (mv (mv (no_op $0)))))\n",
      "(lambda (h (mv (h (no_op $0)))))\n",
      "(lambda (h (mv (cnot (no_op $0)))))\n",
      "(lambda (h (cnot (mv (no_op $0)))))\n",
      "(lambda (h (cnot (h (no_op $0)))))\n",
      "(lambda (cnot (mv (mv (no_op $0)))))\n",
      "(lambda (cnot (mv (minv (no_op $0)))))\n",
      "(lambda (cnot (mv (h (no_op $0)))))\n",
      "(lambda (cnot (mv (cnot (no_op $0)))))\n",
      "(lambda (cnot (h (mv (no_op $0)))))\n",
      "(lambda (cnot (h (cnot (no_op $0)))))\n",
      "(lambda (mv (mv (mv (minv (no_op $0))))))\n",
      "(lambda (mv (mv (mv (h (no_op $0))))))\n",
      "(lambda (mv (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (minv (h (no_op $0))))))\n",
      "(lambda (mv (mv (minv (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (h (mv (no_op $0))))))\n",
      "(lambda (mv (mv (h (cnot (no_op $0))))))\n",
      "(lambda (mv (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (mv (cnot (h (no_op $0))))))\n",
      "(lambda (mv (minv (h (mv (no_op $0))))))\n",
      "(lambda (mv (minv (h (cnot (no_op $0))))))\n",
      "(lambda (mv (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (minv (cnot (h (no_op $0))))))\n",
      "(lambda (mv (h (mv (mv (no_op $0))))))\n",
      "(lambda (mv (h (mv (h (no_op $0))))))\n",
      "(lambda (mv (h (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (h (cnot (mv (no_op $0))))))\n",
      "(lambda (mv (h (cnot (h (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (h (no_op $0))))))\n",
      "(lambda (mv (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (mv (cnot (h (mv (no_op $0))))))\n",
      "(lambda (mv (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (mv_r (minv (h (mv (no_op $0))))))\n",
      "(lambda (mv_r (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (mv (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (h (no_op $0))))))\n",
      "(lambda (mv_r (h (mv (cnot (no_op $0))))))\n",
      "(lambda (mv_r (h (cnot (mv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (h (no_op $0))))))\n",
      "(lambda (mv_r (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (mv_r (cnot (h (mv (no_op $0))))))\n",
      "(lambda (minv (h (mv (mv (no_op $0))))))\n",
      "(lambda (minv (h (mv (h (no_op $0))))))\n",
      "(lambda (minv (h (mv (cnot (no_op $0))))))\n",
      "(lambda (minv (h (cnot (mv (no_op $0))))))\n",
      "(lambda (minv (h (cnot (h (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (h (no_op $0))))))\n",
      "(lambda (minv (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (minv (cnot (h (mv (no_op $0))))))\n",
      "(lambda (minv (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (h (mv (mv (mv (no_op $0))))))\n",
      "(lambda (h (mv (mv (h (no_op $0))))))\n",
      "(lambda (h (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (h (mv (h (mv (no_op $0))))))\n",
      "(lambda (h (mv (h (cnot (no_op $0))))))\n",
      "(lambda (h (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (h (mv (cnot (h (no_op $0))))))\n",
      "(lambda (h (cnot (mv (mv (no_op $0))))))\n",
      "(lambda (h (cnot (mv (minv (no_op $0))))))\n",
      "(lambda (h (cnot (mv (h (no_op $0))))))\n",
      "(lambda (h (cnot (mv (cnot (no_op $0))))))\n",
      "(lambda (h (cnot (h (mv (no_op $0))))))\n",
      "(lambda (h (cnot (h (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (minv (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (h (no_op $0))))))\n",
      "(lambda (cnot (mv (mv (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (minv (h (no_op $0))))))\n",
      "(lambda (cnot (mv (minv (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (h (mv (no_op $0))))))\n",
      "(lambda (cnot (mv (h (cnot (no_op $0))))))\n",
      "(lambda (cnot (mv (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (mv (cnot (h (no_op $0))))))\n",
      "(lambda (cnot (mv_r (h (mv (no_op $0))))))\n",
      "(lambda (cnot (mv_r (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (minv (h (mv (no_op $0))))))\n",
      "(lambda (cnot (minv (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (h (mv (mv (no_op $0))))))\n",
      "(lambda (cnot (h (mv (h (no_op $0))))))\n",
      "(lambda (cnot (h (mv (cnot (no_op $0))))))\n",
      "(lambda (cnot (h (cnot (mv (no_op $0))))))\n",
      "(lambda (cnot (h (cnot (h (no_op $0))))))\n",
      "(lambda (mv (mv (mv (minv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (minv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (minv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (mv (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (minv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (minv (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv (h (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (h (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (h (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv (h (cnot (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (minv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (minv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (minv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv_r (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (mv_r (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (minv (h (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (minv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv (cnot (h (cnot (h (no_op $0)))))))\n",
      "(lambda (mv_r (mv_r (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (mv_r (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (minv (h (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (minv (cnot (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (mv (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (h (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (h (cnot (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (cnot (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (mv (cnot (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (mv (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (minv (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (h (no_op $0)))))))\n",
      "(lambda (mv_r (h (cnot (mv (cnot (no_op $0)))))))\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerating arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    # p_0,\n",
    "    p_inc,\n",
    "    p_dec,\n",
    "]\n",
    "\n",
    "grammar = dc.grammar.Grammar.uniform(primitives)\n",
    "pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(dc.type.tint, dc.type.tint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = pcfg.quantized_enumeration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lambda $0)\n",
      "(lambda (inc $0))\n",
      "(lambda (dec $0))\n",
      "(lambda (inc (inc $0)))\n",
      "(lambda (inc (dec $0)))\n",
      "(lambda (dec (inc $0)))\n",
      "(lambda (dec (dec $0)))\n",
      "(lambda (inc (inc (inc $0))))\n",
      "(lambda (inc (inc (dec $0))))\n",
      "(lambda (inc (dec (inc $0))))\n",
      "(lambda (inc (dec (dec $0))))\n",
      "(lambda (dec (inc (inc $0))))\n",
      "(lambda (dec (inc (dec $0))))\n",
      "(lambda (dec (dec (inc $0))))\n",
      "(lambda (dec (dec (dec $0))))\n",
      "(lambda (inc (inc (inc (inc $0)))))\n",
      "(lambda (inc (inc (inc (dec $0)))))\n",
      "(lambda (inc (inc (dec (inc $0)))))\n",
      "(lambda (inc (inc (dec (dec $0)))))\n",
      "(lambda (inc (dec (inc (inc $0)))))\n",
      "(lambda (inc (dec (inc (dec $0)))))\n",
      "(lambda (inc (dec (dec (inc $0)))))\n",
      "(lambda (inc (dec (dec (dec $0)))))\n",
      "(lambda (dec (inc (inc (inc $0)))))\n",
      "(lambda (dec (inc (inc (dec $0)))))\n",
      "(lambda (dec (inc (dec (inc $0)))))\n",
      "(lambda (dec (inc (dec (dec $0)))))\n",
      "(lambda (dec (dec (inc (inc $0)))))\n",
      "(lambda (dec (dec (inc (dec $0)))))\n",
      "(lambda (dec (dec (dec (inc $0)))))\n",
      "(lambda (dec (dec (dec (dec $0)))))\n",
      "(lambda (inc (inc (inc (inc (inc $0))))))\n",
      "(lambda (inc (inc (inc (inc (dec $0))))))\n",
      "(lambda (inc (inc (inc (dec (inc $0))))))\n",
      "(lambda (inc (inc (inc (dec (dec $0))))))\n",
      "(lambda (inc (inc (dec (inc (inc $0))))))\n",
      "(lambda (inc (inc (dec (inc (dec $0))))))\n",
      "(lambda (inc (inc (dec (dec (inc $0))))))\n",
      "(lambda (inc (inc (dec (dec (dec $0))))))\n",
      "(lambda (inc (dec (inc (inc (inc $0))))))\n",
      "(lambda (inc (dec (inc (inc (dec $0))))))\n",
      "(lambda (inc (dec (inc (dec (inc $0))))))\n",
      "(lambda (inc (dec (inc (dec (dec $0))))))\n",
      "(lambda (inc (dec (dec (inc (inc $0))))))\n",
      "(lambda (inc (dec (dec (inc (dec $0))))))\n",
      "(lambda (inc (dec (dec (dec (inc $0))))))\n",
      "(lambda (inc (dec (dec (dec (dec $0))))))\n",
      "(lambda (dec (inc (inc (inc (inc $0))))))\n",
      "(lambda (dec (inc (inc (inc (dec $0))))))\n",
      "(lambda (dec (inc (inc (dec (inc $0))))))\n",
      "(lambda (dec (inc (inc (dec (dec $0))))))\n",
      "(lambda (dec (inc (dec (inc (inc $0))))))\n",
      "(lambda (dec (inc (dec (inc (dec $0))))))\n",
      "(lambda (dec (inc (dec (dec (inc $0))))))\n",
      "(lambda (dec (inc (dec (dec (dec $0))))))\n",
      "(lambda (dec (dec (inc (inc (inc $0))))))\n",
      "(lambda (dec (dec (inc (inc (dec $0))))))\n",
      "(lambda (dec (dec (inc (dec (inc $0))))))\n",
      "(lambda (dec (dec (inc (dec (dec $0))))))\n",
      "(lambda (dec (dec (dec (inc (inc $0))))))\n",
      "(lambda (dec (dec (dec (inc (dec $0))))))\n",
      "(lambda (dec (dec (dec (dec (inc $0))))))\n",
      "(lambda (dec (dec (dec (dec (dec $0))))))\n",
      "(lambda (inc (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (inc (dec (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (inc (dec (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (inc (dec (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (inc (dec $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (inc $0)))))))\n",
      "(lambda (inc (dec (dec (dec (dec (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (inc (dec $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (inc $0)))))))\n",
      "(lambda (dec (inc (inc (inc (dec (dec $0)))))))\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in iterator:\n",
    "    counter +=1\n",
    "    if counter<100:\n",
    "        print(i)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[(lambda 0)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_17539/1611270510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrestricted_pcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(restricted_pcfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrestricted_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumeration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_pcfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestricted_pcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit_execution_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_circuit_to_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfull_pcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_grammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcircuit_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\u001b[0m in \u001b[0;36menumerate_pcfg\u001b[0;34m(pcfg, timeout, circuit_execution_function)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0menum_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0mt_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized_enumeration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mt_0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mquantized_enumeration\u001b[0;34m(self, resolution, skeletons, observational_equivalence)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskeleton_cost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeletons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskeleton_costs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomplete_skeleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mskeleton_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mcomplete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_skeleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAbstraction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomplete_skeleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mAbstraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misApplication\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mcomplete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   1851\u001b[0m                             \u001b[0;32myield\u001b[0m \u001b[0mApplication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNamedHole\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexpressions_of_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mexpressions_of_size\u001b[0;34m(symbol, size)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                             key = compute_signature(proposed_expression,\n\u001b[1;32m   1825\u001b[0m                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m                                                     self.free_variable_types[symbol])\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mequivalences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mcompute_signature\u001b[0;34m(expression, tp, arguments)\u001b[0m\n\u001b[1;32m   1730\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_to_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/grammar.py\u001b[0m in \u001b[0;36mvalue_to_key\u001b[0;34m(value, output_type)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 \u001b[0;31m# Final position should be the same (otherwise we exclude all moving operations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 \u001b[0;31m# Generated unitary should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0munitary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_algorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_circuit_to_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munitary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_algorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcircuit_full\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36mstate_circuit_to_mat\u001b[0;34m(circuit)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstate_circuit_to_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfull_circuit_to_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36mfull_circuit_to_mat\u001b[0;34m(full_circuit)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_op_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_to_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36mhadamard\u001b[0;34m(circuit, qubit_1)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhadamard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqubit_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_hadamard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mqubit_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/primitives.py\u001b[0m in \u001b[0;36mtensor_contraction\u001b[0;34m(A, B, indices)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mn_qubits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_qubit_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_qubits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dc/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mN2\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m     \u001b[0mnewshape_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0molda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tsize, tcircuit))\n",
    "# print(restricted_pcfg)\n",
    "restricted_dictionary = dc.enumeration.enumerate_pcfg(restricted_pcfg,timeout=6, circuit_execution_function=state_circuit_to_mat)\n",
    "\n",
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tsize, tcircuit_full))\n",
    "full_dictionary = dc.enumeration.enumerate_pcfg(full_pcfg,timeout=6, circuit_execution_function=full_circuit_to_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerated 223 programs\n"
     ]
    }
   ],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(4))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(4))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"matched_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, []]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.program.Program.parse(matched_programs[0][0]).evaluate([])(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for the recognition network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [3,5]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar, contextual=False)\n",
    "lr=0.000001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:44<00:00, 114.46it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps = 6000\n",
    "for _ in trange(n_steps):\n",
    "    programs_batch = random.sample(matched_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(n_qubit))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    # replaceProgramsWithLikelihoodSummaries\n",
    "    # summaries = [dc.grammar.ContextualGrammar.fromGrammar(grammar).closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    summaries = [grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    recognition_model.zero_grad()\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() # why max and not mean?\n",
    "     \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.783640596221253, tensor([-7.6573], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv(no_op $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-15.567281192442506, tensor([-15.4090], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot (no_op $0)))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-52.145060152057745, tensor([-52.8876], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size_to_int $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size_to_int $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) (no_op $0) )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# profile running time, enumeration speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_quantum(matched_dictionary={unitaries: simple_program, complicated_list},)\n",
    "# for each sample\n",
    "#     embedding= feature_extractor([unitary, complicated_list]) (i.e. encoder)  #in the case of great we first need an embedding and here we get the final embedding\n",
    "    \n",
    "#     # apply the recognition model\n",
    "#     [from frontierBiasOptimal]\n",
    "#     features = self._MLP(features)\n",
    "#     features = features.expand(batchSize, features.size(-1))  # TODO\n",
    "#     lls = self.grammarBuilder.batchedLogLikelihoods(features, [simple_program])\n",
    "        \n",
    "#     # train (optimize -lls  adam)\n",
    "#     lls.backward\n",
    "    \n",
    "# # look at the new likelihoods\n",
    "#     recognitionmodel.grammarOfTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more enumerated tasks (10k)\n",
    "\n",
    "# bags of words (Gates) e.g. number of occurrences for each gate\n",
    "# great https://github.com/google-research/crossbeam/blob/main/crossbeam/model/great.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observational equivalence\n",
    "# https://cseweb.ucsd.edu/~npolikarpova/publications/oopsla20-probe.pdf\n",
    "\n",
    "# let's start from arithmetic expressions\n",
    "\n",
    "# remove no_op to enable continuation type in grammar\n",
    "\n",
    "# continuationtype: only most recent of this type can be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (and what happens when only one primitive is allowed)\n",
    "# No_op\n",
    "# Observational equivalence on multiple values\n",
    "# Parallelize training of Feature Extractor network\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalences should depend on non terminal symbol\n",
    "\n",
    "# recognition model should be contestula\n",
    "# remove size to int but we need circuit to size"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3b58914974b8dde835498c747ea4f1aaf3fb4cb185c0609e0c7a19c91a9bce2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
