####### Graphics Programs #######
### Synth (language); Model: No language
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionTimeout 1800 --recognition_0 examples --Helmholtz 0.5 --skip_first_test --taskDataset logo_unlimited_200 --sample_n_supervised 0 --om_original_ordering 1

# N.B. All replications are run by changing the random seed in --seed.
# We run all replications with --seed = 1,2,3; but omit here for concision.
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionTimeout 1800 --recognition_0 examples --Helmholtz 0.5 --skip_first_test --taskDataset logo_unlimited_200 --sample_n_supervised 0 --taskReranker randomShuffle --seed 1

### Synth (language); Model: No compression
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionTimeout 1800 --recognition_0 --recognition_1 examples language --Helmholtz 0  --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1 --language_compression --lc_score 0.2 --max_compression 5 --om_original_ordering 1 --smt_pseudoalignments 0.1 --no-consolidation

### Synth (language); Model: No generative language model
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionSteps 10000 --recognition_0 --recognition_1 examples language --Helmholtz 0 --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0

### Synth (language); Model: Ours, generative language
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionTimeout 1800 --recognition_0 --recognition_1 examples language --Helmholtz 0.5 --synchronous_grammar --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1

### Synth (language); Model: Ours, GL + Translation Priors
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionSteps 10000 --recognition_0 --recognition_1 examples language --Helmholtz 0.5 --synchronous_grammar --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1 --smt_pseudoalignments 0.1 --om_original_ordering 1

### Synth (language); Model: Ours, GL + TP + Language Compression
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionTimeout 1800 --recognition_0 --recognition_1 examples language --Helmholtz 0.5 --synchronous_grammar --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1 --language_compression --lc_score 0.2 --max_compression 5 --om_original_ordering 1 --smt_pseudoalignments 0.1


### Human train, human test. 
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 3 --no-cuda --recognitionSteps 10000 --recognition_0 --recognition_1 examples language --Helmholtz 0.5 --synchronous_grammar --skip_first_test --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/humans --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1 --smt_pseudoalignments 0.1  --language_compression --lc_score 0.2 --max_compression 5 --om_original_ordering 1 

### DSL Comparison: pure enumeration. # Check for first testing evaluation.
python3.7 bin/logo.py  --enumerationTimeout 1800 --testingTimeout 1800  --iterations 12 --biasOptimal --contextual --taskBatchSize 40 --testEvery 1 --no-cuda --recognitionTimeout 1800 --recognition_0 --recognition_1 examples language --Helmholtz 0 --taskDataset logo_unlimited_200 --language_encoder recurrent --languageDataset logo_unlimited_200/synthetic --sample_n_supervised 0 --moses_dir ./moses_compiled --smt_phrase_length 1 --language_compression --lc_score 0.2 --max_compression 5 --om_original_ordering 1 --smt_pseudoalignments 0.1 --no-consolidation

# The following experiments require the released pretrained checkpoints.
### Synth train, human test. This requires resuming from the pretrained model (best (Outs))

### DSL Comparison: best DSL (no language), pure enumeration. This requires resuming from a pretrained checkpoint.

### DSL Comparison: best DSL (Ours): pure enumeration. This requires resuming from a pretrained checkpoint.

### DSL Comparison: best DSL (Ours): neural search. This requires resuming from a pretrained checkpoint.

###### Text Editing #######
### Synth (language); Model: No language

### Synth (language); Model: No compression

### Synth (language); Model: No generative language model

### Synth (language); Model: Ours, generative language

### Synth (language); Model: Ours, GL + Translation Priors

### Synth (language); Model: Ours, GL + TP + Language Compression

### Human train, human test. 

### DSL Comparison: pure enumeration.

# The following experiments require the released pretrained checkpoints.
### Synth train, human test. This requires resuming from the pretrained model (best (Outs))

### DSL Comparison: best DSL (no language), pure enumeration. This requires resuming from a pretrained checkpoint.

### DSL Comparison: best DSL (Ours): pure enumeration. This requires resuming from a pretrained checkpoint.

### DSL Comparison: best DSL (Ours): neural search. This requires resuming from a pretrained checkpoint.