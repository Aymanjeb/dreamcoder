# @package _global_
defaults:
  - data: deepcoder
  - model: mbas
  - solver: astar # not used by model=rb

job_name: anon_job # used to be called `prefix`
run_name: anon_run # used to be called `name`
full_name: null # this will be set by matt.py to be cwd_path().name which is `time.job.run`
load: null # load=@(['22-23-14.mar29_test_mbas0.*','12-40-03.mar29_test_mbas0.*']) 
mode: train
device: cpu
seed: 100 # null means random
print: False # just print the cfg and exit

check_overrides: True # if set to False, theres to checking on if an override was okay to do.

dirty: False # set to True to skip errors due to dirty repo
is_dirty: null # set by matt.py. This tells whether the repo was actually dirty when launching

argv: null # this will get set by matt.py
commit: null # this will get set by matt.py
start_time: null # this will get set by matt.py
start_time_filename: null # this will get set by matt.py. It's a filename-safe version of start_time
job_id: null # not used internally for anything, just by the `job` manager.
job_info: null # optionally set by job.py to {time_str}.{self.job_name}.{run_name}

notify_crash: null # null | email | text
notify_done: null  # null | email | text

loop:
  print_every: 100
  save_every: 10000
  max_steps: 500000
  # validation
  valid_every: 10000
  search_valid_every: 50000
  search_valid_timeout: 3
  search_valid_num_tasks: 50
  round_j: False
  j_multiplier: 4

loader:
  buf_size: 1000 # size of buffer
  max_tasks: null # truncate to this many tasks. null = unlimited
  max_valid: ${loop.search_valid_num_tasks} # truncate validation tasks to this many
  repeat: True # loop once you reach the end of the dataset
  freeze: False # loop a single buffer of tasks forever
  threaded: False # multithreading

debug:
  verbose: False
  mlb_debug: True
  channel: False # check gradients for channel separation (only between sketches not between examples)
  zero_output_feats: False # replace outputFeatures(task) with all zeros so _compare(rep,all_zeros) is run
  zero_input_feats: False # replace inputFeatures(task) with all zeros. This means holes are no longer a function of the input features.
  zero_concrete_eval: False # Take the result of encodeValue(rep) and turn it to all zeros
  zero_sk: False # Take the result of rep(sk) and turn it to all zeros so _compare(all_zeros,outputFeatures) is run
  validate_cache: False # double check that the cache is identical to the non-cache verison. Also applies to PTask.input_feats()
  p_check_abstract: 0. # (only if validate_cache=True) probability (out of 1.0) of checking .get_abstract() on all cache things are the same (quite intensive)
  pnode_concrete_check: False # cheap check to make sure both concrete-mode propagate() is working (equivalent to actual outputs) and execute_single() as well
  no_cache: False # disables caching altogether
  validate_batcher_inside: False
  validate_batcher_full: False
  unbatched: False


plot: # for mode=plot
  file: null # defaults to time string
  title: null # defaults to time string
  legend: null # a string like "['Blended Semantics (ours)', 'Neural Semantics', 'RNN']"
  cropped: True
  font_size: 14
  linewidth: 4
  filetype: eps # only used if no `plot.file` is provided (otherwise we just use the extension on `plot.file`)
  x_max: null # manually set the x axis to a certain maximum
  iclr_paper: False # set some stuff w coloring and zorder

testgen: # for mode=testgen
  from_fn: null # deepcoder | josh | lucas
  to_file: null # path relative to testgen_path()
  num_tasks: null
  josh:
    wave: 3 # 1 | 2 | 3 | 3.1 | final
  lucas:
    version: 1 # 1 | 2 | 3 | old | bootstrap

test: # for mode=test
  from_file: null # path relative to testgen_path()
  out: null # output file. defaults to job_info if thats set (job.py sets it to {time_str}.{self.job_name}.{run_name}), else to {sing.cfg.start_time_filename}.{sing.cfg.job_name}.{sing.cfg.run_name}
  timeout: 30
  max_tasks: null

printif:
  fake: False # print_if(s,'fake') will only fire if this is True
  beval: True
  beval_single: True
printer:
  beval: False

hydra:
  run:
    dir: ./outputs/${mode}/${now:%Y-%m-%d}/${now:%H-%M-%S}.${job_name}.${run_name}
