{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:07.396057Z",
     "iopub.status.busy": "2022-04-26T18:19:07.395857Z",
     "iopub.status.idle": "2022-04-26T18:19:07.402513Z",
     "shell.execute_reply": "2022-04-26T18:19:07.401897Z",
     "shell.execute_reply.started": "2022-04-26T18:19:07.396033Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dreamcoder as dc\n",
    "from dreamcoder.domains.quantum_algorithms.primitives import *\n",
    "from dreamcoder.domains.quantum_algorithms.tasks import *\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:46.815077Z",
     "iopub.status.busy": "2022-04-25T18:28:46.814683Z",
     "iopub.status.idle": "2022-04-25T18:28:46.817838Z",
     "shell.execute_reply": "2022-04-25T18:28:46.817473Z",
     "shell.execute_reply.started": "2022-04-25T18:28:46.815035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (('cnot', 0, 1), ('swap', 0, 1), ('hadamard', 1)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit = 2\n",
    "full_circuit = (n_qubit,\n",
    "           ((\"cnot\", 0, 1),\n",
    "           (\"swap\", 0, 1),\n",
    "           (\"hadamard\", 1))\n",
    ")\n",
    "full_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:47.410256Z",
     "iopub.status.busy": "2022-04-25T18:28:47.409861Z",
     "iopub.status.idle": "2022-04-25T18:28:47.415882Z",
     "shell.execute_reply": "2022-04-25T18:28:47.415468Z",
     "shell.execute_reply.started": "2022-04-25T18:28:47.410236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = eye(n_qubit)\n",
    "tensor_to_mat(swap(cnot(tensor,0,1),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:58.544879Z",
     "iopub.status.busy": "2022-04-25T18:28:58.544688Z",
     "iopub.status.idle": "2022-04-25T18:28:58.549754Z",
     "shell.execute_reply": "2022-04-25T18:28:58.549327Z",
     "shell.execute_reply.started": "2022-04-25T18:28:58.544856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.707,  0.707,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.707,  0.707],\n",
       "       [ 0.   ,  0.   ,  0.707, -0.707],\n",
       "       [ 0.707, -0.707,  0.   ,  0.   ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_circuit_to_mat(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.176362Z",
     "iopub.status.busy": "2022-04-25T18:28:59.175938Z",
     "iopub.status.idle": "2022-04-25T18:28:59.490576Z",
     "shell.execute_reply": "2022-04-25T18:28:59.490076Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.176338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \n",
      "q_0: ──■───X──────\n",
      "     ┌─┴─┐ │ ┌───┐\n",
      "q_1: ┤ X ├─X─┤ H ├\n",
      "     └───┘   └───┘\n"
     ]
    }
   ],
   "source": [
    "print_circuit(full_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:28:59.875600Z",
     "iopub.status.busy": "2022-04-25T18:28:59.875358Z",
     "iopub.status.idle": "2022-04-25T18:28:59.886662Z",
     "shell.execute_reply": "2022-04-25T18:28:59.886239Z",
     "shell.execute_reply.started": "2022-04-25T18:28:59.875580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐   ┌───┐\n",
      "q_0: ┤ X ├─X─┤ H ├\n",
      "     └─┬─┘ │ └───┘\n",
      "q_1: ──■───X──────\n",
      "                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    }
   ],
   "source": [
    "with QiskitTester(full_circuit) as QT:\n",
    "    QT.circuit.cnot(QT.q(0),QT.q(1))\n",
    "    QT.circuit.swap(QT.q(0),QT.q(1))\n",
    "    QT.circuit.h(QT.q(1))\n",
    "print(QT)\n",
    "QT.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:01.068751Z",
     "iopub.status.busy": "2022-04-25T18:29:01.068535Z",
     "iopub.status.idle": "2022-04-25T18:29:01.072992Z",
     "shell.execute_reply": "2022-04-25T18:29:01.072599Z",
     "shell.execute_reply.started": "2022-04-25T18:29:01.068732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubit= 3\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "code.infer()\n",
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, -1, 3), (('cnot', 1, 0),))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.evaluate([])(no_op(n_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_circuit_to_mat(code.evaluate([])(no_op(n_qubit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T23:20:35.960776Z",
     "iopub.status.busy": "2022-04-25T23:20:35.960513Z",
     "iopub.status.idle": "2022-04-25T23:20:35.965165Z",
     "shell.execute_reply": "2022-04-25T23:20:35.964700Z",
     "shell.execute_reply.started": "2022-04-25T23:20:35.960751Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks = makeTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"hadamard_0\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h $0))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -4.1588830833596715)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task =get_task_from_name(\"cnot_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot $0))\")\n",
    "task.logLikelihood(code), grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -8.317766166719343)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (minv(mv $0))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))\")\n",
    "code.evaluate([])(no_op(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, 3), (('cnot', 0, 1), ('cnot', 1, 0), ('cnot', 0, 1)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding primitive\n",
    "code = dc.program.Program.parse(\"(lambda (mv (emb (lambda  (mv(mv(cnot(minv(mv_r(cnot(minv (mv (cnot $0))))))))))  $0 )))\")\n",
    "\n",
    "code.evaluate([])(no_op(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.]], dtype=float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cz_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (h(mv(cnot(mv_r(h (mv $0)))))))\")\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n",
    "np.round(state_circuit_to_mat(code.evaluate([])(no_op(2))),decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ───\n",
      "        \n",
      "q_1: ─■─\n",
      "      │ \n",
      "q_2: ─■─\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Code consistent with Qiskit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(3))) as QT:\n",
    "    QT.circuit.cz(QT.q(0),QT.q(1))\n",
    "print(QT)\n",
    "QT.check()\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "q_0: ─■─\n",
      "      │ \n",
      "q_1: ─■─\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1., -0.],\n",
       "       [ 0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with QiskitTester(code.evaluate([])(no_op(2))) as QT:\n",
    "    QT.circuit.cz(QT.q(1),QT.q(0))\n",
    "print(QT)\n",
    "np.real(np.array(QT.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -16.635532333438686)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_nn_1\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot ((rep (dec(dec(size $0))) (lambda (mv $0))) $0)))\")\n",
    "code.evaluate([])(no_op(3))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          ┌───┐                         ┌───┐     \n",
      "q_0: ──■──┤ X ├──■───────────────────■──┤ X ├──■──\n",
      "     ┌─┴─┐└─┬─┘┌─┴─┐     ┌───┐     ┌─┴─┐└─┬─┘┌─┴─┐\n",
      "q_1: ┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├──■──┤ X ├\n",
      "     └───┘     └───┘┌─┴─┐└─┬─┘┌─┴─┐└───┘     └───┘\n",
      "q_2: ───────────────┤ X ├──■──┤ X ├───────────────\n",
      "                    └───┘     └───┘               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, -56.838068805915505)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) ) $0 )))))\")\n",
    "print_circuit(code.evaluate([])(no_op(3)))\n",
    "task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) ) $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If swap was included\n",
    "# task = get_task_from_name(\"swap_0n\",tasks)\n",
    "# code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda (swap(mv_r $0))) )  (mv_r( (rep (dec(size $0)) (lambda (mv(swap $0))) )  $0 )))))\")\n",
    "# print_circuit(code.evaluate([])(no_op(5)))\n",
    "# task.logLikelihood(code),  grammar.logLikelihood(code.infer(), code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile bottom-up enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available?: False\n",
      "using cuda?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--resume RESUME] [-i ITERATIONS]\n",
      "                             [-t ENUMERATIONTIMEOUT] [-R RECOGNITIONTIMEOUT]\n",
      "                             [-RS RECOGNITIONSTEPS] [-k TOPK]\n",
      "                             [-p PSEUDOCOUNTS] [-b AIC] [-l STRUCTUREPENALTY]\n",
      "                             [-a ARITY] [-c CPUS] [--no-cuda]\n",
      "                             [-m MAXIMUMFRONTIER] [--reuseRecognition]\n",
      "                             [--recognition] [--ensembleSize ENSEMBLESIZE]\n",
      "                             [-g] [-d] [--no-consolidation]\n",
      "                             [--testingTimeout TESTINGTIMEOUT]\n",
      "                             [--testEvery TESTEVERY] [--seed SEED]\n",
      "                             [--activation {relu,sigmoid,tanh}]\n",
      "                             [--solver {ocaml,pypy,bottom,python}]\n",
      "                             [-r HELMHOLTZRATIO]\n",
      "                             [--compressor {pypy,rust,vs,pypy_vs,ocaml,memorize}]\n",
      "                             [--matrixRank MATRIXRANK] [--mask]\n",
      "                             [--biasOptimal] [--contextual]\n",
      "                             [--clear-recognition CLEAR-RECOGNITION]\n",
      "                             [--primitive-graph PRIMITIVE-GRAPH [PRIMITIVE-GRAPH ...]]\n",
      "                             [--taskBatchSize TASKBATCHSIZE]\n",
      "                             [--taskReranker {default,random,randomShuffle,unsolved,unsolvedEntropy,unsolvedRandomEntropy,randomkNN,randomLowEntropykNN}]\n",
      "                             [--storeTaskMetrics] [--rewriteTaskMetrics]\n",
      "                             [--addTaskMetrics ADDTASKMETRICS [ADDTASKMETRICS ...]]\n",
      "                             [--auxiliary] [--addFullTaskMetrics]\n",
      "                             [--countParameters COUNTPARAMETERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1536060b-098c-4fd5-b891-f22aa0311306\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/tmp-23320Afm1Zw1Bm3I3.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import binutil  # required to import from dreamcoder modules\n",
    "except ModuleNotFoundError:\n",
    "    import bin.binutil  # alt import if called as module\n",
    "\n",
    "from dreamcoder.domains.quantum_algorithms.main import main\n",
    "from dreamcoder.dreamcoder import commandlineArguments\n",
    "from dreamcoder.utilities import numberOfCPUs\n",
    "\n",
    "arguments = commandlineArguments(\n",
    "    featureExtractor=None, # it was TowerCNN\n",
    "    CPUs=numberOfCPUs(),\n",
    "    helmholtzRatio=0.5,\n",
    "    recognitionTimeout=6,\n",
    "    iterations=6,\n",
    "    a=3,\n",
    "    structurePenalty=1,\n",
    "    pseudoCounts=10,\n",
    "    topK=2,\n",
    "    maximumFrontier=5,\n",
    "    extras=None,\n",
    "    solver=\"bottom\", \n",
    "    useRecognitionModel=False,\n",
    "    enumerationTimeout=6,#-g\n",
    "    compressor=\"pypy\")   #ocaml, python, pypy  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running EC on 01-mar-grp-0020 @ 2022-04-03 20:06:17.653038 with 8 CPUs and parameters:\n",
      "\t noConsolidation  =  False\n",
      "\t iterations  =  6\n",
      "\t enumerationTimeout  =  6\n",
      "\t useRecognitionModel  =  False\n",
      "\t topk_use_only_likelihood  =  False\n",
      "\t pseudoCounts  =  10\n",
      "\t aic  =  1.0\n",
      "\t structurePenalty  =  1\n",
      "\t arity  =  3\n",
      "\t taskReranker  =  default\n",
      "\t storeTaskMetrics  =  True\n",
      "\t rewriteTaskMetrics  =  False\n",
      "\t maximumFrontier  =  5\n",
      "\t solver  =  bottom\n",
      "\t topK  =  2\n",
      "\t evaluationTimeout  =  0.01\n",
      "\t cuda  =  False\n",
      "\n",
      "Currently using this much memory: 208424960\n",
      "Currently using this much memory: 208429056\n",
      "Using a waking task batch of size: 19\n",
      "Disabling parallelism on the Python side because we only have one job.\n",
      "If you are using ocaml or bottom, there could still be parallelism.\n",
      "(frontend) Launching int -> tcircuit (19 tasks) w/ 8 CPUs. 0.000000 <= MDL < 6.000000. Timeout 6.000000.\n",
      "PANIC! Exception in child worker: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 243, in _f\n",
      "    r = f(*a, **k)\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\", line 407, in solveForTask_bottom\n",
      "    compile_me=False,\n",
      "  File \"/Users/lsarra/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/utilities.py\", line 404, in callCompiled\n",
      "    stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 800, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/Users/lsarra/opt/anaconda3/envs/dc/lib/python3.7/subprocess.py\", line 1551, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pypy3': 'pypy3'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/m3rq3pbs7lq6drdpnnfm1fvjwthg2w/T/ipykernel_23556/2686176463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/domains/quantum_algorithms/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     41\u001b[0m                            \u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                            **arguments)\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mecIterator\u001b[0;34m(grammar, tasks, _, useDSL, noConsolidation, mask, seed, addFullTaskMetrics, matrixRank, solver, compressor, biasOptimal, contextual, testingTasks, iterations, resume, enumerationTimeout, testingTimeout, testEvery, reuseRecognition, ensembleSize, useRecognitionModel, recognitionTimeout, recognitionSteps, helmholtzRatio, featureExtractor, activation, topK, topk_use_only_likelihood, use_map_search_times, maximumFrontier, pseudoCounts, aic, structurePenalty, arity, evaluationTimeout, taskBatchSize, taskReranker, CPUs, cuda, message, outputPrefix, storeTaskMetrics, rewriteTaskMetrics, auxiliaryLoss, custom_wake_generative)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                                       \u001b[0menumerationTimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menumerationTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                                                       \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                                                       evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSearchTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/dreamcoder.py\u001b[0m in \u001b[0;36mdefault_wake_generative\u001b[0;34m(grammar, tasks, maximumFrontier, enumerationTimeout, CPUs, solver, evaluationTimeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m                                                    \u001b[0mCPUs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPUs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                                                    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                                                    evaluationTimeout=evaluationTimeout)\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generative model enumeration results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrontier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopDownFrontiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ownCloud/topics/artificial-scientific-discovery/2021_Unitary-Synthesis/ec/dreamcoder/enumeration.py\u001b[0m in \u001b[0;36mmulticoreEnumeration\u001b[0;34m(g, tasks, _, enumerationTimeout, solver, CPUs, maximumFrontier, verbose, evaluationTimeout, testing)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PANIC! Exception in child worker:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"success\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Mark the CPUs is no longer being used and pause the stopwatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %lprun -f dc.domains.quantum_algorithms.primitives.tensor_contraction -f dc.domains.quantum_algorithms.tasks.QuantumTask.logLikelihood -f dc.domains.quantum_algorithms.primitives.execute_quantum_algorithm -f full_circuit_to_mat -f dc.enumeration.multicoreEnumeration main(arguments)\n",
    "main(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -13.862943611198904)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda ((rep (inc(inc(dec 0))) (lambda (mv $0))) $0))\")\n",
    "code.evaluate([])(no_op(5))\n",
    "code.infer()\n",
    "tasks[0].logLikelihood(code),  grammar.logLikelihood(code.infer(), code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T18:29:57.433325Z",
     "iopub.status.busy": "2022-04-25T18:29:57.432928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pcfg compilation: distinct non terminals 2 ; distinct environments 2\n",
      "start symbol: (tcircuit, (tcircuit,))\n",
      "\n",
      "(tcircuit, (tcircuit,)) ::= mv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= mv_r\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= minv\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= h\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= cnot\t0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= rep\t0x(int, (tcircuit,)) 1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= emb\t1x(tcircuit, (tcircuit,)) 0x(tcircuit, (tcircuit,))\t\t-2.0794415416798357\n",
      "(tcircuit, (tcircuit,)) ::= $0\t\t\t-2.0794415416798357\n",
      "\n",
      "(int, (tcircuit,)) ::= 0\t\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= inc\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= dec\t0x(int, (tcircuit,))\t\t-1.3862943611198906\n",
      "(int, (tcircuit,)) ::= size\t0x(tcircuit, (tcircuit,))\t\t-1.3862943611198906\n",
      "[(lambda 0)]\n",
      " -- Bottom up enumeration, cost 0\n",
      " -- Bottom up enumeration, cost 1\n",
      " -- Bottom up enumeration, cost 2\n",
      " -- Bottom up enumeration, cost 3\n",
      " -- Bottom up enumeration, cost 4\n",
      " -- Bottom up enumeration, cost 5\n",
      " -- Bottom up enumeration, cost 6\n",
      " -- Bottom up enumeration, cost 7\n",
      " -- Bottom up enumeration, cost 8\n",
      " -- Bottom up enumeration, cost 9\n",
      " -- Bottom up enumeration, cost 10\n",
      " -- Bottom up enumeration, cost 11\n",
      " -- Bottom up enumeration, cost 12\n",
      " -- Bottom up enumeration, cost 13\n",
      " -- Bottom up enumeration, cost 14\n",
      " -- Bottom up enumeration, cost 15\n",
      " -- Bottom up enumeration, cost 16\n",
      " -- Bottom up enumeration, cost 17\n",
      " -- Bottom up enumeration, cost 18\n",
      " -- Bottom up enumeration, cost 19\n",
      " -- Bottom up enumeration, cost 20\n",
      " -- Bottom up enumeration, cost 21\n",
      " -- Bottom up enumeration, cost 22\n",
      " -- Bottom up enumeration, cost 23\n",
      " -- Bottom up enumeration, cost 24\n",
      " -- Bottom up enumeration, cost 25\n",
      " -- Bottom up enumeration, cost 26\n",
      " -- Bottom up enumeration, cost 27\n",
      " -- Bottom up enumeration, cost 28\n",
      " -- Bottom up enumeration, cost 29\n",
      " -- Bottom up enumeration, cost 30\n",
      " -- Bottom up enumeration, cost 31\n",
      " -- Bottom up enumeration, cost 32\n",
      " -- Bottom up enumeration, cost 33\n",
      " -- Bottom up enumeration, cost 34\n",
      " -- Bottom up enumeration, cost 35\n",
      " -- Bottom up enumeration, cost 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m restricted_pcfg \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mPCFG\u001b[39m.\u001b[39mfrom_grammar(grammar, request\u001b[39m=\u001b[39mdc\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39marrow(tcircuit, tcircuit))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m restricted_dictionary \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49menumeration\u001b[39m.\u001b[39;49menumerate_pcfg(restricted_pcfg,timeout\u001b[39m=\u001b[39;49m\u001b[39m3600\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m                                                       circuit_execution_function\u001b[39m=\u001b[39;49mstate_circuit_to_mat,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=3'>4</a>\u001b[0m                                                       no_op\u001b[39m=\u001b[39;49mno_op,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=4'>5</a>\u001b[0m                                                       observational_equivalence\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000030vscode-remote?line=5'>6</a>\u001b[0m                                                       sound\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py:656\u001b[0m, in \u001b[0;36menumerate_pcfg\u001b[0;34m(pcfg, timeout, circuit_execution_function, no_op, observational_equivalence, sound)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=652'>653</a>\u001b[0m n_min \u001b[39m=\u001b[39m QuantumTask\u001b[39m.\u001b[39mmin_size\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=653'>654</a>\u001b[0m n_max \u001b[39m=\u001b[39m  QuantumTask\u001b[39m.\u001b[39mmax_size\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=655'>656</a>\u001b[0m \u001b[39mfor\u001b[39;00m code \u001b[39min\u001b[39;00m pcfg\u001b[39m.\u001b[39mquantized_enumeration(observational_equivalence\u001b[39m=\u001b[39mobservational_equivalence,\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=656'>657</a>\u001b[0m                                        inputs\u001b[39m=\u001b[39m[[no_op(\u001b[39m3\u001b[39m)],[no_op(\u001b[39m4\u001b[39m)]],\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=657'>658</a>\u001b[0m                                        sound\u001b[39m=\u001b[39msound):\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=658'>659</a>\u001b[0m     \u001b[39mif\u001b[39;00m (time\u001b[39m.\u001b[39mtime()\u001b[39m>\u001b[39mt_0\u001b[39m+\u001b[39mtimeout): \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/enumeration.py?line=659'>660</a>\u001b[0m     \u001b[39m# check if it is a valid circuit\u001b[39;00m\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1902\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration\u001b[0;34m(self, resolution, skeletons, observational_equivalence, sound, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1899'>1900</a>\u001b[0m eprint(\u001b[39m\"\u001b[39m\u001b[39m -- Bottom up enumeration, cost\u001b[39m\u001b[39m\"\u001b[39m, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1900'>1901</a>\u001b[0m \u001b[39mfor\u001b[39;00m skeleton, skeleton_cost \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(skeletons, skeleton_costs):\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1901'>1902</a>\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m complete_skeleton(cost\u001b[39m-\u001b[39mskeleton_cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1902'>1903</a>\u001b[0m         \u001b[39myield\u001b[39;00m e\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1884\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1881'>1882</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete_skeleton\u001b[39m(cost, skeleton):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1882'>1883</a>\u001b[0m     \u001b[39mif\u001b[39;00m skeleton\u001b[39m.\u001b[39misAbstraction:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1883'>1884</a>\u001b[0m         \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m complete_skeleton(cost, skeleton\u001b[39m.\u001b[39mbody):\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1884'>1885</a>\u001b[0m             \u001b[39myield\u001b[39;00m Abstraction(b)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1885'>1886</a>\u001b[0m     \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misApplication:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1892\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.complete_skeleton\u001b[0;34m(cost, skeleton)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1889'>1890</a>\u001b[0m                 \u001b[39myield\u001b[39;00m Application(f, x)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1890'>1891</a>\u001b[0m \u001b[39melif\u001b[39;00m skeleton\u001b[39m.\u001b[39misNamedHole:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1891'>1892</a>\u001b[0m     \u001b[39myield from\u001b[39;00m expressions_of_size(skeleton\u001b[39m.\u001b[39;49mname, cost)\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1892'>1893</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1893'>1894</a>\u001b[0m     \u001b[39mif\u001b[39;00m cost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py:1865\u001b[0m, in \u001b[0;36mPCFG.quantized_enumeration.<locals>.expressions_of_size\u001b[0;34m(symbol, size)\u001b[0m\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1862'>1863</a>\u001b[0m accepted_new \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1863'>1864</a>\u001b[0m \u001b[39mfor\u001b[39;00m proposed_expression \u001b[39min\u001b[39;00m new:\n\u001b[0;32m-> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1864'>1865</a>\u001b[0m     key \u001b[39m=\u001b[39m test_generator\u001b[39m.\u001b[39;49mcompute_signature(proposed_expression,\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1865'>1866</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_type[symbol],\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1866'>1867</a>\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfree_variable_types[symbol])\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1868'>1869</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m equivalences[symbol]:\n\u001b[1;32m   <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/grammar.py?line=1869'>1870</a>\u001b[0m         equivalences[symbol][key] \u001b[39m=\u001b[39m proposed_expression\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:92\u001b[0m, in \u001b[0;36mSloppy.compute_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_signature\u001b[39m(\u001b[39mself\u001b[39m, expression, tp, arguments):\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=91'>92</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msound_signature(expression, tp, arguments)\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=93'>94</a>\u001b[0m     outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=94'>95</a>\u001b[0m     \u001b[39mfor\u001b[39;00m test_input \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_inputs(arguments):\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py:86\u001b[0m, in \u001b[0;36mSloppy.sound_signature\u001b[0;34m(self, expression, tp, arguments)\u001b[0m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=83'>84</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=84'>85</a>\u001b[0m \u001b[39m#eprint(\"output\", tuple(outputs))\u001b[39;00m\n\u001b[0;32m---> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(o \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m outputs):\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=86'>87</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/sloppy.py?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "restricted_pcfg = dc.grammar.PCFG.from_grammar(grammar, request=dc.type.arrow(tcircuit, tcircuit))\n",
    "restricted_dictionary = dc.enumeration.enumerate_pcfg(restricted_pcfg,timeout=3600, \n",
    "                                                      circuit_execution_function=state_circuit_to_mat,\n",
    "                                                      no_op=no_op,\n",
    "                                                      observational_equivalence=True,\n",
    "                                                      sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcfg = dc.grammar.PCFG.from_grammar(full_grammar, request=dc.type.arrow(tcircuit_full, tcircuit_full))\n",
    "full_dictionary = dc.enumeration.enumerate_pcfg(full_pcfg,\n",
    "                                                timeout=3600, \n",
    "                                                circuit_execution_function=full_circuit_to_mat,\n",
    "                                                no_op=f_no_op,\n",
    "                                                observational_equivalence=True,\n",
    "                                                sound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matched_programs = []\n",
    "for unitary in full_dictionary.keys():\n",
    "    if unitary in restricted_dictionary.keys():\n",
    "        try:\n",
    "            full_task = full_dictionary[unitary][\"task\"]\n",
    "            full_unitary = full_circuit_to_mat(dc.program.Program.parse(full_task).evaluate([])(f_no_op(4)))\n",
    "            \n",
    "            restricted_task = restricted_dictionary[unitary][\"task\"]\n",
    "            restricted_unitary = state_circuit_to_mat(dc.program.Program.parse(restricted_task).evaluate([])(no_op(4)))\n",
    "\n",
    "            if np.all(full_unitary==restricted_unitary):\n",
    "                matched_programs.append([full_task, \n",
    "                                         restricted_task, \n",
    "                                         max(full_dictionary[unitary][\"time\"],restricted_dictionary[unitary][\"time\"])])\n",
    "        except QuantumCircuitException:\n",
    "            ...\n",
    "    # else: print(full_dictionary[unitary][\"task\"])\n",
    "eprint(f\"Enumerated {len(matched_programs)} programs\")\n",
    "# how long it took to enumerate (when the program was found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m code \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(\u001b[39mlist\u001b[39m(full_dictionary\u001b[39m.\u001b[39mvalues())[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000034vscode-remote?line=1'>2</a>\u001b[0m print_circuit(code\u001b[39m.\u001b[39mevaluate([])(f_no_op(\u001b[39m4\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(list(full_dictionary.values())[-1][\"task\"])\n",
    "print_circuit(code.evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "          \n",
      "q_0: ─────\n",
      "          \n",
      "q_1: ─────\n",
      "     ┌───┐\n",
      "q_2: ┤ H ├\n",
      "     └───┘\n",
      "q_3: ─────\n",
      "          \n",
      "q_4: ─────\n",
      "     ┌───┐\n",
      "q_5: ┤ H ├\n",
      "     └───┘\n"
     ]
    }
   ],
   "source": [
    "code = dc.program.Program.parse(\"(lambda (fh (fh $0 (inc (inc 0))) (dec (fsize $0))))\")\n",
    "print_circuit(code.evaluate([])(f_no_op(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_programs(str_e1, str_e2, reset_state=True): # embed to reset state (i.e. if restricted_set)\n",
    "    if reset_state:\n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "        state_changed = 0\n",
    "        for n_qubit in range(QuantumTask.min_size,  QuantumTask.max_size):\n",
    "            if e1.evaluate([])(no_op(n_qubit))[0][0] !=0:\n",
    "                state_changed +=1\n",
    "        if state_changed:\n",
    "            e1 = dc.program.Program.parse(f\"(lambda (emb {str_e1} $0))\") # if it is already at the beginning do not embed\n",
    "\n",
    "    else: \n",
    "        e1 = dc.program.Program.parse(str_e1)\n",
    "    e2 = dc.program.Program.parse(str_e2)\n",
    "\n",
    "    return dc.program.Abstraction(\n",
    "        dc.program.Application(e2,\n",
    "        dc.program.Application(e1, dc.program.Index(0)))\n",
    "    ).betaNormalForm(reduceInventions=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_timeout = 10\n",
    "time_0 = time.time()\n",
    "merged_programs = []\n",
    "for i in range(len(matched_programs)):\n",
    "    for j in range(len(matched_programs)):\n",
    "        ii = np.random.randint(0,len(matched_programs))\n",
    "        jj = np.random.randint(0,len(matched_programs))\n",
    "        if (time.time()>time_0+merging_timeout): break\n",
    "        \n",
    "        full_program = merge_two_programs(matched_programs[ii][0], matched_programs[jj][0], reset_state=False)\n",
    "        restricted_program = merge_two_programs(matched_programs[ii][1], matched_programs[jj][1], reset_state=True)\n",
    "        merged_programs.append([\n",
    "            str(full_program),\n",
    "            str(restricted_program),\n",
    "            -1\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_program = merge_two_programs(matched_programs[i][1], matched_programs[j][1], reset_state=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_e1 = matched_programs[i][1]\n",
    "e1 = dc.program.Program.parse(str_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1, 5),\n",
       " (('hadamard', 0),\n",
       "  ('cnot', 0, 1),\n",
       "  ('hadamard', 0),\n",
       "  ('cnot', 0, 1),\n",
       "  ('cnot', 3, 4),\n",
       "  ('hadamard', 3)))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.evaluate([])(no_op(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_programs = matched_programs + merged_programs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "save_path = os.path.join(\"experimentOutputs/quantum/\",\"training_programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(dataset_programs, f)\n",
    "    \n",
    "with open(save_path+\"_matched\",\"wb\") as f:\n",
    "    pickle.dump(matched_programs, f)\n",
    "    \n",
    "with open(save_path+\"_restricted\",\"wb\") as f:\n",
    "    pickle.dump(restricted_dictionary, f)\n",
    "    \n",
    "with open(save_path+\"_full\",\"wb\") as f:\n",
    "    pickle.dump(full_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened dictionary with 4.05e+05 restricted programs and 1.04e+06 high-level programs\n",
      "Opened file with 1527579 programs\n"
     ]
    }
   ],
   "source": [
    "with open(save_path,\"rb\") as f:\n",
    "        dataset_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_matched\",\"rb\") as f:\n",
    "        matched_programs = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_restricted\",\"rb\") as f:\n",
    "        restricted_dictionary = pickle.load(f)\n",
    "        \n",
    "with open(save_path+\"_full\",\"rb\") as f:\n",
    "        full_dictionary = pickle.load(f)\n",
    "        \n",
    "print(f\"Opened dictionary with {len(restricted_dictionary):1.2e} restricted programs and {len(full_dictionary):1.2e} high-level programs\")\n",
    "print(f\"Opened file with {len(dataset_programs)} programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset in 1374821 training programs and 152758 testing programs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(dataset_programs)\n",
    "training_split = int(0.9*len(dataset_programs))\n",
    "training_programs = dataset_programs[:training_split]\n",
    "testing_programs = dataset_programs[training_split:]\n",
    "print(f\"Split dataset in {len(training_programs)} training programs and {len(testing_programs)} testing programs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractors for Recognition Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:47.800176Z",
     "iopub.status.busy": "2022-04-25T22:50:47.799722Z",
     "iopub.status.idle": "2022-04-25T22:50:47.805016Z",
     "shell.execute_reply": "2022-04-25T22:50:47.804479Z",
     "shell.execute_reply.started": "2022-04-25T22:50:47.800125Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import dreamcoder.great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsFeatureExtractor(nn.Module):\n",
    "    def __init__(self, tasks, full_op_names): # why do we need tasks?\n",
    "        super(BagOfWordsFeatureExtractor, self).__init__()\n",
    "        self.recomputeTasks = False\n",
    "        \n",
    "        self.qubit_test_range = [QuantumTask.min_size,QuantumTask.max_size]\n",
    "        self.qubit_num = self.qubit_test_range[1]-self.qubit_test_range[0]+1\n",
    "        \n",
    "        self.names = list(full_op_names.keys())\n",
    "        self.len_names =len(self.names)\n",
    "        \n",
    "        self.outputDimensionality = self.len_names*self.qubit_num\n",
    "        self.tasks=tasks\n",
    "        \n",
    "    # full_circuit to embedding (bag of words)\n",
    "    def full_circuit_to_embedding(self, full_circuit):\n",
    "        embedding = np.zeros([self.len_names], dtype=int)\n",
    "        for operation in full_circuit:\n",
    "            embedding[self.names.index(operation[0])]+=1\n",
    "        return embedding\n",
    "\n",
    "    def full_task_to_embedding(self,full_task):\n",
    "        full_embedding = np.hstack(\n",
    "            [self.full_circuit_to_embedding(full_task.target_algorithm(n_qubit)[1]) \n",
    "             for n_qubit in range(self.qubit_test_range[0],self.qubit_test_range[1]+1)]\n",
    "            )\n",
    "        return full_embedding\n",
    "    \n",
    "    def featuresOfTask(self, t):\n",
    "        return dc.recognition.variable(self.full_task_to_embedding(t)).float()\n",
    "    def featuresOfTasks(self, ts):\n",
    "        return dc.recognition.variable([self.full_task_to_embedding(t) for t in ts]).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GREAT feature for recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:54.744552Z",
     "iopub.status.busy": "2022-04-25T22:50:54.744330Z",
     "iopub.status.idle": "2022-04-25T22:50:54.768748Z",
     "shell.execute_reply": "2022-04-25T22:50:54.768221Z",
     "shell.execute_reply.started": "2022-04-25T22:50:54.744526Z"
    }
   },
   "outputs": [],
   "source": [
    "class GreatFeatureExtractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, tasks, full_op_names, d_model):\n",
    "        super(GreatFeatureExtractor, self).__init__()\n",
    "        \n",
    "        # number of qubits of the circuits to consider \n",
    "        self.n_min = QuantumTask.min_size\n",
    "        self.n_max =  QuantumTask.max_size\n",
    "        \n",
    "        self.outputDimensionality = d_model\n",
    "        self.feature_extr = dc.great.Great(layers=4, d_model=self.outputDimensionality, batch_first=True)\n",
    "        \n",
    "        # make list of lexicons (possible gate names)\n",
    "        self.vertex_lexicon = list(full_op_names.keys()) + [\"input\", \"aggregate\"]\n",
    "        # define embedding network for the lexicons\n",
    "        self.vertex_lexicon_embedding = nn.Embedding(len(self.vertex_lexicon), self.outputDimensionality)\n",
    "        self.vertex_lexicon_embedding_eval = torch.stack([\n",
    "            self.vertex_lexicon_embedding(torch.tensor(n)) for n in range(self.vertex_lexicon_embedding.num_embeddings)\n",
    "        ])\n",
    "        \n",
    "        # define embedding network for the input type numbers (last one is aggregate)\n",
    "        self.vertex_kind_embeddings = {n_qubits:nn.Embedding(n_qubits+1, self.outputDimensionality) \n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "        self.vertex_kind_embeddings_eval = {n_qubits:torch.stack([\n",
    "            self.vertex_kind_embeddings[n_qubits](torch.tensor(n)) for n in range(self.vertex_kind_embeddings[n_qubits].num_embeddings)\n",
    "            ])\n",
    "                                       for n_qubits in range(self.n_min,self.n_max+1)}\n",
    "\n",
    "\n",
    "        # make edge lexicon list\n",
    "        self.edge_lexicon = sorted([\"nothing\", \"input\", \"io\", \"output\", \"aggregator\"])\n",
    "        # define embedding network for lexicon\n",
    "        self.edge_lexicon_embedding = nn.Embedding(len(self.edge_lexicon), self.outputDimensionality)\n",
    "        self.edge_lexicon_embedding_eval = torch.stack(\n",
    "            [self.edge_lexicon_embedding(torch.tensor(n)) for n in range(self.edge_lexicon_embedding.num_embeddings)]\n",
    "            )\n",
    "\n",
    "        # define many embedding neural networks for the node id\n",
    "        self.max_gate_size = 2\n",
    "        self.edge_kind_embeddings = [nn.Embedding(self.max_gate_size, self.outputDimensionality),\n",
    "                                     nn.Embedding(self.max_gate_size, self.outputDimensionality)]\n",
    "        self.edge_kind_embeddings_eval = torch.stack(\n",
    "            [torch.stack(\n",
    "                [emb(torch.tensor(n)) for n in range(self.max_gate_size)]\n",
    "                ) for emb in self.edge_kind_embeddings]\n",
    "            )\n",
    "        \n",
    "        # define the no_relation tensor\n",
    "        self.edge_no_relation = self.edge_lexicon.index(\"nothing\")\n",
    "\n",
    "    def add_vertex(self,type, kind, vertices):\n",
    "        # VERTEX: #, type, kind\n",
    "        # Type = gate type\n",
    "        # kind = qubit id of that gate\n",
    "        idx = len(vertices) \n",
    "        vertices.append((idx, type, kind))\n",
    "        return idx\n",
    "\n",
    "    def get_initial_bindings(self,n_bindings, vertices):\n",
    "        return {i:self.add_vertex(self.vertex_lexicon.index(\"input\"),i, vertices) for i in range(n_bindings)}\n",
    "\n",
    "    def get_relations(self,changed_vertices):\n",
    "        relations = []\n",
    "        changed_vertices_array = np.array(changed_vertices)\n",
    "        \n",
    "        # among inputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"input\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][0]) )\n",
    "        \n",
    "        # among outputs\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(i+1, len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"output\"),i,j, changed_vertices_array[i][1], changed_vertices_array[j][1] ))\n",
    "        \n",
    "        # input - output\n",
    "        for i in range(len(changed_vertices_array)):\n",
    "            for j in range(len(changed_vertices_array)):\n",
    "                relations.append((self.edge_lexicon.index(\"io\"),i,j, changed_vertices_array[i][0], changed_vertices_array[j][1]))\n",
    "        \n",
    "        # EDGES row: type kind1 kind2 vertex_from vertex_to\n",
    "        # Type = input/output/io\n",
    "        # kind = #1 -> #2\n",
    "        return relations\n",
    "\n",
    "    def get_graph(self, circuit, bindings, vertices, edges):\n",
    "        if len(circuit)>0:\n",
    "            current_op = circuit[0]\n",
    "            new_bindings = bindings.copy()\n",
    "            changed_vertices = []\n",
    "            for idx, i in enumerate(current_op[1:]): \n",
    "                # current_op[1:] contains qubit_1, qubit_2, ... on which the gate is applied\n",
    "                new_bindings[i] = self.add_vertex(self.vertex_lexicon.index(current_op[0]), idx, vertices) \n",
    "                changed_vertices.append([bindings[i], new_bindings[i]])\n",
    "                \n",
    "            relations = self.get_relations(changed_vertices)\n",
    "            edges.extend(relations)\n",
    "            self.get_graph(circuit[1:], new_bindings, vertices, edges)\n",
    "            \n",
    "    # define total embedding\n",
    "    def get_vertex_list_embedding(self,vertex_list,n_qubits):\n",
    "        vertex_array = np.array(vertex_list) # IDX, GATE, KIND\n",
    "        vertex_embedding = (self.vertex_lexicon_embedding_eval[vertex_array[:,1]] + \n",
    "                            self.vertex_kind_embeddings_eval[n_qubits][vertex_array[:,2]])\n",
    "        return vertex_embedding\n",
    "\n",
    "    def get_edge_list_embedding(self, edges, vertices):\n",
    "        edges_array = np.array(edges,dtype=int)\n",
    "        # EDGES: type, kind1, kind2, v1, v2\n",
    "        # no relation embedding\n",
    "        edge_embedding = self.edge_lexicon_embedding_eval[self.edge_no_relation].repeat(len(vertices),len(vertices),1)\n",
    "\n",
    "        # add type embedding (gate type)\n",
    "        edge_type_embedding = self.edge_lexicon_embedding_eval[edges_array[:,0]]\n",
    "        edge_embedding[edges_array[:,-2], edges_array[:,-1]] = edge_type_embedding\n",
    "\n",
    "        # non aggregated edges also have \"kind\" = 0,1... (qubit index in input/output)\n",
    "        # select non aggregator edges\n",
    "        non_aggregated_edges = edges_array[ edges_array[:,0]!=self.edge_lexicon.index(\"aggregator\") ]\n",
    "        # calculate edge kind embedding (according to qubit id)\n",
    "        edge_kind_embedding= (self.edge_kind_embeddings_eval[(0,non_aggregated_edges[:,1])] \n",
    "                            + self.edge_kind_embeddings_eval[(1,non_aggregated_edges[:,2])])\n",
    "        # add also kind embedding\n",
    "        edge_embedding[non_aggregated_edges[:,-2], non_aggregated_edges[:,-1]] += edge_kind_embedding\n",
    "        return edge_embedding\n",
    "\n",
    "\n",
    "    def full_circuit_to_VE_embeddings(self, full_circuit):\n",
    "        n_qubits, circuit = full_circuit\n",
    "        \n",
    "        vertices = []\n",
    "        edges = []\n",
    "        \n",
    "        # add aggregator vertex\n",
    "        self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
    "\n",
    "        bindings = self.get_initial_bindings(n_qubits, vertices)\n",
    "        self.get_graph(circuit, bindings, vertices, edges)\n",
    "        \n",
    "        # make vertex list\n",
    "        # sort it\n",
    "        vertex_embedding = self.get_vertex_list_embedding(vertices, n_qubits)\n",
    "        \n",
    "        # add aggregator edges between all vertices\n",
    "        for vertex_2 in vertices[1:]: # start from 1 to exclude aggregate vertex\n",
    "            edges.append((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
    "        \n",
    "        # make edges embedding\n",
    "        edge_embedding = self.get_edge_list_embedding(edges, vertices)\n",
    "        return vertex_embedding, edge_embedding\n",
    "    \n",
    "    # Batch embedding calculation\n",
    "    def full_circuits_to_feature(self, full_circuits):\n",
    "        Vs = []\n",
    "        Es = []\n",
    "        \n",
    "        # Prepare the graph for each circuit\n",
    "        for full_circuit in full_circuits:\n",
    "            vertex_embedding, edge_embedding = self.full_circuit_to_VE_embeddings(full_circuit)\n",
    "            \n",
    "            Vs.append(vertex_embedding)\n",
    "            Es.append(edge_embedding)\n",
    "            \n",
    "        # Pad the sequences in the batch to largest\n",
    "        Vs_padded = torch.nn.utils.rnn.pad_sequence(Vs, batch_first=True)\n",
    "        Es_padded = torch.zeros([Vs_padded.shape[0],Vs_padded.shape[1],Vs_padded.shape[1],Vs_padded.shape[2]])\n",
    "        for i in range(len(Es)):\n",
    "            Es_padded[i,:len(Es[i]),:len(Es[i])] = Es[i]\n",
    "            \n",
    "        # Calculate associated mask\n",
    "        Vs_mask = torch.ones(Vs_padded.shape[0],Vs_padded.shape[1])\n",
    "        for i in range(len(Vs)):\n",
    "            Vs_mask[i,:len(Vs[i])] = 0\n",
    "        \n",
    "        # Batch calculation of embedding by applying the transformer\n",
    "        return gr.feature_extr(Vs_padded, Es_padded, mask=Vs_mask)[:,0] # take only aggregator vertex\n",
    "            \n",
    "    def featuresOfTask(self, t):\n",
    "        return self.featuresOfTasks([t])[0]\n",
    "    \n",
    "    def featuresOfTasks(self, ts):\n",
    "        embeddings = []\n",
    "        for n_qubit in range(self.n_min, self.n_max):\n",
    "            full_circuits = [t.target_algorithm(n_qubit) for t in ts]\n",
    "            embeddings.append(self.full_circuits_to_feature(full_circuits))\n",
    "        \n",
    "        embedding = sum(embeddings)\n",
    "        return dc.recognition.variable(embedding).float()\n",
    "    \n",
    "    def taskOfProgram(self, p, t): # why do we need this?\n",
    "        return dc.task.Task(\"dummy task\", t, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:50:56.180693Z",
     "iopub.status.busy": "2022-04-25T22:50:56.180547Z",
     "iopub.status.idle": "2022-04-25T22:50:56.204326Z",
     "shell.execute_reply": "2022-04-25T22:50:56.203907Z",
     "shell.execute_reply.started": "2022-04-25T22:50:56.180676Z"
    }
   },
   "outputs": [],
   "source": [
    "gr = GreatFeatureExtractor(None,full_op_names, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 10\n",
    "programs_batch = random.sample(training_programs, batch_size)\n",
    "tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                for i, program in enumerate(programs_batch)]\n",
    "embedding = gr.featuresOfTasks(tasks_batch)\n",
    "\n",
    "full_circuit = dc.program.Program.parse(programs_batch[0][0]).evaluate([])(f_no_op(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '(lambda (fh (fcnot (fcnot (fh (fh (fh $0 (inc 0)) (dec (fsize $0))) 0) (inc 0) 0) (inc (inc 0)) (inc 0)) (inc 0)))'\n",
    "full_circuit = dc.program.Program.parse(program).evaluate([])(f_no_op(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n",
      "call\n"
     ]
    }
   ],
   "source": [
    "n_qubits, circuit = full_circuit\n",
    "\n",
    "vertices = []\n",
    "edges = []\n",
    "\n",
    "# add aggregator vertex\n",
    "gr.add_vertex(gr.vertex_lexicon.index(\"aggregate\"), gr.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
    "\n",
    "bindings = gr.get_initial_bindings(n_qubits, vertices)\n",
    "gr.get_graph(circuit, bindings, vertices, edges)\n",
    "\n",
    "# make vertex list\n",
    "# sort it\n",
    "vertex_embedding = gr.get_vertex_list_embedding(vertices, n_qubits)\n",
    "\n",
    "# add aggregator edges between all vertices\n",
    "for vertex_2 in vertices[1:]: # start from 1 to exclude aggregate vertex\n",
    "    edges.append((gr.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
    "\n",
    "# make edges embedding\n",
    "edge_embedding = gr.get_edge_list_embedding(edges, vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5, 4),\n",
       " (1, 4, 0),\n",
       " (2, 4, 1),\n",
       " (3, 4, 2),\n",
       " (4, 4, 3),\n",
       " (5, 0, 0),\n",
       " (6, 0, 0),\n",
       " (7, 0, 0),\n",
       " (8, 1, 0),\n",
       " (9, 1, 1),\n",
       " (10, 1, 0),\n",
       " (11, 1, 1),\n",
       " (12, 0, 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T22:51:13.548669Z",
     "iopub.status.busy": "2022-04-25T22:51:13.548371Z",
     "iopub.status.idle": "2022-04-25T22:51:13.580349Z",
     "shell.execute_reply": "2022-04-25T22:51:13.579965Z",
     "shell.execute_reply.started": "2022-04-25T22:51:13.548641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_extractor = BagOfWordsFeatureExtractor(None, full_op_names)\n",
    "feature_extractor = GreatFeatureExtractor(None, full_op_names, d_model=128)\n",
    "recognition_model = dc.recognition.RecognitionModel(feature_extractor, grammar, contextual=True)\n",
    "\n",
    "lr=0.001\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=lr, eps=1e-3, amsgrad=True)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T00:29:23.684184Z",
     "iopub.status.busy": "2022-04-26T00:29:23.683874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 213/10000 [00:41<31:48,  5.13it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 59'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=5'>6</a>\u001b[0m programs_batch \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(training_programs, batch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=6'>7</a>\u001b[0m tasks_batch \u001b[39m=\u001b[39m [QuantumTask(i,\u001b[39mlambda\u001b[39;00m n_qubit, program\u001b[39m=\u001b[39mprogram: dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mevaluate([])(f_no_op(n_qubit)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=7'>8</a>\u001b[0m                \u001b[39mfor\u001b[39;00m i, program \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(programs_batch)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=8'>9</a>\u001b[0m embedding \u001b[39m=\u001b[39m recognition_model\u001b[39m.\u001b[39;49mfeatureExtractor\u001b[39m.\u001b[39;49mfeaturesOfTask(tasks_batch[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=9'>10</a>\u001b[0m simple_programs \u001b[39m=\u001b[39m [dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m program \u001b[39min\u001b[39;00m programs_batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000056vscode-remote?line=10'>11</a>\u001b[0m contextual_grammar \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mContextualGrammar\u001b[39m.\u001b[39mfromGrammar(grammar)\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.featuresOfTask\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=177'>178</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeaturesOfTask\u001b[39m(\u001b[39mself\u001b[39m, t):\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=178'>179</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeaturesOfTasks([t])[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.featuresOfTasks\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=182'>183</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_qubit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_min, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_max):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=183'>184</a>\u001b[0m     full_circuits \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mtarget_algorithm(n_qubit) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=184'>185</a>\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_circuits_to_feature(full_circuits))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=186'>187</a>\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(embeddings)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=187'>188</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dc\u001b[39m.\u001b[39mrecognition\u001b[39m.\u001b[39mvariable(embedding)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.full_circuits_to_feature\u001b[0;34m(self, full_circuits)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=172'>173</a>\u001b[0m     Vs_mask[i,:\u001b[39mlen\u001b[39m(Vs[i])] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=174'>175</a>\u001b[0m \u001b[39m# Batch calculation of embedding by applying the transformer\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=175'>176</a>\u001b[0m \u001b[39mreturn\u001b[39;00m gr\u001b[39m.\u001b[39;49mfeature_extr(Vs_padded, Es_padded, mask\u001b[39m=\u001b[39;49mVs_mask)[:,\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:288\u001b[0m, in \u001b[0;36mGreat.forward\u001b[0;34m(self, x, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=285'>286</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, relation: Tensor, mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=286'>287</a>\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=287'>288</a>\u001b[0m         x \u001b[39m=\u001b[39m l(x, relation, mask)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:256\u001b[0m, in \u001b[0;36mGreatLayer.forward\u001b[0;34m(self, src, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=253'>254</a>\u001b[0m src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(src2)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=254'>255</a>\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(src)\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=255'>256</a>\u001b[0m src2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(src))))\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=256'>257</a>\u001b[0m src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(src2)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=257'>258</a>\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(src)\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps = 10000\n",
    "\n",
    "gr.feature_extr.train();\n",
    "for _ in trange(n_steps):\n",
    "    programs_batch = random.sample(training_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTask(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    recognition_model.zero_grad()\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:29:05.932779Z",
     "iopub.status.busy": "2022-04-26T19:29:05.932539Z",
     "iopub.status.idle": "2022-04-26T19:29:06.088014Z",
     "shell.execute_reply": "2022-04-26T19:29:06.087539Z",
     "shell.execute_reply.started": "2022-04-26T19:29:05.932756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/4773 [00:06<21:55,  3.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 61'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=6'>7</a>\u001b[0m programs_batch \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(testing_programs, batch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=7'>8</a>\u001b[0m tasks_batch \u001b[39m=\u001b[39m [QuantumTask(i,\u001b[39mlambda\u001b[39;00m n_qubit, program\u001b[39m=\u001b[39mprogram: dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mevaluate([])(f_no_op(n_qubit)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=8'>9</a>\u001b[0m                \u001b[39mfor\u001b[39;00m i, program \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(programs_batch)]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=9'>10</a>\u001b[0m embedding \u001b[39m=\u001b[39m recognition_model\u001b[39m.\u001b[39;49mfeatureExtractor\u001b[39m.\u001b[39;49mfeaturesOfTasks(tasks_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=10'>11</a>\u001b[0m simple_programs \u001b[39m=\u001b[39m [dc\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mProgram\u001b[39m.\u001b[39mparse(program[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m program \u001b[39min\u001b[39;00m programs_batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000079vscode-remote?line=11'>12</a>\u001b[0m contextual_grammar \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mgrammar\u001b[39m.\u001b[39mContextualGrammar\u001b[39m.\u001b[39mfromGrammar(grammar)\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.featuresOfTasks\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=182'>183</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_qubit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_min, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_max):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=183'>184</a>\u001b[0m     full_circuits \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mtarget_algorithm(n_qubit) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=184'>185</a>\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_circuits_to_feature(full_circuits))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=186'>187</a>\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(embeddings)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=187'>188</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dc\u001b[39m.\u001b[39mrecognition\u001b[39m.\u001b[39mvariable(embedding)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32m/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb Cell 53'\u001b[0m in \u001b[0;36mGreatFeatureExtractor.full_circuits_to_feature\u001b[0;34m(self, full_circuits)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=172'>173</a>\u001b[0m     Vs_mask[i,:\u001b[39mlen\u001b[39m(Vs[i])] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=174'>175</a>\u001b[0m \u001b[39m# Batch calculation of embedding by applying the transformer\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bzpg005/u/lsarra/notebooks/unitary-synthesis/ec/quantum_notebook.ipynb#ch0000052vscode-remote?line=175'>176</a>\u001b[0m \u001b[39mreturn\u001b[39;00m gr\u001b[39m.\u001b[39;49mfeature_extr(Vs_padded, Es_padded, mask\u001b[39m=\u001b[39;49mVs_mask)[:,\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:288\u001b[0m, in \u001b[0;36mGreat.forward\u001b[0;34m(self, x, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=285'>286</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, relation: Tensor, mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=286'>287</a>\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=287'>288</a>\u001b[0m         x \u001b[39m=\u001b[39m l(x, relation, mask)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:252\u001b[0m, in \u001b[0;36mGreatLayer.forward\u001b[0;34m(self, src, relation, mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=239'>240</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src: Tensor, relation: Tensor, mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=240'>241</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Pass the input through the encoder layer.\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=241'>242</a>\u001b[0m \n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=242'>243</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=249'>250</a>\u001b[0m \u001b[39m        see the docs in Transformer class.\u001b[39;00m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=250'>251</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=251'>252</a>\u001b[0m     src2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(src, src, src, relation, attn_mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=252'>253</a>\u001b[0m                           key_padding_mask\u001b[39m=\u001b[39;49mmask)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=253'>254</a>\u001b[0m     src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(src2)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=254'>255</a>\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(src)\n",
      "File \u001b[0;32m~/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///u/lsarra/conda-envs/dc2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py:187\u001b[0m, in \u001b[0;36mMultiheadAttentionRelation.forward\u001b[0;34m(self, query, key, value, relation, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=183'>184</a>\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m) \u001b[39m+\u001b[39m r\u001b[39m.\u001b[39mview(B, L, L, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=185'>186</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mbqkhe,bkhe->bqkh\u001b[39m\u001b[39m'\u001b[39m, q, k)\n\u001b[0;32m--> <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=186'>187</a>\u001b[0m a \u001b[39m=\u001b[39m a \u001b[39m/\u001b[39;49m ((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads)\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=188'>189</a>\u001b[0m \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///zeropoint/u/lsarra/notebooks/unitary-synthesis/ec/dreamcoder/great.py?line=189'>190</a>\u001b[0m     key_padding_mask \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m*\u001b[39m (key_padding_mask \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps_test = int(len(testing_programs)/batch_size)\n",
    "\n",
    "gr.feature_extr.eval();\n",
    "test_losses = []\n",
    "for _ in trange(n_steps_test):\n",
    "    programs_batch = random.sample(testing_programs, batch_size)\n",
    "    tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                   for i, program in enumerate(programs_batch)]\n",
    "    embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "    simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "    contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "    \n",
    "    summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "    \n",
    "    features = recognition_model._MLP(embedding)\n",
    "    lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "    loss = -lls.mean() \n",
    "    test_losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test dataset: 34.032530784606934\n",
      "Last training losses: 33.23689865112305\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performance on test dataset: {np.mean(test_losses)}\")\n",
    "print(f\"Last training losses: {np.mean(losses[-50:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:23.299842Z",
     "iopub.status.busy": "2022-04-26T18:19:23.299363Z",
     "iopub.status.idle": "2022-04-26T18:19:23.380903Z",
     "shell.execute_reply": "2022-04-26T18:19:23.380458Z",
     "shell.execute_reply.started": "2022-04-26T18:19:23.299794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29.1121815835177, tensor([-24.1656], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8000 # program we are testing\n",
    "task = QuantumTask(i,lambda n_qubit, program=matched_programs[i]: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "code =  dc.program.Program.parse(matched_programs[i][1])\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:25.164529Z",
     "iopub.status.busy": "2022-04-26T18:19:25.164279Z",
     "iopub.status.idle": "2022-04-26T18:19:25.188522Z",
     "shell.execute_reply": "2022-04-26T18:19:25.188119Z",
     "shell.execute_reply.started": "2022-04-26T18:19:25.164509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     ┌───┐     ┌───┐               \n",
      "q_0: ┤ H ├──■──┤ X ├───────────────\n",
      "     ├───┤┌─┴─┐└─┬─┘┌───┐     ┌───┐\n",
      "q_1: ┤ H ├┤ X ├──■──┤ H ├──■──┤ X ├\n",
      "     ├───┤└───┘     └───┘┌─┴─┐└─┬─┘\n",
      "q_2: ┤ H ├───────────────┤ X ├──■──\n",
      "     └───┘               └───┘     \n",
      "q_3: ──────────────────────────────\n",
      "                                   \n",
      "             ┌───┐        ┌───┐\n",
      "q_0: ──■───X─┤ H ├──■───X─┤ H ├\n",
      "     ┌─┴─┐ │ └───┘  │   │ └───┘\n",
      "q_1: ┤ X ├─┼────────┼───X──────\n",
      "     └───┘ │      ┌─┴─┐        \n",
      "q_2: ──────X──────┤ X ├────────\n",
      "                  └───┘        \n",
      "q_3: ──────────────────────────\n",
      "                               \n"
     ]
    }
   ],
   "source": [
    "print_circuit(dc.program.Program.parse(matched_programs[i][1]).evaluate([])(no_op(4)))\n",
    "print_circuit(dc.program.Program.parse(matched_programs[i][0]).evaluate([])(f_no_op(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T19:37:45.516189Z",
     "iopub.status.busy": "2022-04-26T19:37:45.515743Z",
     "iopub.status.idle": "2022-04-26T19:37:45.562522Z",
     "shell.execute_reply": "2022-04-26T19:37:45.562092Z",
     "shell.execute_reply.started": "2022-04-26T19:37:45.516161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.317766166719343, tensor([-6.1669], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"cnot_10\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda (cnot (mv(minv( $0)))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T18:19:26.677832Z",
     "iopub.status.busy": "2022-04-26T18:19:26.677368Z",
     "iopub.status.idle": "2022-04-26T18:19:26.714873Z",
     "shell.execute_reply": "2022-04-26T18:19:26.714468Z",
     "shell.execute_reply.started": "2022-04-26T18:19:26.677784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.635532333438686, tensor([-21.4344], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_01\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda  (cnot(minv(mv_r(cnot(minv (mv (cnot  $0))))))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T20:04:03.555071Z",
     "iopub.status.busy": "2022-04-26T20:04:03.554552Z",
     "iopub.status.idle": "2022-04-26T20:04:03.597859Z",
     "shell.execute_reply": "2022-04-26T20:04:03.597393Z",
     "shell.execute_reply.started": "2022-04-26T20:04:03.555019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-56.838068805915505, tensor([-67.8985], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = get_task_from_name(\"swap_0n\",tasks)\n",
    "code = dc.program.Program.parse(\"(lambda ((  (rep (dec(dec(size $0))) (lambda ((cnot(minv(mv_r(cnot(minv (mv (cnot(mv_r $0)))))))))) )  (mv_r( (rep (dec(size $0)) (lambda (mv((cnot(minv(mv_r(cnot(minv (mv (cnot $0)))))))))) )  $0 )))))\")\n",
    "\n",
    "embedding = recognition_model.featureExtractor.featuresOfTask(task)\n",
    "predicted_grammar_of_task = recognition_model(embedding)\n",
    "\n",
    "grammar.logLikelihood(code.infer(),code), predicted_grammar_of_task.logLikelihood(code.infer(),code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.logLikelihood(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    batch_size = 32\n",
    "    n_steps = 1000\n",
    "\n",
    "    gr.feature_extr.train();\n",
    "    for _ in trange(n_steps):\n",
    "        programs_batch = random.sample(matched_programs, batch_size)\n",
    "        tasks_batch = [QuantumTask(i,lambda n_qubit, program=program: dc.program.Program.parse(program[0]).evaluate([])(f_no_op(n_qubit)))\n",
    "                    for i, program in enumerate(programs_batch)]\n",
    "        embedding = recognition_model.featureExtractor.featuresOfTasks(tasks_batch)\n",
    "        simple_programs = [dc.program.Program.parse(program[1]) for program in programs_batch]\n",
    "        contextual_grammar = dc.grammar.ContextualGrammar.fromGrammar(grammar)\n",
    "        \n",
    "        summaries = [contextual_grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "        \n",
    "        # if not using contextual grammar\n",
    "        # summaries = [grammar.closedLikelihoodSummary(simple_program.infer(), simple_program) for simple_program in simple_programs ]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recognition_model.zero_grad()\n",
    "        \n",
    "        features = recognition_model._MLP(embedding)\n",
    "        lls = recognition_model.grammarBuilder.batchedLogLikelihoods(features, summaries)\n",
    "        loss = -lls.mean() \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:20<07:57,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 2.77232 s\n",
      "File: /tmp/ipykernel_5224/1500948551.py\n",
      "Function: full_circuit_to_embeddings at line 126\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   126                                               def full_circuit_to_embeddings(self, full_circuit):\n",
      "   127      4032       7131.0      1.8      0.3          n_qubits, circuit = full_circuit\n",
      "   128                                                   \n",
      "   129      4032       6016.0      1.5      0.2          vertices = set()\n",
      "   130      4032       3139.0      0.8      0.1          edges = set()\n",
      "   131                                                   \n",
      "   132                                                   # add aggregator vertex\n",
      "   133      4032      19337.0      4.8      0.7          self.add_vertex(self.vertex_lexicon.index(\"aggregate\"), self.vertex_kind_embeddings[n_qubits].num_embeddings-1, vertices)\n",
      "   134                                           \n",
      "   135      4032      45828.0     11.4      1.7          bindings = self.get_initial_bindings(n_qubits, vertices)\n",
      "   136      4032     489074.0    121.3     17.6          self.get_graph(circuit, bindings, vertices, edges)\n",
      "   137                                                   \n",
      "   138                                                   # make vertex list\n",
      "   139                                                   # sort it\n",
      "   140      4032      32831.0      8.1      1.2          vertex_list = sorted(list(vertices), key=lambda vertex: vertex[0])\n",
      "   141      4032     332576.0     82.5     12.0          vertex_embedding = self.get_vertex_list_embedding(vertex_list, n_qubits)\n",
      "   142                                                   \n",
      "   143                                                   # add aggregator edges between all vertices\n",
      "   144     52278      45104.0      0.9      1.6          for vertex_2 in vertex_list[1:]:\n",
      "   145     48246      61617.0      1.3      2.2              edges.add((self.edge_lexicon.index(\"aggregator\"), 137, 137, 0, vertex_2[0]))\n",
      "   146                                                   \n",
      "   147                                                   # make edges embedding\n",
      "   148      4032    1723674.0    427.5     62.2          edge_embedding = self.get_edge_list_embedding(list(edges), vertex_list)\n",
      "   149      4032       5998.0      1.5      0.2          return vertex_embedding, edge_embedding\n",
      "   150                                                   # return self.feature_extr(vertex_embedding[None], edge_embedding[None])[0][0] # squeeze and take aggregate vertex"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f gr.full_circuit_to_embeddings train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Try to merge two low-level programs and see if we find one solution in the full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - X Split training/test dataset\n",
    "# - X Fix dataset augmentation by removing EMBED gate when not needed\n",
    "# - X Fix graph generation with aggregator edges (all vertices connected to AGGREGATOR!)\n",
    "# - X Masking to allow batch processing (1=masked, 0=allowed)\n",
    "# - Refactor notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v[\"task\"] for v in restricted_dictionary.values()], len(restricted_dictionary)\n",
    "[v[\"task\"] for v in full_dictionary.values()], len(full_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-26T19:51:39.308675Z",
     "iopub.status.busy": "2022-04-26T19:51:39.307983Z",
     "iopub.status.idle": "2022-04-26T19:51:39.441889Z",
     "shell.execute_reply": "2022-04-26T19:51:39.441136Z",
     "shell.execute_reply.started": "2022-04-26T19:51:39.308647Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2759, -0.9362, -0.9602,  ...,  0.6412,  0.4378, -0.7729],\n",
       "         [ 1.7919, -0.6928, -0.9339,  ...,  0.8708,  1.3383, -1.1959],\n",
       "         [ 1.2987, -0.6996,  0.0477,  ...,  0.3061,  1.1436, -1.6745],\n",
       "         [ 1.2819,  0.2977, -1.0037,  ...,  0.4054,  1.5640, -0.7430],\n",
       "         [ 1.7916,  0.0230, -0.8343,  ...,  1.0366,  1.3168, -1.8804]],\n",
       "\n",
       "        [[ 2.0887, -0.1400,  0.0943,  ...,  0.9963,  1.7624, -2.4135],\n",
       "         [ 1.4391,  0.5386, -0.4229,  ...,  2.0502,  1.9189, -1.3506],\n",
       "         [ 1.6665,  0.8416,  1.2304,  ...,  0.8859,  0.6563, -2.1701],\n",
       "         [ 1.5891, -0.5968, -0.0885,  ...,  1.3230,  0.4269, -0.0181],\n",
       "         [ 1.8056,  0.2443, -1.2259,  ...,  0.9780,  0.1213, -0.8895]],\n",
       "\n",
       "        [[ 0.8442,  0.1006,  0.0183,  ...,  1.8837,  0.5749, -0.5465],\n",
       "         [ 2.5495, -0.1414,  0.4686,  ...,  1.7190,  1.0287, -1.3964],\n",
       "         [ 1.8204, -0.5687,  0.1718,  ...,  0.3555,  1.1992, -1.9379],\n",
       "         [ 0.5032, -0.4394,  0.1243,  ...,  0.9252,  0.4069, -1.3862],\n",
       "         [ 0.3281, -0.9118,  1.0388,  ...,  1.8198,  0.3727, -1.3449]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.3547,  0.3113, -1.0753,  ...,  1.2877,  0.4014, -0.3564],\n",
       "         [ 0.6609,  0.1625,  0.1371,  ...,  1.2780,  0.9802, -1.6158],\n",
       "         [ 1.4975, -0.7608, -0.8684,  ...,  1.5775, -0.1982, -1.9023],\n",
       "         [ 1.5495, -0.6564, -0.6223,  ...,  2.0482,  0.7048, -0.4304],\n",
       "         [ 0.3180, -0.5374, -0.1619,  ...,  2.0027,  0.7437, -1.5314]],\n",
       "\n",
       "        [[ 1.4287, -0.4453,  0.5868,  ...,  1.3229, -0.5583, -1.2987],\n",
       "         [ 1.7313, -0.4392, -0.9725,  ...,  1.3026, -0.0118, -1.4333],\n",
       "         [ 1.4873, -1.5506,  0.4468,  ...,  1.1709, -0.4355, -0.2878],\n",
       "         [ 1.1434, -0.2029, -0.0112,  ...,  1.1371,  0.4448, -0.0070],\n",
       "         [ 1.6713, -1.0351,  0.0396,  ...,  2.2492, -0.6135, -0.4507]],\n",
       "\n",
       "        [[ 1.4418,  0.3296, -0.0159,  ...,  0.8935,  0.5671, -3.1858],\n",
       "         [ 0.9681,  0.8472, -0.8943,  ...,  0.5434, -0.2662, -1.9399],\n",
       "         [ 1.1947,  0.3078, -0.4165,  ..., -0.0205,  0.0526, -1.9974],\n",
       "         [ 2.0432,  0.3872,  0.3145,  ...,  0.2231,  0.2443, -2.2678],\n",
       "         [ 1.6737, -0.1154,  0.1803,  ...,  0.4033,  0.4201, -1.9801]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc.great.Great(layers=4,batch_first=True)(torch.rand(9,5,512),\n",
    "                        torch.rand(9,5,5,512),torch.rand(9,5)>0.5 )\n",
    "\n",
    "# check output batched with mask and not batched\n",
    "# SHOULD the edge relation matrix be symmetric?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21ea1a886259afbd8a118ef6898db29b8a19fae78d92613d0ae3d877be73df6a"
  },
  "kernelspec": {
   "display_name": "dc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
